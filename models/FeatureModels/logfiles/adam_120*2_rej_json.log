5690
5690
5910
[0, 0, 1, 1000, 0, 0.5, 0.0, 0.5416666666666666]
Iteration 1, loss = 0.65760701
Iteration 2, loss = 0.60219734
Iteration 3, loss = 0.57416122
Iteration 4, loss = 0.56729426
Iteration 5, loss = 0.56271830
Iteration 6, loss = 0.55912497
Iteration 7, loss = 0.55711982
Iteration 8, loss = 0.55657584
Iteration 9, loss = 0.55321446
Iteration 10, loss = 0.55293109
Iteration 11, loss = 0.55126090
Iteration 12, loss = 0.55161653
Iteration 13, loss = 0.55005363
Iteration 14, loss = 0.54875232
Iteration 15, loss = 0.55115258
Iteration 16, loss = 0.55027112
Iteration 17, loss = 0.54751900
Iteration 18, loss = 0.54665022
Iteration 19, loss = 0.54549391
Iteration 20, loss = 0.54510337
Iteration 21, loss = 0.54511833
Iteration 22, loss = 0.54541166
Iteration 23, loss = 0.54352753
Iteration 24, loss = 0.54498180
Iteration 25, loss = 0.54325737
Iteration 26, loss = 0.54339959
Iteration 27, loss = 0.54388149
Iteration 28, loss = 0.54173823
Iteration 29, loss = 0.54295189
Iteration 30, loss = 0.54200779
Iteration 31, loss = 0.54159314
Iteration 32, loss = 0.54056068
Iteration 33, loss = 0.54162696
Iteration 34, loss = 0.54233431
Iteration 35, loss = 0.54446817
Iteration 36, loss = 0.54063121
Iteration 37, loss = 0.54060785
Iteration 38, loss = 0.54010593
Iteration 39, loss = 0.53960448
Iteration 40, loss = 0.53933207
Iteration 41, loss = 0.53868578
Iteration 42, loss = 0.53845657
Iteration 43, loss = 0.53979330
Iteration 44, loss = 0.53787613
Iteration 45, loss = 0.53756008
Iteration 46, loss = 0.53910957
Iteration 47, loss = 0.53894995
Iteration 48, loss = 0.53762428
Iteration 49, loss = 0.53752129
Iteration 50, loss = 0.53867193
Iteration 51, loss = 0.53815136
Iteration 52, loss = 0.53944768
Iteration 53, loss = 0.53687174
Iteration 54, loss = 0.53688143
Iteration 55, loss = 0.53682476
Iteration 56, loss = 0.53712668
Iteration 57, loss = 0.53735907
Iteration 58, loss = 0.53686695
Iteration 59, loss = 0.53645976
Iteration 60, loss = 0.53682278
Iteration 61, loss = 0.53523762
Iteration 62, loss = 0.53646343
Iteration 63, loss = 0.53676270
Iteration 64, loss = 0.53833236
Iteration 65, loss = 0.53718389
Iteration 66, loss = 0.53535471
Iteration 67, loss = 0.53603708
Iteration 68, loss = 0.53513858
Iteration 69, loss = 0.53463177
Iteration 70, loss = 0.53496530
Iteration 71, loss = 0.53574479
Iteration 72, loss = 0.53780651
Iteration 73, loss = 0.53435799
Iteration 74, loss = 0.53553003
Iteration 75, loss = 0.53371822
Iteration 76, loss = 0.53574223
Iteration 77, loss = 0.53365389
Iteration 78, loss = 0.53353716
Iteration 79, loss = 0.53390302
Iteration 80, loss = 0.53335417
Iteration 81, loss = 0.53540032
Iteration 82, loss = 0.53440259
Iteration 83, loss = 0.53373980
Iteration 84, loss = 0.53276045
Iteration 85, loss = 0.53341610
Iteration 86, loss = 0.53211140
Iteration 87, loss = 0.53202510
Iteration 88, loss = 0.53223269
Iteration 89, loss = 0.53194206
Iteration 90, loss = 0.53239543
Iteration 91, loss = 0.53364515
Iteration 92, loss = 0.53413794
Iteration 93, loss = 0.53238270
Iteration 94, loss = 0.53290394
Iteration 95, loss = 0.53131225
Iteration 96, loss = 0.53059001
Iteration 97, loss = 0.53123738
Iteration 98, loss = 0.53097903
Iteration 99, loss = 0.53210274
Iteration 100, loss = 0.53173307
Iteration 101, loss = 0.53286650
Iteration 102, loss = 0.53131157
Iteration 103, loss = 0.53196764
Iteration 104, loss = 0.53155805
Iteration 105, loss = 0.53174446
Iteration 106, loss = 0.53032370
Iteration 107, loss = 0.53036371
Iteration 108, loss = 0.53047057
Iteration 109, loss = 0.53098188
Iteration 110, loss = 0.53049387
Iteration 111, loss = 0.53048470
Iteration 112, loss = 0.52943559
Iteration 113, loss = 0.52997990
Iteration 114, loss = 0.52932496
Iteration 115, loss = 0.52892948
Iteration 116, loss = 0.52912609
Iteration 117, loss = 0.52966696
Iteration 118, loss = 0.52900706
Iteration 119, loss = 0.53381680
Iteration 120, loss = 0.53125675
Iteration 121, loss = 0.52924651
Iteration 122, loss = 0.52996571
Iteration 123, loss = 0.52865535
Iteration 124, loss = 0.52836021
Iteration 125, loss = 0.52888308
Iteration 126, loss = 0.52896127
Iteration 127, loss = 0.52797150
Iteration 128, loss = 0.52781672
Iteration 129, loss = 0.52838147
Iteration 130, loss = 0.53035469
Iteration 131, loss = 0.52805731
Iteration 132, loss = 0.52956515
Iteration 133, loss = 0.52847476
Iteration 134, loss = 0.52748252
Iteration 135, loss = 0.52980558
Iteration 136, loss = 0.52879030
Iteration 137, loss = 0.52801841
Iteration 138, loss = 0.52726369
Iteration 139, loss = 0.52700051
Iteration 140, loss = 0.52722536
Iteration 141, loss = 0.52707618
Iteration 142, loss = 0.52840411
Iteration 143, loss = 0.52699438
Iteration 144, loss = 0.52736190
Iteration 145, loss = 0.52671150
Iteration 146, loss = 0.52777591
Iteration 147, loss = 0.52826013
Iteration 148, loss = 0.52657620
Iteration 149, loss = 0.52619013
Iteration 150, loss = 0.52634252
Iteration 151, loss = 0.52759891
Iteration 152, loss = 0.52686838
Iteration 153, loss = 0.52835389
Iteration 154, loss = 0.53051931
Iteration 155, loss = 0.52615816
Iteration 156, loss = 0.52693286
Iteration 157, loss = 0.52657928
Iteration 158, loss = 0.52546904
Iteration 159, loss = 0.52517302
Iteration 160, loss = 0.52585964
Iteration 161, loss = 0.52621234
Iteration 162, loss = 0.52781445
Iteration 163, loss = 0.52989126
Iteration 164, loss = 0.52606728
Iteration 165, loss = 0.52480433
Iteration 166, loss = 0.52536736
Iteration 167, loss = 0.52594772
Iteration 168, loss = 0.52642352
Iteration 169, loss = 0.52435755
Iteration 170, loss = 0.52448631
Iteration 171, loss = 0.52482615
Iteration 172, loss = 0.52593638
Iteration 173, loss = 0.52502625
Iteration 174, loss = 0.52377824
Iteration 175, loss = 0.52582399
Iteration 176, loss = 0.52524567
Iteration 177, loss = 0.52546290
Iteration 178, loss = 0.52423519
Iteration 179, loss = 0.52397050
Iteration 180, loss = 0.52348107
Iteration 181, loss = 0.52380734
Iteration 182, loss = 0.52333907
Iteration 183, loss = 0.52478322
Iteration 184, loss = 0.52372180
Iteration 185, loss = 0.52244244
Iteration 186, loss = 0.52239267
Iteration 187, loss = 0.52335208
Iteration 188, loss = 0.52462045
Iteration 189, loss = 0.52471447
Iteration 190, loss = 0.52301442
Iteration 191, loss = 0.52143424
Iteration 192, loss = 0.52251377
Iteration 193, loss = 0.52336326
Iteration 194, loss = 0.52195134
Iteration 195, loss = 0.52234047
Iteration 196, loss = 0.52147432
Iteration 197, loss = 0.52442160
Iteration 198, loss = 0.52329085
Iteration 199, loss = 0.52270816
Iteration 200, loss = 0.52349659
Iteration 201, loss = 0.52392518
Iteration 202, loss = 0.52188216
Iteration 203, loss = 0.52335748
Iteration 204, loss = 0.52477319
Iteration 205, loss = 0.52341421
Iteration 206, loss = 0.52390939
Iteration 207, loss = 0.52227821
Iteration 208, loss = 0.52232506
Iteration 209, loss = 0.52150021
Iteration 210, loss = 0.52118997
Iteration 211, loss = 0.52199340
Iteration 212, loss = 0.52145484
Iteration 213, loss = 0.52105102
Iteration 214, loss = 0.52192374
Iteration 215, loss = 0.52147141
Iteration 216, loss = 0.52196397
Iteration 217, loss = 0.52032367
Iteration 218, loss = 0.52076107
Iteration 219, loss = 0.52392750
Iteration 220, loss = 0.52162148
Iteration 221, loss = 0.52060542
Iteration 222, loss = 0.51992405
Iteration 223, loss = 0.52006539
Iteration 224, loss = 0.52120053
Iteration 225, loss = 0.52027599
Iteration 226, loss = 0.52049518
Iteration 227, loss = 0.52405022
Iteration 228, loss = 0.52466864
Iteration 229, loss = 0.51984331
Iteration 230, loss = 0.52029696
Iteration 231, loss = 0.52259664
Iteration 232, loss = 0.52228218
Iteration 233, loss = 0.51878734
Iteration 234, loss = 0.51950540
Iteration 235, loss = 0.51910477
Iteration 236, loss = 0.51972511
Iteration 237, loss = 0.52142149
Iteration 238, loss = 0.52020426
Iteration 239, loss = 0.51941829
Iteration 240, loss = 0.52020100
Iteration 241, loss = 0.52066456
Iteration 242, loss = 0.51895344
Iteration 243, loss = 0.51955142
Iteration 244, loss = 0.52115751
Iteration 245, loss = 0.51829819
Iteration 246, loss = 0.51945818
Iteration 247, loss = 0.51956202
Iteration 248, loss = 0.51905484
Iteration 249, loss = 0.51727137
Iteration 250, loss = 0.51701604
Iteration 251, loss = 0.51806409
Iteration 252, loss = 0.51928635
Iteration 253, loss = 0.51873349
Iteration 254, loss = 0.51758424
Iteration 255, loss = 0.51742197
Iteration 256, loss = 0.51909259
Iteration 257, loss = 0.51864041
Iteration 258, loss = 0.51851811
Iteration 259, loss = 0.51931560
Iteration 260, loss = 0.51978069
Iteration 261, loss = 0.51894738
Iteration 262, loss = 0.51909127
Iteration 263, loss = 0.51799326
Iteration 264, loss = 0.51748858
Iteration 265, loss = 0.51743298
Iteration 266, loss = 0.51705137
Iteration 267, loss = 0.51767564
Iteration 268, loss = 0.51811882
Iteration 269, loss = 0.52142981
Iteration 270, loss = 0.51977127
Iteration 271, loss = 0.51709130
Iteration 272, loss = 0.51617611
Iteration 273, loss = 0.51727669
Iteration 274, loss = 0.51840195
Iteration 275, loss = 0.52151369
Iteration 276, loss = 0.51905413
Iteration 277, loss = 0.52037662
Iteration 278, loss = 0.51690021
Iteration 279, loss = 0.51562950
Iteration 280, loss = 0.51740375
Iteration 281, loss = 0.51896320
Iteration 282, loss = 0.51818224
Iteration 283, loss = 0.51574904
Iteration 284, loss = 0.51614412
Iteration 285, loss = 0.51586491
Iteration 286, loss = 0.51535334
Iteration 287, loss = 0.51697856
Iteration 288, loss = 0.51455399
Iteration 289, loss = 0.51590849
Iteration 290, loss = 0.51559797
Iteration 291, loss = 0.51845310
Iteration 292, loss = 0.51633346
Iteration 293, loss = 0.51562416
Iteration 294, loss = 0.51645039
Iteration 295, loss = 0.51445864
Iteration 296, loss = 0.51471539
Iteration 297, loss = 0.51640289
Iteration 298, loss = 0.51742293
Iteration 299, loss = 0.51868059
Iteration 300, loss = 0.51423881
Iteration 301, loss = 0.51478032
Iteration 302, loss = 0.51561080
Iteration 303, loss = 0.51507805
Iteration 304, loss = 0.51532258
Iteration 305, loss = 0.51571396
Iteration 306, loss = 0.51846675
Iteration 307, loss = 0.51449948
Iteration 308, loss = 0.51554357
Iteration 309, loss = 0.51521804
Iteration 310, loss = 0.51486156
Iteration 311, loss = 0.51447575
Iteration 312, loss = 0.51376980
Iteration 313, loss = 0.51474922
Iteration 314, loss = 0.51446769
Iteration 315, loss = 0.51510327
Iteration 316, loss = 0.51679397
Iteration 317, loss = 0.51510323
Iteration 318, loss = 0.51449134
Iteration 319, loss = 0.51518550
Iteration 320, loss = 0.51578381
Iteration 321, loss = 0.51521532
Iteration 322, loss = 0.51414067
Iteration 323, loss = 0.51334829
Iteration 324, loss = 0.51524881
Iteration 325, loss = 0.51313135
Iteration 326, loss = 0.51456720
Iteration 327, loss = 0.51932478
Iteration 328, loss = 0.51504964
Iteration 329, loss = 0.51354166
Iteration 330, loss = 0.51430906
Iteration 331, loss = 0.51447615
Iteration 332, loss = 0.51320925
Iteration 333, loss = 0.51616717
Iteration 334, loss = 0.51330114
Iteration 335, loss = 0.51382683
Iteration 336, loss = 0.51525313
Iteration 337, loss = 0.51631336
Iteration 338, loss = 0.51744049
Iteration 339, loss = 0.51291975
Iteration 340, loss = 0.51403889
Iteration 341, loss = 0.51354135
Iteration 342, loss = 0.51352045
Iteration 343, loss = 0.51610202
Iteration 344, loss = 0.51340287
Iteration 345, loss = 0.51558725
Iteration 346, loss = 0.51332018
Iteration 347, loss = 0.51292049
Iteration 348, loss = 0.51818666
Iteration 349, loss = 0.52035615
Iteration 350, loss = 0.51771146
Iteration 351, loss = 0.51455846
Iteration 352, loss = 0.51382390
Iteration 353, loss = 0.51667837
Iteration 354, loss = 0.51307626
Iteration 355, loss = 0.51239388
Iteration 356, loss = 0.51401288
Iteration 357, loss = 0.51264976
Iteration 358, loss = 0.51300895
Iteration 359, loss = 0.51291861
Iteration 360, loss = 0.51092840
Iteration 361, loss = 0.51157537
Iteration 362, loss = 0.51360700
Iteration 363, loss = 0.51154223
Iteration 364, loss = 0.51409283
Iteration 365, loss = 0.51433768
Iteration 366, loss = 0.51321458
Iteration 367, loss = 0.51342397
Iteration 368, loss = 0.51198625
Iteration 369, loss = 0.51285228
Iteration 370, loss = 0.51187063
Iteration 371, loss = 0.51232901
Iteration 372, loss = 0.51660225
Iteration 373, loss = 0.51461337
Iteration 374, loss = 0.51433106
Iteration 375, loss = 0.51124710
Iteration 376, loss = 0.51224103
Iteration 377, loss = 0.51102704
Iteration 378, loss = 0.51770482
Iteration 379, loss = 0.51522688
Iteration 380, loss = 0.51088639
Iteration 381, loss = 0.51160859
Iteration 382, loss = 0.51141710
Iteration 383, loss = 0.51192964
Iteration 384, loss = 0.51270038
Iteration 385, loss = 0.51180272
Iteration 386, loss = 0.51302843
Iteration 387, loss = 0.51114062
Iteration 388, loss = 0.51326319
Iteration 389, loss = 0.51267447
Iteration 390, loss = 0.51170668
Iteration 391, loss = 0.51118113
Iteration 392, loss = 0.51028022
Iteration 393, loss = 0.51228890
Iteration 394, loss = 0.51077474
Iteration 395, loss = 0.51189542
Iteration 396, loss = 0.50983343
Iteration 397, loss = 0.50979153
Iteration 398, loss = 0.51253696
Iteration 399, loss = 0.51315676
Iteration 400, loss = 0.50999625
Iteration 401, loss = 0.51233440
Iteration 402, loss = 0.51004547
Iteration 403, loss = 0.51070406
Iteration 404, loss = 0.51001344
Iteration 405, loss = 0.51103951
Iteration 406, loss = 0.51011476
Iteration 407, loss = 0.51052920
Iteration 408, loss = 0.51177420
Iteration 409, loss = 0.51184676
Iteration 410, loss = 0.50980744
Iteration 411, loss = 0.51071015
Iteration 412, loss = 0.50894664
Iteration 413, loss = 0.51030747
Iteration 414, loss = 0.50995767
Iteration 415, loss = 0.50977384
Iteration 416, loss = 0.51064137
Iteration 417, loss = 0.50940921
Iteration 418, loss = 0.50987183
Iteration 419, loss = 0.50879182
Iteration 420, loss = 0.51262099
Iteration 421, loss = 0.51166932
Iteration 422, loss = 0.51013186
Iteration 423, loss = 0.51109427
Iteration 424, loss = 0.51026584
Iteration 425, loss = 0.51017149
Iteration 426, loss = 0.51086455
Iteration 427, loss = 0.51133004
Iteration 428, loss = 0.51133544
Iteration 429, loss = 0.50962105
Iteration 430, loss = 0.51281202
Iteration 431, loss = 0.51031033
Iteration 432, loss = 0.50959046
Iteration 433, loss = 0.51074944
Iteration 434, loss = 0.51021800
Iteration 435, loss = 0.51042723
Iteration 436, loss = 0.50895162
Iteration 437, loss = 0.50804569
Iteration 438, loss = 0.50930454
Iteration 439, loss = 0.50950810
Iteration 440, loss = 0.51162268
Iteration 441, loss = 0.51345461
Iteration 442, loss = 0.51353512
Iteration 443, loss = 0.51065239
Iteration 444, loss = 0.50993078
Iteration 445, loss = 0.51021878
Iteration 446, loss = 0.51116656
Iteration 447, loss = 0.50871904
Iteration 448, loss = 0.50994632
Iteration 449, loss = 0.51282114
Iteration 450, loss = 0.50902551
Iteration 451, loss = 0.50822435
Iteration 452, loss = 0.50869888
Iteration 453, loss = 0.50864429
Iteration 454, loss = 0.50868191
Iteration 455, loss = 0.50991420
Iteration 456, loss = 0.50812044
Iteration 457, loss = 0.50983980
Iteration 458, loss = 0.50907112
Iteration 459, loss = 0.50773147
Iteration 460, loss = 0.50907349
Iteration 461, loss = 0.50842507
Iteration 462, loss = 0.50904756
Iteration 463, loss = 0.50935296
Iteration 464, loss = 0.50895010
Iteration 465, loss = 0.51004965
Iteration 466, loss = 0.50960652
Iteration 467, loss = 0.50862556
Iteration 468, loss = 0.50850936
Iteration 469, loss = 0.50944099
Iteration 470, loss = 0.51129614
Iteration 471, loss = 0.50971362
Iteration 472, loss = 0.50745193
Iteration 473, loss = 0.50916538
Iteration 474, loss = 0.50855234
Iteration 475, loss = 0.50907914
Iteration 476, loss = 0.50767024
Iteration 477, loss = 0.50994990
Iteration 478, loss = 0.51077078
Iteration 479, loss = 0.50901265
Iteration 480, loss = 0.50774429
Iteration 481, loss = 0.50913274
Iteration 482, loss = 0.51001790
Iteration 483, loss = 0.50751351
Iteration 484, loss = 0.51065009
Iteration 485, loss = 0.50878679
Iteration 486, loss = 0.50914824
Iteration 487, loss = 0.50676830
Iteration 488, loss = 0.50762879
Iteration 489, loss = 0.50808102
Iteration 490, loss = 0.50856463
Iteration 491, loss = 0.50729820
Iteration 492, loss = 0.50715706
Iteration 493, loss = 0.50971926
Iteration 494, loss = 0.50923765
Iteration 495, loss = 0.50783856
Iteration 496, loss = 0.50982256
Iteration 497, loss = 0.50804185
Iteration 498, loss = 0.50873403
Iteration 499, loss = 0.50775292
Iteration 500, loss = 0.50757658
Iteration 501, loss = 0.50819506
Iteration 502, loss = 0.50767791
Iteration 503, loss = 0.50744732
Iteration 504, loss = 0.50844445
Iteration 505, loss = 0.50705167
Iteration 506, loss = 0.50638505
Iteration 507, loss = 0.50943115
Iteration 508, loss = 0.50657675
Iteration 509, loss = 0.50629178
Iteration 510, loss = 0.50729305
Iteration 511, loss = 0.50800894
Iteration 512, loss = 0.50611104
Iteration 513, loss = 0.50638213
Iteration 514, loss = 0.50561835
Iteration 515, loss = 0.50626406
Iteration 516, loss = 0.50759510
Iteration 517, loss = 0.50830491
Iteration 518, loss = 0.50599459
Iteration 519, loss = 0.50571347
Iteration 520, loss = 0.50591692
Iteration 521, loss = 0.50852156
Iteration 522, loss = 0.50694784
Iteration 523, loss = 0.50616236
Iteration 524, loss = 0.50834961
Iteration 525, loss = 0.50610318
Iteration 526, loss = 0.50513263
Iteration 527, loss = 0.50649373
Iteration 528, loss = 0.50772024
Iteration 529, loss = 0.50589960
Iteration 530, loss = 0.50761711
Iteration 531, loss = 0.50734481
Iteration 532, loss = 0.50540737
Iteration 533, loss = 0.50621837
Iteration 534, loss = 0.50769877
Iteration 535, loss = 0.50704110
Iteration 536, loss = 0.50524169
Iteration 537, loss = 0.50426611
Iteration 538, loss = 0.50569857
Iteration 539, loss = 0.50562664
Iteration 540, loss = 0.50696757
Iteration 541, loss = 0.50657412
Iteration 542, loss = 0.50660925
Iteration 543, loss = 0.50587442
Iteration 544, loss = 0.50538422
Iteration 545, loss = 0.50542879
Iteration 546, loss = 0.50461474
Iteration 547, loss = 0.50626738
Iteration 548, loss = 0.50488831
Iteration 549, loss = 0.50478384
Iteration 550, loss = 0.50684299
Iteration 551, loss = 0.50664573
Iteration 552, loss = 0.50669393
Iteration 553, loss = 0.50720296
Iteration 554, loss = 0.50735450
Iteration 555, loss = 0.51000872
Iteration 556, loss = 0.50618706
Iteration 557, loss = 0.50578129
Iteration 558, loss = 0.50630374
Iteration 559, loss = 0.50680031
Iteration 560, loss = 0.50671665
Iteration 561, loss = 0.50285741
Iteration 562, loss = 0.50422445
Iteration 563, loss = 0.50556961
Iteration 564, loss = 0.50598832
Iteration 565, loss = 0.50733839
Iteration 566, loss = 0.50609971
Iteration 567, loss = 0.50848077
Iteration 568, loss = 0.50885567
Iteration 569, loss = 0.50605289
Iteration 570, loss = 0.50453058
Iteration 571, loss = 0.50541082
Iteration 572, loss = 0.50674485
Iteration 573, loss = 0.50411364
Iteration 574, loss = 0.50636514
Iteration 575, loss = 0.50583646
Iteration 576, loss = 0.50523590
Iteration 577, loss = 0.50426610
Iteration 578, loss = 0.50525656
Iteration 579, loss = 0.50641548
Iteration 580, loss = 0.50632291
Iteration 581, loss = 0.50528278
Iteration 582, loss = 0.50576567
Iteration 583, loss = 0.50478242
Iteration 584, loss = 0.50599607
Iteration 585, loss = 0.50764691
Iteration 586, loss = 0.50475183
Iteration 587, loss = 0.50441681
Iteration 588, loss = 0.50599775
Iteration 589, loss = 0.50531300
Iteration 590, loss = 0.50837737
Iteration 591, loss = 0.50424158
Iteration 592, loss = 0.50390000
Iteration 593, loss = 0.50184485
Iteration 594, loss = 0.50551747
Iteration 595, loss = 0.50581904
Iteration 596, loss = 0.50558080
Iteration 597, loss = 0.50554016
Iteration 598, loss = 0.50367082
Iteration 599, loss = 0.50496333
Iteration 600, loss = 0.50275362
Iteration 601, loss = 0.50495857
Iteration 602, loss = 0.50722880
Iteration 603, loss = 0.50542908
Iteration 604, loss = 0.50491862
Iteration 605, loss = 0.50545303
Iteration 606, loss = 0.50374341
Iteration 607, loss = 0.50308030
Iteration 608, loss = 0.50453337
Iteration 609, loss = 0.50386585
Iteration 610, loss = 0.50347806
Iteration 611, loss = 0.50310144
Iteration 612, loss = 0.50497739
Iteration 613, loss = 0.50428242
Iteration 614, loss = 0.50294646
Iteration 615, loss = 0.50226656
Iteration 616, loss = 0.50425913
Iteration 617, loss = 0.50403957
Iteration 618, loss = 0.50406460
Iteration 619, loss = 0.50575942
Iteration 620, loss = 0.50308535
Iteration 621, loss = 0.50311849
Iteration 622, loss = 0.50257364
Iteration 623, loss = 0.50330541
Iteration 624, loss = 0.50425477
Iteration 625, loss = 0.50477617
Iteration 626, loss = 0.50407155
Iteration 627, loss = 0.50502106
Iteration 628, loss = 0.50395951
Iteration 629, loss = 0.50301064
Iteration 630, loss = 0.50494725
Iteration 631, loss = 0.50362200
Iteration 632, loss = 0.50323651
Iteration 633, loss = 0.50479986
Iteration 634, loss = 0.50400796
Iteration 635, loss = 0.50602381
Iteration 636, loss = 0.50463762
Iteration 637, loss = 0.50370651
Iteration 638, loss = 0.50255162
Iteration 639, loss = 0.50308868
Iteration 640, loss = 0.50129116
Iteration 641, loss = 0.50503313
Iteration 642, loss = 0.50224608
Iteration 643, loss = 0.50343359
Iteration 644, loss = 0.50574968
Iteration 645, loss = 0.50492800
Iteration 646, loss = 0.50471548
Iteration 647, loss = 0.50386705
Iteration 648, loss = 0.50360042
Iteration 649, loss = 0.50353905
Iteration 650, loss = 0.50308385
Iteration 651, loss = 0.50303785
Iteration 652, loss = 0.50428764
Iteration 653, loss = 0.50495541
Iteration 654, loss = 0.50258084
Iteration 655, loss = 0.50385191
Iteration 656, loss = 0.50301755
Iteration 657, loss = 0.50474212
Iteration 658, loss = 0.50259506
Iteration 659, loss = 0.50264396
Iteration 660, loss = 0.50404348
Iteration 661, loss = 0.50127404
Iteration 662, loss = 0.50099986
Iteration 663, loss = 0.50232183
Iteration 664, loss = 0.50242315
Iteration 665, loss = 0.50082944
Iteration 666, loss = 0.50164910
Iteration 667, loss = 0.50618340
Iteration 668, loss = 0.50500192
Iteration 669, loss = 0.50282778
Iteration 670, loss = 0.50092535
Iteration 671, loss = 0.50283112
Iteration 672, loss = 0.50467687
Iteration 673, loss = 0.50305801
Iteration 674, loss = 0.50346242
Iteration 675, loss = 0.50310575
Iteration 676, loss = 0.50461269
Iteration 677, loss = 0.50049038
Iteration 678, loss = 0.50361091
Iteration 679, loss = 0.50117350
Iteration 680, loss = 0.50322424
Iteration 681, loss = 0.50301554
Iteration 682, loss = 0.50378946
Iteration 683, loss = 0.50182655
Iteration 684, loss = 0.50214217
Iteration 685, loss = 0.50312168
Iteration 686, loss = 0.50255999
Iteration 687, loss = 0.50241280
Iteration 688, loss = 0.50160555
Iteration 689, loss = 0.50208416
Iteration 690, loss = 0.50244703
Iteration 691, loss = 0.50169445
Iteration 692, loss = 0.50206456
Iteration 693, loss = 0.50271098
Iteration 694, loss = 0.50075927
Iteration 695, loss = 0.50179302
Iteration 696, loss = 0.50181112
Iteration 697, loss = 0.50157487
Iteration 698, loss = 0.50222911
Iteration 699, loss = 0.50221296
Iteration 700, loss = 0.50322735
Iteration 701, loss = 0.50323776
Iteration 702, loss = 0.50414037
Iteration 703, loss = 0.50553931
Iteration 704, loss = 0.50222177
Iteration 705, loss = 0.50543018
Iteration 706, loss = 0.50354987
Iteration 707, loss = 0.50473416
Iteration 708, loss = 0.50437258
Iteration 709, loss = 0.50207642
Iteration 710, loss = 0.50160006
Iteration 711, loss = 0.50147296
Iteration 712, loss = 0.50115853
Iteration 713, loss = 0.49970737
Iteration 714, loss = 0.50091107
Iteration 715, loss = 0.49933146
Iteration 716, loss = 0.50121521
Iteration 717, loss = 0.50163568
Iteration 718, loss = 0.50086785
Iteration 719, loss = 0.50176150
Iteration 720, loss = 0.50125091
Iteration 721, loss = 0.50266123
Iteration 722, loss = 0.50315601
Iteration 723, loss = 0.50210163
Iteration 724, loss = 0.50052109
Iteration 725, loss = 0.50577200
Iteration 726, loss = 0.50211686
Iteration 727, loss = 0.50371464
Iteration 728, loss = 0.50577497
Iteration 729, loss = 0.50232755
Iteration 730, loss = 0.50152876
Iteration 731, loss = 0.50088620
Iteration 732, loss = 0.50012356
Iteration 733, loss = 0.50107784
Iteration 734, loss = 0.50034473
Iteration 735, loss = 0.50010335
Iteration 736, loss = 0.50142547
Iteration 737, loss = 0.50118140
Iteration 738, loss = 0.50083692
Iteration 739, loss = 0.50221114
Iteration 740, loss = 0.50117512
Iteration 741, loss = 0.50052752
Iteration 742, loss = 0.50191023
Iteration 743, loss = 0.49920513
Iteration 744, loss = 0.50157723
Iteration 745, loss = 0.50002646
Iteration 746, loss = 0.50012397
Iteration 747, loss = 0.50239016
Iteration 748, loss = 0.49896206
Iteration 749, loss = 0.50110332
Iteration 750, loss = 0.50063234
Iteration 751, loss = 0.50016570
Iteration 752, loss = 0.49988024
Iteration 753, loss = 0.50216252
Iteration 754, loss = 0.50088496
Iteration 755, loss = 0.50060376
Iteration 756, loss = 0.50240332
Iteration 757, loss = 0.49965059
Iteration 758, loss = 0.49870672
Iteration 759, loss = 0.50107021
Iteration 760, loss = 0.50102057
Iteration 761, loss = 0.50338926
Iteration 762, loss = 0.50030570
Iteration 763, loss = 0.50143841
Iteration 764, loss = 0.50362671
Iteration 765, loss = 0.50072888
Iteration 766, loss = 0.49933263
Iteration 767, loss = 0.49947300
Iteration 768, loss = 0.50165410
Iteration 769, loss = 0.50010211
Iteration 770, loss = 0.50201113
Iteration 771, loss = 0.50274095
Iteration 772, loss = 0.49941160
Iteration 773, loss = 0.49990964
Iteration 774, loss = 0.50062858
Iteration 775, loss = 0.50133969
Iteration 776, loss = 0.50061327
Iteration 777, loss = 0.50117119
Iteration 778, loss = 0.49932061
Iteration 779, loss = 0.49997479
Iteration 780, loss = 0.50387349
Iteration 781, loss = 0.50106261
Iteration 782, loss = 0.50302456
Iteration 783, loss = 0.50119801
Iteration 784, loss = 0.49943899
Iteration 785, loss = 0.49927541
Iteration 786, loss = 0.49954162
Iteration 787, loss = 0.49757334
Iteration 788, loss = 0.49983008
Iteration 789, loss = 0.49886838
Iteration 790, loss = 0.50040171
Iteration 791, loss = 0.49887633
Iteration 792, loss = 0.49915257
Iteration 793, loss = 0.49905861
Iteration 794, loss = 0.50069125
Iteration 795, loss = 0.49836507
Iteration 796, loss = 0.49999961
Iteration 797, loss = 0.50175552
Iteration 798, loss = 0.50084859
Iteration 799, loss = 0.49982125
Iteration 800, loss = 0.49966642
Iteration 801, loss = 0.49969963
Iteration 802, loss = 0.50371804
Iteration 803, loss = 0.49957230
Iteration 804, loss = 0.49880114
Iteration 805, loss = 0.49962438
Iteration 806, loss = 0.50083402
Iteration 807, loss = 0.49981362
Iteration 808, loss = 0.50121728
Iteration 809, loss = 0.49975622
Iteration 810, loss = 0.49990905
Iteration 811, loss = 0.49980924
Iteration 812, loss = 0.49953414
Iteration 813, loss = 0.49847184
Iteration 814, loss = 0.50048847
Iteration 815, loss = 0.50089995
Iteration 816, loss = 0.50104662
Iteration 817, loss = 0.50044985
Iteration 818, loss = 0.49898639
Iteration 819, loss = 0.49982708
Iteration 820, loss = 0.49927489
Iteration 821, loss = 0.50019152
Iteration 822, loss = 0.50069244
Iteration 823, loss = 0.49786556
Iteration 824, loss = 0.50082155
Iteration 825, loss = 0.50240411
Iteration 826, loss = 0.50243235
Iteration 827, loss = 0.49975901
Iteration 828, loss = 0.49825977
Iteration 829, loss = 0.49825442
Iteration 830, loss = 0.49896074
Iteration 831, loss = 0.49956043
Iteration 832, loss = 0.50022306
Iteration 833, loss = 0.49921162
Iteration 834, loss = 0.49827711
Iteration 835, loss = 0.49795700
Iteration 836, loss = 0.50043160
Iteration 837, loss = 0.49885574
Iteration 838, loss = 0.49999308
Iteration 839, loss = 0.49921108
Iteration 840, loss = 0.49918632
Iteration 841, loss = 0.49885360
Iteration 842, loss = 0.50038621
Iteration 843, loss = 0.49825637
Iteration 844, loss = 0.49949175
Iteration 845, loss = 0.49849472
Iteration 846, loss = 0.49872534
Iteration 847, loss = 0.49845190
Iteration 848, loss = 0.50211949
Iteration 849, loss = 0.49836959
Iteration 850, loss = 0.49674935
Iteration 851, loss = 0.49805059
Iteration 852, loss = 0.49762783
Iteration 853, loss = 0.49964533
Iteration 854, loss = 0.50018522
Iteration 855, loss = 0.49828968
Iteration 856, loss = 0.49942601
Iteration 857, loss = 0.50052043
Iteration 858, loss = 0.49836770
Iteration 859, loss = 0.50070203
Iteration 860, loss = 0.50205127
Iteration 861, loss = 0.49753747
Iteration 862, loss = 0.49948410
Iteration 863, loss = 0.50163800
Iteration 864, loss = 0.49794530
Iteration 865, loss = 0.50115938
Iteration 866, loss = 0.49869331
Iteration 867, loss = 0.50068824
Iteration 868, loss = 0.49795912
Iteration 869, loss = 0.49768068
Iteration 870, loss = 0.50060036
Iteration 871, loss = 0.49782663
Iteration 872, loss = 0.50035029
Iteration 873, loss = 0.50120623
Iteration 874, loss = 0.50403683
Iteration 875, loss = 0.49872376
Iteration 876, loss = 0.49855683
Iteration 877, loss = 0.49822981
Iteration 878, loss = 0.49624773
Iteration 879, loss = 0.49818494
Iteration 880, loss = 0.50099514
Iteration 881, loss = 0.50020349
Iteration 882, loss = 0.49757161
Iteration 883, loss = 0.49833228
Iteration 884, loss = 0.49752348
Iteration 885, loss = 0.49725049
Iteration 886, loss = 0.49913602
Iteration 887, loss = 0.49915231
Iteration 888, loss = 0.49945289
Iteration 889, loss = 0.49742161
Iteration 890, loss = 0.49865920
Iteration 891, loss = 0.49768859
Iteration 892, loss = 0.49859467
Iteration 893, loss = 0.49923881
Iteration 894, loss = 0.49744275
Iteration 895, loss = 0.49792003
Iteration 896, loss = 0.50031896
Iteration 897, loss = 0.49661277
Iteration 898, loss = 0.49684114
Iteration 899, loss = 0.49746613
Iteration 900, loss = 0.49787825
Iteration 901, loss = 0.49743960
Iteration 902, loss = 0.49956300
Iteration 903, loss = 0.49850483
Iteration 904, loss = 0.49669017
Iteration 905, loss = 0.49676471
Iteration 906, loss = 0.49854436
Iteration 907, loss = 0.50005551
Iteration 908, loss = 0.49655247
Iteration 909, loss = 0.49727066
Iteration 910, loss = 0.49650762
Iteration 911, loss = 0.49832289
Iteration 912, loss = 0.49776465
Iteration 913, loss = 0.49694027
Iteration 914, loss = 0.49810930
Iteration 915, loss = 0.49727666
Iteration 916, loss = 0.49960444
Iteration 917, loss = 0.49827005
Iteration 918, loss = 0.49858677
Iteration 919, loss = 0.49748266
Iteration 920, loss = 0.49706877
Iteration 921, loss = 0.49970887
Iteration 922, loss = 0.49695180
Iteration 923, loss = 0.49795972
Iteration 924, loss = 0.49604153
Iteration 925, loss = 0.50004868
Iteration 926, loss = 0.50058864
Iteration 927, loss = 0.49778906
Iteration 928, loss = 0.49640355
Iteration 929, loss = 0.49738656
Iteration 930, loss = 0.49790287
Iteration 931, loss = 0.49598988
Iteration 932, loss = 0.49639246
Iteration 933, loss = 0.49556101
Iteration 934, loss = 0.49850409
Iteration 935, loss = 0.49814483
Iteration 936, loss = 0.49823897
Iteration 937, loss = 0.49813552
Iteration 938, loss = 0.49634198
Iteration 939, loss = 0.49701567
Iteration 940, loss = 0.49806816
Iteration 941, loss = 0.50004339
Iteration 942, loss = 0.49808341
Iteration 943, loss = 0.49729082
Iteration 944, loss = 0.49856590
Iteration 945, loss = 0.49892463
Iteration 946, loss = 0.49707380
Iteration 947, loss = 0.50132514
Iteration 948, loss = 0.49662621
Iteration 949, loss = 0.49998438
Iteration 950, loss = 0.49795826
Iteration 951, loss = 0.49756760
Iteration 952, loss = 0.49749264
Iteration 953, loss = 0.50075785
Iteration 954, loss = 0.49967414
Iteration 955, loss = 0.49862920
Iteration 956, loss = 0.49636695
Iteration 957, loss = 0.49876649
Iteration 958, loss = 0.49955268
Iteration 959, loss = 0.49637219
Iteration 960, loss = 0.49898910
Iteration 961, loss = 0.49687213
Iteration 962, loss = 0.49630317
Iteration 963, loss = 0.49606811
Iteration 964, loss = 0.49690058
Iteration 965, loss = 0.49500340
Iteration 966, loss = 0.49557157
Iteration 967, loss = 0.49690410
Iteration 968, loss = 0.49866028
Iteration 969, loss = 0.49821493
Iteration 970, loss = 0.49669383
Iteration 971, loss = 0.49749708
Iteration 972, loss = 0.49632105
Iteration 973, loss = 0.49641438
Iteration 974, loss = 0.50073684
Iteration 975, loss = 0.49607916
Iteration 976, loss = 0.50468232
Iteration 977, loss = 0.50174249
Iteration 978, loss = 0.49726717
Iteration 979, loss = 0.49739037
Iteration 980, loss = 0.49463453
Iteration 981, loss = 0.49719214
Iteration 982, loss = 0.49618757
Iteration 983, loss = 0.50145632
Iteration 984, loss = 0.50051205
Iteration 985, loss = 0.50009857
Iteration 986, loss = 0.49642233
Iteration 987, loss = 0.49603734
Iteration 988, loss = 0.49560488
Iteration 989, loss = 0.49614044
Iteration 990, loss = 0.49627999
Iteration 991, loss = 0.49543490
Iteration 992, loss = 0.49706559
Iteration 993, loss = 0.49760323
Iteration 994, loss = 0.49632704
Iteration 995, loss = 0.49755260
Iteration 996, loss = 0.49585875
Iteration 997, loss = 0.49694759
Iteration 998, loss = 0.49817560
Iteration 999, loss = 0.49678884
Iteration 1000, loss = 0.49629061
Iteration 1001, loss = 0.49531275
Iteration 1002, loss = 0.49671857
Iteration 1003, loss = 0.49774404
Iteration 1004, loss = 0.49485984
Iteration 1005, loss = 0.49531217
Iteration 1006, loss = 0.49567255
Iteration 1007, loss = 0.49686449
Iteration 1008, loss = 0.49604232
Iteration 1009, loss = 0.49568808
Iteration 1010, loss = 0.49637256
Iteration 1011, loss = 0.49796456
Iteration 1012, loss = 0.49606060
Iteration 1013, loss = 0.49594999
Iteration 1014, loss = 0.49868902
Iteration 1015, loss = 0.49843427
Iteration 1016, loss = 0.49645491
Iteration 1017, loss = 0.49562492
Iteration 1018, loss = 0.49884645
Iteration 1019, loss = 0.49488355
Iteration 1020, loss = 0.49596005
Iteration 1021, loss = 0.49515472
Iteration 1022, loss = 0.49418272
Iteration 1023, loss = 0.49493034
Iteration 1024, loss = 0.49446808
Iteration 1025, loss = 0.49653998
Iteration 1026, loss = 0.49417371
Iteration 1027, loss = 0.49613222
Iteration 1028, loss = 0.49650764
Iteration 1029, loss = 0.49629876
Iteration 1030, loss = 0.49559090
Iteration 1031, loss = 0.49547312
Iteration 1032, loss = 0.49890738
Iteration 1033, loss = 0.49598659
Iteration 1034, loss = 0.49658708
Iteration 1035, loss = 0.49528564
Iteration 1036, loss = 0.49669924
Iteration 1037, loss = 0.49798392
Iteration 1038, loss = 0.49566832
Iteration 1039, loss = 0.49420706
Iteration 1040, loss = 0.49502326
Iteration 1041, loss = 0.49773917
Iteration 1042, loss = 0.49708096
Iteration 1043, loss = 0.49498227
Iteration 1044, loss = 0.49729946
Iteration 1045, loss = 0.49913456
Iteration 1046, loss = 0.49502184
Iteration 1047, loss = 0.49466011
Iteration 1048, loss = 0.49545177
Iteration 1049, loss = 0.49517742
Iteration 1050, loss = 0.49491402
Iteration 1051, loss = 0.49944888
Iteration 1052, loss = 0.49777100
Iteration 1053, loss = 0.49606028
Iteration 1054, loss = 0.49495070
Iteration 1055, loss = 0.49819149
Iteration 1056, loss = 0.49892496
Iteration 1057, loss = 0.49403377
Iteration 1058, loss = 0.49794801
Iteration 1059, loss = 0.49455895
Iteration 1060, loss = 0.49510477
Iteration 1061, loss = 0.49382456
Iteration 1062, loss = 0.49389482
Iteration 1063, loss = 0.49461570
Iteration 1064, loss = 0.49386072
Iteration 1065, loss = 0.49410484
Iteration 1066, loss = 0.49547825
Iteration 1067, loss = 0.49607217
Iteration 1068, loss = 0.49474010
Iteration 1069, loss = 0.49748093
Iteration 1070, loss = 0.49715236
Iteration 1071, loss = 0.50250979
Iteration 1072, loss = 0.49616671
Iteration 1073, loss = 0.49354755
Iteration 1074, loss = 0.49508188
Iteration 1075, loss = 0.49530577
Iteration 1076, loss = 0.49710189
Iteration 1077, loss = 0.49499580
Iteration 1078, loss = 0.49486851
Iteration 1079, loss = 0.49686395
Iteration 1080, loss = 0.49354946
Iteration 1081, loss = 0.49521030
Iteration 1082, loss = 0.49597874
Iteration 1083, loss = 0.49467598
Iteration 1084, loss = 0.49558609
Iteration 1085, loss = 0.49486187
Iteration 1086, loss = 0.49561988
Iteration 1087, loss = 0.49678853
Iteration 1088, loss = 0.49483893
Iteration 1089, loss = 0.49430656
Iteration 1090, loss = 0.49575195
Iteration 1091, loss = 0.49411725
Iteration 1092, loss = 0.49474212
Iteration 1093, loss = 0.49485012
Iteration 1094, loss = 0.49531740
Iteration 1095, loss = 0.49541312
Iteration 1096, loss = 0.49413167
Iteration 1097, loss = 0.49607900
Iteration 1098, loss = 0.49493356
Iteration 1099, loss = 0.49397083
Iteration 1100, loss = 0.49530908
Iteration 1101, loss = 0.49807569
Iteration 1102, loss = 0.49447387
Iteration 1103, loss = 0.49359194
Iteration 1104, loss = 0.49461861
Iteration 1105, loss = 0.49878000
Iteration 1106, loss = 0.49551757
Iteration 1107, loss = 0.49320187
Iteration 1108, loss = 0.49411351
Iteration 1109, loss = 0.49369000
Iteration 1110, loss = 0.49636640
Iteration 1111, loss = 0.49440514
Iteration 1112, loss = 0.49484277
Iteration 1113, loss = 0.49553217
Iteration 1114, loss = 0.49503549
Iteration 1115, loss = 0.49589153
Iteration 1116, loss = 0.49318066
Iteration 1117, loss = 0.49470907
Iteration 1118, loss = 0.49402072
Iteration 1119, loss = 0.49897643
Iteration 1120, loss = 0.49583781
Iteration 1121, loss = 0.49384094
Iteration 1122, loss = 0.49429588
Iteration 1123, loss = 0.49504545
Iteration 1124, loss = 0.49459081
Iteration 1125, loss = 0.49322112
Iteration 1126, loss = 0.49663394
Iteration 1127, loss = 0.49502472
Iteration 1128, loss = 0.49471045
Iteration 1129, loss = 0.49493676
Iteration 1130, loss = 0.49616291
Iteration 1131, loss = 0.49567058
Iteration 1132, loss = 0.49373660
Iteration 1133, loss = 0.49308804
Iteration 1134, loss = 0.49405555
Iteration 1135, loss = 0.49282482
Iteration 1136, loss = 0.49617031
Iteration 1137, loss = 0.49437610
Iteration 1138, loss = 0.49313473
Iteration 1139, loss = 0.49297124
Iteration 1140, loss = 0.49355954
Iteration 1141, loss = 0.49573684
Iteration 1142, loss = 0.49446524
Iteration 1143, loss = 0.49418357
Iteration 1144, loss = 0.49493814
Iteration 1145, loss = 0.49510629
Iteration 1146, loss = 0.49334238
Iteration 1147, loss = 0.49598530
Iteration 1148, loss = 0.49358423
Iteration 1149, loss = 0.49274499
Iteration 1150, loss = 0.49603635
Iteration 1151, loss = 0.49303860
Iteration 1152, loss = 0.49433325
Iteration 1153, loss = 0.49210309
Iteration 1154, loss = 0.49355569
Iteration 1155, loss = 0.49723834
Iteration 1156, loss = 0.49527597
Iteration 1157, loss = 0.49537606
Iteration 1158, loss = 0.49349057
Iteration 1159, loss = 0.49526309
Iteration 1160, loss = 0.49416182
Iteration 1161, loss = 0.49348341
Iteration 1162, loss = 0.49456063
Iteration 1163, loss = 0.49336771
Iteration 1164, loss = 0.49495347
Iteration 1165, loss = 0.49369295
Iteration 1166, loss = 0.49392810
Iteration 1167, loss = 0.49556328
Iteration 1168, loss = 0.49333353
Iteration 1169, loss = 0.49287760
Iteration 1170, loss = 0.49375957
Iteration 1171, loss = 0.49267452
Iteration 1172, loss = 0.49295644
Iteration 1173, loss = 0.49398218
Iteration 1174, loss = 0.49635115
Iteration 1175, loss = 0.49437494
Iteration 1176, loss = 0.49403762
Iteration 1177, loss = 0.49342400
Iteration 1178, loss = 0.49870777
Iteration 1179, loss = 0.49473302
Iteration 1180, loss = 0.49394155
Iteration 1181, loss = 0.49335883
Iteration 1182, loss = 0.49291790
Iteration 1183, loss = 0.49519592
Iteration 1184, loss = 0.49289972
Iteration 1185, loss = 0.49292083
Iteration 1186, loss = 0.49540400
Iteration 1187, loss = 0.49443749
Iteration 1188, loss = 0.50029307
Iteration 1189, loss = 0.50211632
Iteration 1190, loss = 0.49373367
Iteration 1191, loss = 0.49229270
Iteration 1192, loss = 0.49274959
Iteration 1193, loss = 0.49188681
Iteration 1194, loss = 0.49353773
Iteration 1195, loss = 0.49197788
Iteration 1196, loss = 0.49348060
Iteration 1197, loss = 0.49432830
Iteration 1198, loss = 0.49329718
Iteration 1199, loss = 0.49438779
Iteration 1200, loss = 0.49354799
Iteration 1201, loss = 0.49249577
Iteration 1202, loss = 0.49192132
Iteration 1203, loss = 0.49455799
Iteration 1204, loss = 0.49634897
Iteration 1205, loss = 0.49355722
Iteration 1206, loss = 0.49323206
Iteration 1207, loss = 0.49370420
Iteration 1208, loss = 0.49278692
Iteration 1209, loss = 0.49710537
Iteration 1210, loss = 0.49219353
Iteration 1211, loss = 0.49043289
Iteration 1212, loss = 0.49152298
Iteration 1213, loss = 0.49605111
Iteration 1214, loss = 0.49265949
Iteration 1215, loss = 0.49432041
Iteration 1216, loss = 0.49368545
Iteration 1217, loss = 0.49214000
Iteration 1218, loss = 0.49284528
Iteration 1219, loss = 0.49285992
Iteration 1220, loss = 0.49456354
Iteration 1221, loss = 0.49665634
Iteration 1222, loss = 0.49427864
Iteration 1223, loss = 0.49734497
Iteration 1224, loss = 0.49529229
Iteration 1225, loss = 0.49536589
Iteration 1226, loss = 0.49138242
Iteration 1227, loss = 0.49296491
Iteration 1228, loss = 0.49665204
Iteration 1229, loss = 0.49354667
Iteration 1230, loss = 0.49318744
Iteration 1231, loss = 0.49339670
Iteration 1232, loss = 0.49218261
Iteration 1233, loss = 0.49253782
Iteration 1234, loss = 0.49180862
Iteration 1235, loss = 0.49272874
Iteration 1236, loss = 0.49206149
Iteration 1237, loss = 0.49318132
Iteration 1238, loss = 0.49241695
Iteration 1239, loss = 0.49563862
Iteration 1240, loss = 0.49309901
Iteration 1241, loss = 0.49526509
Iteration 1242, loss = 0.49197717
Iteration 1243, loss = 0.49229444
Iteration 1244, loss = 0.49130322
Iteration 1245, loss = 0.49307309
Iteration 1246, loss = 0.49156560
Iteration 1247, loss = 0.49448930
Iteration 1248, loss = 0.49544452
Iteration 1249, loss = 0.49347656
Iteration 1250, loss = 0.49768034
Iteration 1251, loss = 0.49223011
Iteration 1252, loss = 0.49271027
Iteration 1253, loss = 0.49452984
Iteration 1254, loss = 0.49279438
Iteration 1255, loss = 0.49578092
Iteration 1256, loss = 0.49187220
Iteration 1257, loss = 0.49300874
Iteration 1258, loss = 0.49345659
Iteration 1259, loss = 0.49243590
Iteration 1260, loss = 0.49071499
Iteration 1261, loss = 0.49282406
Iteration 1262, loss = 0.49278220
Iteration 1263, loss = 0.49344803
Iteration 1264, loss = 0.49250620
Iteration 1265, loss = 0.49324218
Iteration 1266, loss = 0.49217279
Iteration 1267, loss = 0.49191481
Iteration 1268, loss = 0.49261075
Iteration 1269, loss = 0.49271401
Iteration 1270, loss = 0.49118156
Iteration 1271, loss = 0.49214425
Iteration 1272, loss = 0.49292843
Iteration 1273, loss = 0.50213765
Iteration 1274, loss = 0.49476784
Iteration 1275, loss = 0.49561983
Iteration 1276, loss = 0.49351252
Iteration 1277, loss = 0.49258052
Iteration 1278, loss = 0.49566436
Iteration 1279, loss = 0.49672225
Iteration 1280, loss = 0.49571648
Iteration 1281, loss = 0.49138778
Iteration 1282, loss = 0.49224036
Iteration 1283, loss = 0.49311960
Iteration 1284, loss = 0.49248232
Iteration 1285, loss = 0.49168032
Iteration 1286, loss = 0.49267650
Iteration 1287, loss = 0.49158934
Iteration 1288, loss = 0.49183571
Iteration 1289, loss = 0.49409296
Iteration 1290, loss = 0.49544884
Iteration 1291, loss = 0.49588388
Iteration 1292, loss = 0.49273726
Iteration 1293, loss = 0.49637880
Iteration 1294, loss = 0.49248543
Iteration 1295, loss = 0.49342009
Iteration 1296, loss = 0.49336663
Iteration 1297, loss = 0.49055556
Iteration 1298, loss = 0.49212653
Iteration 1299, loss = 0.49164748
Iteration 1300, loss = 0.49216193
Iteration 1301, loss = 0.49408638
Iteration 1302, loss = 0.49151650
Iteration 1303, loss = 0.49397158
Iteration 1304, loss = 0.49459051
Iteration 1305, loss = 0.49836609
Iteration 1306, loss = 0.49390240
Iteration 1307, loss = 0.49368330
Iteration 1308, loss = 0.49095632
Iteration 1309, loss = 0.49170976
Iteration 1310, loss = 0.49531367
Iteration 1311, loss = 0.49129952
Iteration 1312, loss = 0.49107884
Iteration 1313, loss = 0.49157923
Iteration 1314, loss = 0.49111828
Iteration 1315, loss = 0.49268001
Iteration 1316, loss = 0.49251621
Iteration 1317, loss = 0.49232744
Iteration 1318, loss = 0.49391269
Iteration 1319, loss = 0.49128633
Iteration 1320, loss = 0.49304458
Iteration 1321, loss = 0.49230736
Iteration 1322, loss = 0.49148103
Iteration 1323, loss = 0.49081847
Iteration 1324, loss = 0.49214025
Iteration 1325, loss = 0.49080598
Iteration 1326, loss = 0.49115533
Iteration 1327, loss = 0.49308372
Iteration 1328, loss = 0.49266063
Iteration 1329, loss = 0.49152163
Iteration 1330, loss = 0.49691174
Iteration 1331, loss = 0.49294988
Iteration 1332, loss = 0.49475951
Iteration 1333, loss = 0.49200021
Iteration 1334, loss = 0.49256128
Iteration 1335, loss = 0.49082455
Iteration 1336, loss = 0.49008183
Iteration 1337, loss = 0.49323227
Iteration 1338, loss = 0.49379084
Iteration 1339, loss = 0.49206214
Iteration 1340, loss = 0.48897968
Iteration 1341, loss = 0.49246033
Iteration 1342, loss = 0.49292322
Iteration 1343, loss = 0.49287867
Iteration 1344, loss = 0.49404917
Iteration 1345, loss = 0.49325561
Iteration 1346, loss = 0.49273652
Iteration 1347, loss = 0.49308914
Iteration 1348, loss = 0.49406339
Iteration 1349, loss = 0.49097397
Iteration 1350, loss = 0.49151997
Iteration 1351, loss = 0.49075023
Iteration 1352, loss = 0.49013220
Iteration 1353, loss = 0.49277683
Iteration 1354, loss = 0.48894133
Iteration 1355, loss = 0.49017934
Iteration 1356, loss = 0.49045542
Iteration 1357, loss = 0.49447855
Iteration 1358, loss = 0.49085125
Iteration 1359, loss = 0.49191592
Iteration 1360, loss = 0.49311561
Iteration 1361, loss = 0.49047747
Iteration 1362, loss = 0.49318424
Iteration 1363, loss = 0.49120400
Iteration 1364, loss = 0.49205268
Iteration 1365, loss = 0.49310130
Iteration 1366, loss = 0.49076120
Iteration 1367, loss = 0.49130024
Iteration 1368, loss = 0.49102739
Iteration 1369, loss = 0.49276385
Iteration 1370, loss = 0.49097045
Iteration 1371, loss = 0.49002108
Iteration 1372, loss = 0.49015478
Iteration 1373, loss = 0.48959100
Iteration 1374, loss = 0.49287910
Iteration 1375, loss = 0.49114063
Iteration 1376, loss = 0.49414846
Iteration 1377, loss = 0.49001512
Iteration 1378, loss = 0.49558516
Iteration 1379, loss = 0.49118902
Iteration 1380, loss = 0.49141617
Iteration 1381, loss = 0.48903935
Iteration 1382, loss = 0.49080934
Iteration 1383, loss = 0.49380509
Iteration 1384, loss = 0.49189654
Iteration 1385, loss = 0.49188761
Iteration 1386, loss = 0.49755145
Iteration 1387, loss = 0.49543639
Iteration 1388, loss = 0.48998424
Iteration 1389, loss = 0.49521550
Iteration 1390, loss = 0.49186559
Iteration 1391, loss = 0.49205113
Iteration 1392, loss = 0.49417884
Iteration 1393, loss = 0.49133857
Iteration 1394, loss = 0.48958917
Iteration 1395, loss = 0.49231926
Iteration 1396, loss = 0.49099669
Iteration 1397, loss = 0.49006858
Iteration 1398, loss = 0.49181257
Iteration 1399, loss = 0.49119609
Iteration 1400, loss = 0.49131665
Iteration 1401, loss = 0.49089525
Iteration 1402, loss = 0.49112328
Iteration 1403, loss = 0.49180547
Iteration 1404, loss = 0.49110005
Iteration 1405, loss = 0.49054550
Iteration 1406, loss = 0.49082961
Iteration 1407, loss = 0.49019599
Iteration 1408, loss = 0.49291805
Iteration 1409, loss = 0.49018501
Iteration 1410, loss = 0.49079799
Iteration 1411, loss = 0.48968030
Iteration 1412, loss = 0.48997762
Iteration 1413, loss = 0.49027215
Iteration 1414, loss = 0.48964602
Iteration 1415, loss = 0.48906000
Iteration 1416, loss = 0.49016556
Iteration 1417, loss = 0.49058865
Iteration 1418, loss = 0.49023954
Iteration 1419, loss = 0.49169859
Iteration 1420, loss = 0.49324759
Iteration 1421, loss = 0.49166861
Iteration 1422, loss = 0.49116614
Iteration 1423, loss = 0.49103291
Iteration 1424, loss = 0.49074963
Iteration 1425, loss = 0.49199287
Iteration 1426, loss = 0.48932281
Iteration 1427, loss = 0.48863522
Iteration 1428, loss = 0.49024537
Iteration 1429, loss = 0.49127972
Iteration 1430, loss = 0.48932461
Iteration 1431, loss = 0.49043104
Iteration 1432, loss = 0.48923266
Iteration 1433, loss = 0.49117407
Iteration 1434, loss = 0.49003295
Iteration 1435, loss = 0.49116023
Iteration 1436, loss = 0.49131816
Iteration 1437, loss = 0.48958595
Iteration 1438, loss = 0.48916640
Iteration 1439, loss = 0.49030031
Iteration 1440, loss = 0.49359636
Iteration 1441, loss = 0.49192957
Iteration 1442, loss = 0.49397918
Iteration 1443, loss = 0.49117263
Iteration 1444, loss = 0.49230809
Iteration 1445, loss = 0.48727203
Iteration 1446, loss = 0.48992943
Iteration 1447, loss = 0.49045541
Iteration 1448, loss = 0.48996589
Iteration 1449, loss = 0.49166286
Iteration 1450, loss = 0.49341168
Iteration 1451, loss = 0.49246718
Iteration 1452, loss = 0.48921520
Iteration 1453, loss = 0.48963758
Iteration 1454, loss = 0.49162328
Iteration 1455, loss = 0.49175209
Iteration 1456, loss = 0.49047768
Iteration 1457, loss = 0.49132444
Iteration 1458, loss = 0.48948123
Iteration 1459, loss = 0.48947693
Iteration 1460, loss = 0.49333723
Iteration 1461, loss = 0.48871761
Iteration 1462, loss = 0.48941350
Iteration 1463, loss = 0.48878570
Iteration 1464, loss = 0.48882691
Iteration 1465, loss = 0.49289307
Iteration 1466, loss = 0.49060959
Iteration 1467, loss = 0.48775811
Iteration 1468, loss = 0.49051310
Iteration 1469, loss = 0.48957342
Iteration 1470, loss = 0.48891447
Iteration 1471, loss = 0.48918879
Iteration 1472, loss = 0.48906006
Iteration 1473, loss = 0.49236937
Iteration 1474, loss = 0.49005185
Iteration 1475, loss = 0.49104250
Iteration 1476, loss = 0.49037746
Iteration 1477, loss = 0.49002152
Iteration 1478, loss = 0.49169728
Iteration 1479, loss = 0.48903227
Iteration 1480, loss = 0.49207554
Iteration 1481, loss = 0.49067521
Iteration 1482, loss = 0.48973896
Iteration 1483, loss = 0.48760607
Iteration 1484, loss = 0.49366983
Iteration 1485, loss = 0.49309822
Iteration 1486, loss = 0.49050884
Iteration 1487, loss = 0.48850429
Iteration 1488, loss = 0.49144404
Iteration 1489, loss = 0.49336427
Iteration 1490, loss = 0.48938696
Iteration 1491, loss = 0.48982060
Iteration 1492, loss = 0.48919593
Iteration 1493, loss = 0.48897443
Iteration 1494, loss = 0.49179751
Iteration 1495, loss = 0.49137592
Iteration 1496, loss = 0.49270898
Iteration 1497, loss = 0.49200710
Iteration 1498, loss = 0.49237312
Iteration 1499, loss = 0.48767560
Iteration 1500, loss = 0.49043768
Iteration 1501, loss = 0.49055040
Iteration 1502, loss = 0.48881357
Iteration 1503, loss = 0.48757010
Iteration 1504, loss = 0.49116746
Iteration 1505, loss = 0.49036633
Iteration 1506, loss = 0.49029863
Iteration 1507, loss = 0.48908173
Iteration 1508, loss = 0.49008167
Iteration 1509, loss = 0.49033972
Iteration 1510, loss = 0.49438153
Iteration 1511, loss = 0.49080423
Iteration 1512, loss = 0.48848085
Iteration 1513, loss = 0.49140804
Iteration 1514, loss = 0.48868643
Iteration 1515, loss = 0.49000766
Iteration 1516, loss = 0.49046623
Iteration 1517, loss = 0.49053762
Iteration 1518, loss = 0.48993140
Iteration 1519, loss = 0.49101616
Iteration 1520, loss = 0.48859729
Iteration 1521, loss = 0.49155414
Iteration 1522, loss = 0.48866841
Iteration 1523, loss = 0.48939898
Iteration 1524, loss = 0.48768623
Iteration 1525, loss = 0.49091444
Iteration 1526, loss = 0.48809572
Iteration 1527, loss = 0.49012877
Iteration 1528, loss = 0.49303633
Iteration 1529, loss = 0.49421741
Iteration 1530, loss = 0.49091981
Iteration 1531, loss = 0.49026975
Iteration 1532, loss = 0.48857668
Iteration 1533, loss = 0.48807473
Iteration 1534, loss = 0.48724089
Iteration 1535, loss = 0.48727472
Iteration 1536, loss = 0.48818329
Iteration 1537, loss = 0.49008032
Iteration 1538, loss = 0.48805642
Iteration 1539, loss = 0.49287563
Iteration 1540, loss = 0.49464079
Iteration 1541, loss = 0.48917804
Iteration 1542, loss = 0.48774947
Iteration 1543, loss = 0.48939197
Iteration 1544, loss = 0.48750269
Iteration 1545, loss = 0.48853372
Iteration 1546, loss = 0.49063267
Iteration 1547, loss = 0.49403836
Iteration 1548, loss = 0.49304792
Iteration 1549, loss = 0.48928439
Iteration 1550, loss = 0.48830146
Iteration 1551, loss = 0.48802213
Iteration 1552, loss = 0.48653330
Iteration 1553, loss = 0.48896607
Iteration 1554, loss = 0.48925849
Iteration 1555, loss = 0.48934238
Iteration 1556, loss = 0.48885657
Iteration 1557, loss = 0.48860254
Iteration 1558, loss = 0.49093101
Iteration 1559, loss = 0.49195856
Iteration 1560, loss = 0.49369462
Iteration 1561, loss = 0.48802257
Iteration 1562, loss = 0.48975145
Iteration 1563, loss = 0.49124245
Iteration 1564, loss = 0.48840725
Iteration 1565, loss = 0.48775217
Iteration 1566, loss = 0.48934319
Iteration 1567, loss = 0.48888373
Iteration 1568, loss = 0.49213979
Iteration 1569, loss = 0.49262236
Iteration 1570, loss = 0.49198875
Iteration 1571, loss = 0.48824242
Iteration 1572, loss = 0.48719150
Iteration 1573, loss = 0.49150074
Iteration 1574, loss = 0.48746663
Iteration 1575, loss = 0.48806087
Iteration 1576, loss = 0.49197847
Iteration 1577, loss = 0.49128572
Iteration 1578, loss = 0.49075045
Iteration 1579, loss = 0.49187382
Iteration 1580, loss = 0.49008180
Iteration 1581, loss = 0.48863984
Iteration 1582, loss = 0.48716534
Iteration 1583, loss = 0.48795126
Iteration 1584, loss = 0.49142467
Iteration 1585, loss = 0.49248925
Iteration 1586, loss = 0.48688070
Iteration 1587, loss = 0.48976519
Iteration 1588, loss = 0.48937456
Iteration 1589, loss = 0.49045013
Iteration 1590, loss = 0.48982799
Iteration 1591, loss = 0.48827631
Iteration 1592, loss = 0.48898614
Iteration 1593, loss = 0.48888004
Iteration 1594, loss = 0.48887354
Iteration 1595, loss = 0.48767361
Iteration 1596, loss = 0.49024415
Iteration 1597, loss = 0.48750948
Iteration 1598, loss = 0.48859370
Iteration 1599, loss = 0.48961639
Iteration 1600, loss = 0.48945957
Iteration 1601, loss = 0.49015841
Iteration 1602, loss = 0.48847591
Iteration 1603, loss = 0.49071512
Iteration 1604, loss = 0.48782269
Iteration 1605, loss = 0.48964077
Iteration 1606, loss = 0.48992600
Iteration 1607, loss = 0.48767273
Iteration 1608, loss = 0.49466885
Iteration 1609, loss = 0.48839831
Iteration 1610, loss = 0.48894270
Iteration 1611, loss = 0.48755868
Iteration 1612, loss = 0.49175676
Iteration 1613, loss = 0.48927607
Iteration 1614, loss = 0.48776581
Iteration 1615, loss = 0.48961814
Iteration 1616, loss = 0.49234281
Iteration 1617, loss = 0.48763549
Iteration 1618, loss = 0.48673699
Iteration 1619, loss = 0.48712818
Iteration 1620, loss = 0.48808098
Iteration 1621, loss = 0.48895018
Iteration 1622, loss = 0.48966480
Iteration 1623, loss = 0.48745681
Iteration 1624, loss = 0.48883057
Iteration 1625, loss = 0.48747281
Iteration 1626, loss = 0.48669694
Iteration 1627, loss = 0.48605367
Iteration 1628, loss = 0.48826086
Iteration 1629, loss = 0.48613208
Iteration 1630, loss = 0.48736197
Iteration 1631, loss = 0.48762989
Iteration 1632, loss = 0.48789023
Iteration 1633, loss = 0.48900144
Iteration 1634, loss = 0.48728273
Iteration 1635, loss = 0.48756619
Iteration 1636, loss = 0.48808964
Iteration 1637, loss = 0.48795553
Iteration 1638, loss = 0.48914044
Iteration 1639, loss = 0.48915187
Iteration 1640, loss = 0.48910370
Iteration 1641, loss = 0.48816448
Iteration 1642, loss = 0.48963802
Iteration 1643, loss = 0.48942329
Iteration 1644, loss = 0.49115126
Iteration 1645, loss = 0.48806880
Iteration 1646, loss = 0.48828916
Iteration 1647, loss = 0.49288237
Iteration 1648, loss = 0.48736355
Iteration 1649, loss = 0.48605722
Iteration 1650, loss = 0.48788764
Iteration 1651, loss = 0.48757917
Iteration 1652, loss = 0.48825713
Iteration 1653, loss = 0.48802950
Iteration 1654, loss = 0.48581247
Iteration 1655, loss = 0.48760523
Iteration 1656, loss = 0.48943220
Iteration 1657, loss = 0.49015151
Iteration 1658, loss = 0.48842374
Iteration 1659, loss = 0.48814243
Iteration 1660, loss = 0.49079021
Iteration 1661, loss = 0.48619991
Iteration 1662, loss = 0.48768401
Iteration 1663, loss = 0.48832173
Iteration 1664, loss = 0.48669380
Iteration 1665, loss = 0.48943031
Iteration 1666, loss = 0.48589545
Iteration 1667, loss = 0.48923837
Iteration 1668, loss = 0.48771816
Iteration 1669, loss = 0.48587572
Iteration 1670, loss = 0.48964949
Iteration 1671, loss = 0.48808120
Iteration 1672, loss = 0.48694388
Iteration 1673, loss = 0.48881732
Iteration 1674, loss = 0.48913989
Iteration 1675, loss = 0.48982350
Iteration 1676, loss = 0.48782743
Iteration 1677, loss = 0.48772020
Iteration 1678, loss = 0.48728180
Iteration 1679, loss = 0.48905634
Iteration 1680, loss = 0.48713347
Iteration 1681, loss = 0.48683544
Iteration 1682, loss = 0.48747251
Iteration 1683, loss = 0.48677039
Iteration 1684, loss = 0.48690505
Iteration 1685, loss = 0.48726258
Iteration 1686, loss = 0.48728659
Iteration 1687, loss = 0.48741953
Iteration 1688, loss = 0.48925270
Iteration 1689, loss = 0.48708960
Iteration 1690, loss = 0.48999248
Iteration 1691, loss = 0.48930873
Iteration 1692, loss = 0.48738815
Iteration 1693, loss = 0.48689287
Iteration 1694, loss = 0.48793420
Iteration 1695, loss = 0.48801167
Iteration 1696, loss = 0.48774262
Iteration 1697, loss = 0.48781760
Iteration 1698, loss = 0.48663286
Iteration 1699, loss = 0.48712292
Iteration 1700, loss = 0.48679399
Iteration 1701, loss = 0.48689991
Iteration 1702, loss = 0.48919033
Iteration 1703, loss = 0.49115232
Iteration 1704, loss = 0.48609360
Iteration 1705, loss = 0.48729061
Iteration 1706, loss = 0.48780783
Iteration 1707, loss = 0.48811632
Iteration 1708, loss = 0.48884507
Iteration 1709, loss = 0.48877202
Iteration 1710, loss = 0.48675958
Iteration 1711, loss = 0.49113375
Iteration 1712, loss = 0.48891397
Iteration 1713, loss = 0.48966990
Iteration 1714, loss = 0.48869441
Iteration 1715, loss = 0.48596403
Iteration 1716, loss = 0.48661521
Iteration 1717, loss = 0.48718318
Iteration 1718, loss = 0.48730243
Iteration 1719, loss = 0.48689814
Iteration 1720, loss = 0.48696952
Iteration 1721, loss = 0.48804096
Iteration 1722, loss = 0.48811854
Iteration 1723, loss = 0.48915063
Iteration 1724, loss = 0.48636852
Iteration 1725, loss = 0.48831042
Iteration 1726, loss = 0.48743152
Iteration 1727, loss = 0.48697081
Iteration 1728, loss = 0.48609723
Iteration 1729, loss = 0.48555016
Iteration 1730, loss = 0.48594185
Iteration 1731, loss = 0.48851736
Iteration 1732, loss = 0.48644908
Iteration 1733, loss = 0.48553815
Iteration 1734, loss = 0.49005247
Iteration 1735, loss = 0.48869434
Iteration 1736, loss = 0.48737473
Iteration 1737, loss = 0.48628150
Iteration 1738, loss = 0.48991999
Iteration 1739, loss = 0.48780941
Iteration 1740, loss = 0.48719759
Iteration 1741, loss = 0.48570086
Iteration 1742, loss = 0.48859731
Iteration 1743, loss = 0.48605655
Iteration 1744, loss = 0.48679694
Iteration 1745, loss = 0.48740099
Iteration 1746, loss = 0.49042382
Iteration 1747, loss = 0.48641523
Iteration 1748, loss = 0.48730336
Iteration 1749, loss = 0.48655450
Iteration 1750, loss = 0.48618411
Iteration 1751, loss = 0.48817335
Iteration 1752, loss = 0.48577706
Iteration 1753, loss = 0.48806143
Iteration 1754, loss = 0.48739034
Iteration 1755, loss = 0.48740671
Iteration 1756, loss = 0.48656852
Iteration 1757, loss = 0.48714067
Iteration 1758, loss = 0.48556619
Iteration 1759, loss = 0.48650159
Iteration 1760, loss = 0.48557893
Iteration 1761, loss = 0.48517200
Iteration 1762, loss = 0.48596153
Iteration 1763, loss = 0.48765915
Iteration 1764, loss = 0.48616783
Iteration 1765, loss = 0.48634291
Iteration 1766, loss = 0.48596713
Iteration 1767, loss = 0.48677611
Iteration 1768, loss = 0.48650867
Iteration 1769, loss = 0.48674131
Iteration 1770, loss = 0.48772876
Iteration 1771, loss = 0.48848860
Iteration 1772, loss = 0.48979729
Iteration 1773, loss = 0.48727326
Iteration 1774, loss = 0.48898377
Iteration 1775, loss = 0.48735741
Iteration 1776, loss = 0.48936034
Iteration 1777, loss = 0.48559769
Iteration 1778, loss = 0.48632983
Iteration 1779, loss = 0.48657845
Iteration 1780, loss = 0.48515878
Iteration 1781, loss = 0.48851041
Iteration 1782, loss = 0.48656941
Iteration 1783, loss = 0.48548883
Iteration 1784, loss = 0.48471599
Iteration 1785, loss = 0.48503329
Iteration 1786, loss = 0.48364726
Iteration 1787, loss = 0.48607277
Iteration 1788, loss = 0.48550588
Iteration 1789, loss = 0.48650432
Iteration 1790, loss = 0.48564294
Iteration 1791, loss = 0.48642306
Iteration 1792, loss = 0.48832136
Iteration 1793, loss = 0.48750021
Iteration 1794, loss = 0.48487646
Iteration 1795, loss = 0.48438557
Iteration 1796, loss = 0.48686053
Iteration 1797, loss = 0.48775949
Iteration 1798, loss = 0.48646779
Iteration 1799, loss = 0.48466459
Iteration 1800, loss = 0.48513499
Iteration 1801, loss = 0.48555074
Iteration 1802, loss = 0.48662720
Iteration 1803, loss = 0.48610521
Iteration 1804, loss = 0.48502022
Iteration 1805, loss = 0.48707425
Iteration 1806, loss = 0.48416850
Iteration 1807, loss = 0.48529774
Iteration 1808, loss = 0.48546148
Iteration 1809, loss = 0.48626126
Iteration 1810, loss = 0.48678749
Iteration 1811, loss = 0.48434692
Iteration 1812, loss = 0.48554220
Iteration 1813, loss = 0.48781609
Iteration 1814, loss = 0.48705180
Iteration 1815, loss = 0.48720641
Iteration 1816, loss = 0.48588991
Iteration 1817, loss = 0.49404212
Iteration 1818, loss = 0.48913192
Iteration 1819, loss = 0.48728255
Iteration 1820, loss = 0.48753956
Iteration 1821, loss = 0.48606458
Iteration 1822, loss = 0.48616458
Iteration 1823, loss = 0.48848110
Iteration 1824, loss = 0.48596115
Iteration 1825, loss = 0.48676572
Iteration 1826, loss = 0.48701462
Iteration 1827, loss = 0.48602839
Iteration 1828, loss = 0.48496133
Iteration 1829, loss = 0.48673120
Iteration 1830, loss = 0.48758015
Iteration 1831, loss = 0.48609571
Iteration 1832, loss = 0.48471033
Iteration 1833, loss = 0.48695394
Iteration 1834, loss = 0.48710175
Iteration 1835, loss = 0.49023886
Iteration 1836, loss = 0.48610111
Iteration 1837, loss = 0.48565788
Iteration 1838, loss = 0.48516953
Iteration 1839, loss = 0.48726714
Iteration 1840, loss = 0.48544581
Iteration 1841, loss = 0.48580518
Iteration 1842, loss = 0.48726390
Iteration 1843, loss = 0.48665717
Iteration 1844, loss = 0.48676295
Iteration 1845, loss = 0.48641036
Iteration 1846, loss = 0.48661096
Iteration 1847, loss = 0.48835002
Iteration 1848, loss = 0.48626617
Iteration 1849, loss = 0.48494911
Iteration 1850, loss = 0.48634385
Iteration 1851, loss = 0.48356684
Iteration 1852, loss = 0.48599079
Iteration 1853, loss = 0.48424651
Iteration 1854, loss = 0.48508658
Iteration 1855, loss = 0.48571722
Iteration 1856, loss = 0.48610047
Iteration 1857, loss = 0.48498407
Iteration 1858, loss = 0.48740473
Iteration 1859, loss = 0.48841450
Iteration 1860, loss = 0.48417219
Iteration 1861, loss = 0.48582384
Iteration 1862, loss = 0.48579138
Iteration 1863, loss = 0.48566268
Iteration 1864, loss = 0.48726842
Iteration 1865, loss = 0.48638810
Iteration 1866, loss = 0.48527597
Iteration 1867, loss = 0.48634514
Iteration 1868, loss = 0.48529600
Iteration 1869, loss = 0.48634432
Iteration 1870, loss = 0.48501676
Iteration 1871, loss = 0.48894962
Iteration 1872, loss = 0.48713864
Iteration 1873, loss = 0.48675466
Iteration 1874, loss = 0.48574707
Iteration 1875, loss = 0.48564325
Iteration 1876, loss = 0.48867691
Iteration 1877, loss = 0.48553517
Iteration 1878, loss = 0.48965745
Iteration 1879, loss = 0.49137315
Iteration 1880, loss = 0.48640916
Iteration 1881, loss = 0.48662947
Iteration 1882, loss = 0.48704932
Iteration 1883, loss = 0.48531485
Iteration 1884, loss = 0.48417199
Iteration 1885, loss = 0.48592307
Iteration 1886, loss = 0.48743875
Iteration 1887, loss = 0.48508908
Iteration 1888, loss = 0.48390816
Iteration 1889, loss = 0.48452330
Iteration 1890, loss = 0.48281640
Iteration 1891, loss = 0.48448177
Iteration 1892, loss = 0.48478589
Iteration 1893, loss = 0.48526523
Iteration 1894, loss = 0.49041568
Iteration 1895, loss = 0.48664748
Iteration 1896, loss = 0.48345441
Iteration 1897, loss = 0.48380185
Iteration 1898, loss = 0.48348539
Iteration 1899, loss = 0.48481923
Iteration 1900, loss = 0.48625503
Iteration 1901, loss = 0.48419778
Iteration 1902, loss = 0.48340483
Iteration 1903, loss = 0.48520089
Iteration 1904, loss = 0.48338675
Iteration 1905, loss = 0.48341375
Iteration 1906, loss = 0.48541486
Iteration 1907, loss = 0.48437015
Iteration 1908, loss = 0.48347672
Iteration 1909, loss = 0.48479874
Iteration 1910, loss = 0.48470565
Iteration 1911, loss = 0.48547912
Iteration 1912, loss = 0.48742086
Iteration 1913, loss = 0.48692337
Iteration 1914, loss = 0.48399282
Iteration 1915, loss = 0.48322344
Iteration 1916, loss = 0.48698183
Iteration 1917, loss = 0.48387370
Iteration 1918, loss = 0.48647915
Iteration 1919, loss = 0.48306518
Iteration 1920, loss = 0.48637421
Iteration 1921, loss = 0.48458121
Iteration 1922, loss = 0.48350476
Iteration 1923, loss = 0.48517190
Iteration 1924, loss = 0.48588900
Iteration 1925, loss = 0.48475651
Iteration 1926, loss = 0.48317984
Iteration 1927, loss = 0.48508428
Iteration 1928, loss = 0.48520293
Iteration 1929, loss = 0.48439629
Iteration 1930, loss = 0.48493499
Iteration 1931, loss = 0.48536931
Iteration 1932, loss = 0.48383594
Iteration 1933, loss = 0.48308978
Iteration 1934, loss = 0.48660009
Iteration 1935, loss = 0.48780024
Iteration 1936, loss = 0.48273725
Iteration 1937, loss = 0.48611384
Iteration 1938, loss = 0.48384003
Iteration 1939, loss = 0.48548406
Iteration 1940, loss = 0.48652039
Iteration 1941, loss = 0.48275565
Iteration 1942, loss = 0.48626257
Iteration 1943, loss = 0.48525344
Iteration 1944, loss = 0.48667495
Iteration 1945, loss = 0.48598556
Iteration 1946, loss = 0.48439726
Iteration 1947, loss = 0.48557291
Iteration 1948, loss = 0.48606779
Iteration 1949, loss = 0.48658461
Iteration 1950, loss = 0.48534765
Iteration 1951, loss = 0.48534113
Iteration 1952, loss = 0.48641128
Iteration 1953, loss = 0.48727838
Iteration 1954, loss = 0.48719003
Iteration 1955, loss = 0.48483393
Iteration 1956, loss = 0.48372811
Iteration 1957, loss = 0.48519273
Iteration 1958, loss = 0.48472733
Iteration 1959, loss = 0.48323351
Iteration 1960, loss = 0.48393556
Iteration 1961, loss = 0.48958983
Iteration 1962, loss = 0.48502281
Iteration 1963, loss = 0.48340364
Iteration 1964, loss = 0.48485806
Iteration 1965, loss = 0.48632808
Iteration 1966, loss = 0.48471780
Iteration 1967, loss = 0.48674925
Iteration 1968, loss = 0.48555466
Iteration 1969, loss = 0.48322998
Iteration 1970, loss = 0.48410465
Iteration 1971, loss = 0.48786121
Iteration 1972, loss = 0.48292223
Iteration 1973, loss = 0.48563183
Iteration 1974, loss = 0.48521413
Iteration 1975, loss = 0.48434636
Iteration 1976, loss = 0.48290920
Iteration 1977, loss = 0.48162343
Iteration 1978, loss = 0.48356334
Iteration 1979, loss = 0.48368721
Iteration 1980, loss = 0.48481607
Iteration 1981, loss = 0.48300938
Iteration 1982, loss = 0.48684828
Iteration 1983, loss = 0.48790065
Iteration 1984, loss = 0.48820713
Iteration 1985, loss = 0.48750904
Iteration 1986, loss = 0.48507840
Iteration 1987, loss = 0.48222069
Iteration 1988, loss = 0.49010161
Iteration 1989, loss = 0.48437954
Iteration 1990, loss = 0.48634953
Iteration 1991, loss = 0.48357366
Iteration 1992, loss = 0.48355990
Iteration 1993, loss = 0.48457159
Iteration 1994, loss = 0.48501054
Iteration 1995, loss = 0.48382516
Iteration 1996, loss = 0.48613686
Iteration 1997, loss = 0.48647631
Iteration 1998, loss = 0.48442429
Iteration 1999, loss = 0.48336849
Iteration 2000, loss = 0.48324484
Iteration 2001, loss = 0.48640111
Iteration 2002, loss = 0.48536612
Iteration 2003, loss = 0.48217531
Iteration 2004, loss = 0.48333572
Iteration 2005, loss = 0.48712212
Iteration 2006, loss = 0.48572253
Iteration 2007, loss = 0.48235484
Iteration 2008, loss = 0.48331473
Iteration 2009, loss = 0.48620671
Iteration 2010, loss = 0.48856214
Iteration 2011, loss = 0.48509193
Iteration 2012, loss = 0.48292092
Iteration 2013, loss = 0.48226950
Iteration 2014, loss = 0.48266101
Iteration 2015, loss = 0.48278956
Iteration 2016, loss = 0.48489052
Iteration 2017, loss = 0.48510993
Iteration 2018, loss = 0.48170983
Iteration 2019, loss = 0.48510131
Iteration 2020, loss = 0.48317512
Iteration 2021, loss = 0.48218656
Iteration 2022, loss = 0.48302043
Iteration 2023, loss = 0.48201041
Iteration 2024, loss = 0.48441293
Iteration 2025, loss = 0.48542254
Iteration 2026, loss = 0.48543582
Iteration 2027, loss = 0.48277830
Iteration 2028, loss = 0.48286964
Iteration 2029, loss = 0.48450423
Iteration 2030, loss = 0.48378647
Iteration 2031, loss = 0.48338183
Iteration 2032, loss = 0.48369174
Iteration 2033, loss = 0.48288230
Iteration 2034, loss = 0.48201741
Iteration 2035, loss = 0.48489853
Iteration 2036, loss = 0.48594890
Iteration 2037, loss = 0.48654243
Iteration 2038, loss = 0.48214377
Iteration 2039, loss = 0.48281323
Iteration 2040, loss = 0.48582684
Iteration 2041, loss = 0.48332739
Iteration 2042, loss = 0.48239979
Iteration 2043, loss = 0.48323854
Iteration 2044, loss = 0.48379019
Iteration 2045, loss = 0.48283682
Iteration 2046, loss = 0.48243928
Iteration 2047, loss = 0.48153052
Iteration 2048, loss = 0.48549124
Iteration 2049, loss = 0.48357960
Iteration 2050, loss = 0.48300935
Iteration 2051, loss = 0.48520812
Iteration 2052, loss = 0.48210130
Iteration 2053, loss = 0.48592451
Iteration 2054, loss = 0.48417888
Iteration 2055, loss = 0.48540093
Iteration 2056, loss = 0.48405440
Iteration 2057, loss = 0.48429151
Iteration 2058, loss = 0.48187451
Iteration 2059, loss = 0.48210708
Iteration 2060, loss = 0.48216974
Iteration 2061, loss = 0.48410753
Iteration 2062, loss = 0.48503102
Iteration 2063, loss = 0.48358613
Iteration 2064, loss = 0.48141380
Iteration 2065, loss = 0.48293950
Iteration 2066, loss = 0.48196414
Iteration 2067, loss = 0.48232906
Iteration 2068, loss = 0.48338540
Iteration 2069, loss = 0.48349842
Iteration 2070, loss = 0.48363400
Iteration 2071, loss = 0.48181643
Iteration 2072, loss = 0.48723185
Iteration 2073, loss = 0.48372220
Iteration 2074, loss = 0.48330358
Iteration 2075, loss = 0.48498786
Iteration 2076, loss = 0.48512249
Iteration 2077, loss = 0.48467486
Iteration 2078, loss = 0.48662690
Iteration 2079, loss = 0.48677743
Iteration 2080, loss = 0.48563198
Iteration 2081, loss = 0.48596218
Iteration 2082, loss = 0.48209426
Iteration 2083, loss = 0.48419619
Iteration 2084, loss = 0.48308581
Iteration 2085, loss = 0.48247425
Iteration 2086, loss = 0.48353901
Iteration 2087, loss = 0.47995273
Iteration 2088, loss = 0.48215129
Iteration 2089, loss = 0.48223939
Iteration 2090, loss = 0.48305906
Iteration 2091, loss = 0.48121661
Iteration 2092, loss = 0.48224009
Iteration 2093, loss = 0.48274517
Iteration 2094, loss = 0.48552283
Iteration 2095, loss = 0.48455466
Iteration 2096, loss = 0.48296295
Iteration 2097, loss = 0.48176734
Iteration 2098, loss = 0.48378406
Iteration 2099, loss = 0.48599034
Iteration 2100, loss = 0.48224409
Iteration 2101, loss = 0.48176066
Iteration 2102, loss = 0.48411600
Iteration 2103, loss = 0.49020477
Iteration 2104, loss = 0.48509061
Iteration 2105, loss = 0.48277366
Iteration 2106, loss = 0.48316504
Iteration 2107, loss = 0.48155735
Iteration 2108, loss = 0.48417764
Iteration 2109, loss = 0.48270884
Iteration 2110, loss = 0.48556365
Iteration 2111, loss = 0.48238106
Iteration 2112, loss = 0.48089697
Iteration 2113, loss = 0.48308138
Iteration 2114, loss = 0.48347434
Iteration 2115, loss = 0.48279638
Iteration 2116, loss = 0.48306784
Iteration 2117, loss = 0.48782060
Iteration 2118, loss = 0.48645360
Iteration 2119, loss = 0.48494298
Iteration 2120, loss = 0.48214062
Iteration 2121, loss = 0.48271225
Iteration 2122, loss = 0.48967250
Iteration 2123, loss = 0.48525441
Iteration 2124, loss = 0.48321322
Iteration 2125, loss = 0.48119067
Iteration 2126, loss = 0.48124919
Iteration 2127, loss = 0.48345476
Iteration 2128, loss = 0.48163401
Iteration 2129, loss = 0.48177114
Iteration 2130, loss = 0.48419816
Iteration 2131, loss = 0.49038128
Iteration 2132, loss = 0.48556472
Iteration 2133, loss = 0.48406551
Iteration 2134, loss = 0.48308195
Iteration 2135, loss = 0.48460139
Iteration 2136, loss = 0.48232380
Iteration 2137, loss = 0.48215733
Iteration 2138, loss = 0.48078778
Iteration 2139, loss = 0.48213592
Iteration 2140, loss = 0.48151078
Iteration 2141, loss = 0.48442133
Iteration 2142, loss = 0.48182461
Iteration 2143, loss = 0.48240253
Iteration 2144, loss = 0.48302977
Iteration 2145, loss = 0.48386568
Iteration 2146, loss = 0.48293813
Iteration 2147, loss = 0.48570196
Iteration 2148, loss = 0.48041714
Iteration 2149, loss = 0.48080948
Iteration 2150, loss = 0.48482352
Iteration 2151, loss = 0.48330278
Iteration 2152, loss = 0.48173561
Iteration 2153, loss = 0.48487408
Iteration 2154, loss = 0.48322117
Iteration 2155, loss = 0.47996023
Iteration 2156, loss = 0.48247748
Iteration 2157, loss = 0.48111599
Iteration 2158, loss = 0.48198248
Iteration 2159, loss = 0.48393534
Iteration 2160, loss = 0.48096395
Iteration 2161, loss = 0.48206951
Iteration 2162, loss = 0.48449123
Iteration 2163, loss = 0.48218787
Iteration 2164, loss = 0.48075904
Iteration 2165, loss = 0.48357920
Iteration 2166, loss = 0.48256013
Iteration 2167, loss = 0.48126109
Iteration 2168, loss = 0.48258598
Iteration 2169, loss = 0.48269554
Iteration 2170, loss = 0.48538215
Iteration 2171, loss = 0.48221510
Iteration 2172, loss = 0.48214909
Iteration 2173, loss = 0.48064511
Iteration 2174, loss = 0.48142301
Iteration 2175, loss = 0.48342577
Iteration 2176, loss = 0.48109308
Iteration 2177, loss = 0.48201507
Iteration 2178, loss = 0.48199084
Iteration 2179, loss = 0.48171490
Iteration 2180, loss = 0.48585938
Iteration 2181, loss = 0.48396189
Iteration 2182, loss = 0.48025383
Iteration 2183, loss = 0.48288460
Iteration 2184, loss = 0.48213636
Iteration 2185, loss = 0.48436210
Iteration 2186, loss = 0.48180674
Iteration 2187, loss = 0.48688354
Iteration 2188, loss = 0.48605639
Iteration 2189, loss = 0.48266372
Iteration 2190, loss = 0.48189708
Iteration 2191, loss = 0.48270912
Iteration 2192, loss = 0.48337862
Iteration 2193, loss = 0.48085169
Iteration 2194, loss = 0.48107950
Iteration 2195, loss = 0.47876850
Iteration 2196, loss = 0.48025103
Iteration 2197, loss = 0.47967813
Iteration 2198, loss = 0.47988066
Iteration 2199, loss = 0.48144654
Iteration 2200, loss = 0.48139409
Iteration 2201, loss = 0.48039716
Iteration 2202, loss = 0.48519325
Iteration 2203, loss = 0.48552109
Iteration 2204, loss = 0.48277712
Iteration 2205, loss = 0.48371571
Iteration 2206, loss = 0.48486201
Iteration 2207, loss = 0.48247959
Iteration 2208, loss = 0.48293243
Iteration 2209, loss = 0.48116245
Iteration 2210, loss = 0.48121106
Iteration 2211, loss = 0.48060065
Iteration 2212, loss = 0.48340519
Iteration 2213, loss = 0.48207953
Iteration 2214, loss = 0.48148571
Iteration 2215, loss = 0.48246185
Iteration 2216, loss = 0.48131238
Iteration 2217, loss = 0.48168757
Iteration 2218, loss = 0.48328357
Iteration 2219, loss = 0.48390258
Iteration 2220, loss = 0.48321087
Iteration 2221, loss = 0.48127153
Iteration 2222, loss = 0.48160941
Iteration 2223, loss = 0.48198021
Iteration 2224, loss = 0.48082516
Iteration 2225, loss = 0.48030503
Iteration 2226, loss = 0.48111903
Iteration 2227, loss = 0.48358167
Iteration 2228, loss = 0.48205474
Iteration 2229, loss = 0.48138730
Iteration 2230, loss = 0.48200602
Iteration 2231, loss = 0.48043738
Iteration 2232, loss = 0.48019555
Iteration 2233, loss = 0.48258582
Iteration 2234, loss = 0.48324358
Iteration 2235, loss = 0.48098058
Iteration 2236, loss = 0.48182656
Iteration 2237, loss = 0.48336694
Iteration 2238, loss = 0.48247669
Iteration 2239, loss = 0.48033982
Iteration 2240, loss = 0.48224448
Iteration 2241, loss = 0.48214234
Iteration 2242, loss = 0.48029953
Iteration 2243, loss = 0.48200554
Iteration 2244, loss = 0.48126170
Iteration 2245, loss = 0.48205464
Iteration 2246, loss = 0.48136262
Iteration 2247, loss = 0.48119128
Iteration 2248, loss = 0.47991099
Iteration 2249, loss = 0.48160577
Iteration 2250, loss = 0.48349061
Iteration 2251, loss = 0.48836607
Iteration 2252, loss = 0.48042049
Iteration 2253, loss = 0.48227305
Iteration 2254, loss = 0.48079164
Iteration 2255, loss = 0.48231455
Iteration 2256, loss = 0.48143629
Iteration 2257, loss = 0.48463738
Iteration 2258, loss = 0.48111761
Iteration 2259, loss = 0.48011937
Iteration 2260, loss = 0.48244971
Iteration 2261, loss = 0.48076974
Iteration 2262, loss = 0.48174325
Iteration 2263, loss = 0.48122641
Iteration 2264, loss = 0.48316998
Iteration 2265, loss = 0.48058282
Iteration 2266, loss = 0.47980460
Iteration 2267, loss = 0.48147553
Iteration 2268, loss = 0.48366861
Iteration 2269, loss = 0.48192985
Iteration 2270, loss = 0.48020232
Iteration 2271, loss = 0.48151709
Iteration 2272, loss = 0.48198262
Iteration 2273, loss = 0.48159656
Iteration 2274, loss = 0.48177475
Iteration 2275, loss = 0.48192120
Iteration 2276, loss = 0.48302125
Iteration 2277, loss = 0.48170387
Iteration 2278, loss = 0.47968078
Iteration 2279, loss = 0.47897920
Iteration 2280, loss = 0.48006556
Iteration 2281, loss = 0.47974294
Iteration 2282, loss = 0.48148718
Iteration 2283, loss = 0.48013911
Iteration 2284, loss = 0.48053776
Iteration 2285, loss = 0.48800643
Iteration 2286, loss = 0.48169182
Iteration 2287, loss = 0.48057607
Iteration 2288, loss = 0.48408510
Iteration 2289, loss = 0.48241649
Iteration 2290, loss = 0.48262858
Iteration 2291, loss = 0.48322416
Iteration 2292, loss = 0.48225288
Iteration 2293, loss = 0.48164130
Iteration 2294, loss = 0.48313951
Iteration 2295, loss = 0.48322590
Iteration 2296, loss = 0.48009789
Iteration 2297, loss = 0.48001449
Iteration 2298, loss = 0.47958513
Iteration 2299, loss = 0.48212692
Iteration 2300, loss = 0.48079653
Iteration 2301, loss = 0.47920034
Iteration 2302, loss = 0.48125463
Iteration 2303, loss = 0.48304456
Iteration 2304, loss = 0.48060604
Iteration 2305, loss = 0.47937291
Iteration 2306, loss = 0.48107809
Iteration 2307, loss = 0.48083067
Iteration 2308, loss = 0.48095794
Iteration 2309, loss = 0.48524425
Iteration 2310, loss = 0.48374033
Iteration 2311, loss = 0.48478757
Iteration 2312, loss = 0.48970418
Iteration 2313, loss = 0.48192055
Iteration 2314, loss = 0.48117920
Iteration 2315, loss = 0.48398016
Iteration 2316, loss = 0.47957304
Iteration 2317, loss = 0.47888668
Iteration 2318, loss = 0.48057837
Iteration 2319, loss = 0.48253489
Iteration 2320, loss = 0.48281357
Iteration 2321, loss = 0.47902184
Iteration 2322, loss = 0.48052466
Iteration 2323, loss = 0.48064867
Iteration 2324, loss = 0.48069973
Iteration 2325, loss = 0.48426579
Iteration 2326, loss = 0.48309924
Iteration 2327, loss = 0.47825255
Iteration 2328, loss = 0.48600186
Iteration 2329, loss = 0.48257354
Iteration 2330, loss = 0.48480670
Iteration 2331, loss = 0.48127956
Iteration 2332, loss = 0.48038227
Iteration 2333, loss = 0.47932382
Iteration 2334, loss = 0.48003565
Iteration 2335, loss = 0.48055804
Iteration 2336, loss = 0.48012659
Iteration 2337, loss = 0.48144919
Iteration 2338, loss = 0.48109250
Iteration 2339, loss = 0.48113640
Iteration 2340, loss = 0.48213818
Iteration 2341, loss = 0.48195843
Iteration 2342, loss = 0.48055017
Iteration 2343, loss = 0.48020645
Iteration 2344, loss = 0.47949556
Iteration 2345, loss = 0.47837773
Iteration 2346, loss = 0.47882576
Iteration 2347, loss = 0.48005575
Iteration 2348, loss = 0.48002462
Iteration 2349, loss = 0.48043274
Iteration 2350, loss = 0.48321224
Iteration 2351, loss = 0.48295313
Iteration 2352, loss = 0.48086237
Iteration 2353, loss = 0.47865369
Iteration 2354, loss = 0.47941737
Iteration 2355, loss = 0.48127058
Iteration 2356, loss = 0.47992694
Iteration 2357, loss = 0.48180216
Iteration 2358, loss = 0.48097056
Iteration 2359, loss = 0.48062822
Iteration 2360, loss = 0.48237673
Iteration 2361, loss = 0.47907732
Iteration 2362, loss = 0.47988883
Iteration 2363, loss = 0.48005776
Iteration 2364, loss = 0.48134637
Iteration 2365, loss = 0.48030724
Iteration 2366, loss = 0.47993103
Iteration 2367, loss = 0.47807429
Iteration 2368, loss = 0.48068457
Iteration 2369, loss = 0.48021392
Iteration 2370, loss = 0.48298209
Iteration 2371, loss = 0.48649387
Iteration 2372, loss = 0.48109556
Iteration 2373, loss = 0.48005243
Iteration 2374, loss = 0.48008384
Iteration 2375, loss = 0.48154698
Iteration 2376, loss = 0.48005450
Iteration 2377, loss = 0.48099390
Iteration 2378, loss = 0.48063062
Iteration 2379, loss = 0.48273314
Iteration 2380, loss = 0.47954872
Iteration 2381, loss = 0.48290293
Iteration 2382, loss = 0.47746174
Iteration 2383, loss = 0.47867800
Iteration 2384, loss = 0.48097613
Iteration 2385, loss = 0.47960414
Iteration 2386, loss = 0.47873909
Iteration 2387, loss = 0.47788037
Iteration 2388, loss = 0.47924999
Iteration 2389, loss = 0.47823316
Iteration 2390, loss = 0.47851907
Iteration 2391, loss = 0.47940486
Iteration 2392, loss = 0.48338504
Iteration 2393, loss = 0.48096424
Iteration 2394, loss = 0.48121344
Iteration 2395, loss = 0.47979720
Iteration 2396, loss = 0.47966115
Iteration 2397, loss = 0.48152028
Iteration 2398, loss = 0.48218122
Iteration 2399, loss = 0.48018160
Iteration 2400, loss = 0.47960477
Iteration 2401, loss = 0.47967917
Iteration 2402, loss = 0.47790498
Iteration 2403, loss = 0.47740219
Iteration 2404, loss = 0.47864503
Iteration 2405, loss = 0.47696166
Iteration 2406, loss = 0.47989607
Iteration 2407, loss = 0.47799330
Iteration 2408, loss = 0.48037633
Iteration 2409, loss = 0.47876205
Iteration 2410, loss = 0.47785678
Iteration 2411, loss = 0.47983920
Iteration 2412, loss = 0.47821518
Iteration 2413, loss = 0.48045568
Iteration 2414, loss = 0.47886561
Iteration 2415, loss = 0.48031942
Iteration 2416, loss = 0.47775110
Iteration 2417, loss = 0.47745893
Iteration 2418, loss = 0.48065108
Iteration 2419, loss = 0.48076273
Iteration 2420, loss = 0.47891989
Iteration 2421, loss = 0.47921849
Iteration 2422, loss = 0.48240235
Iteration 2423, loss = 0.47951667
Iteration 2424, loss = 0.48099688
Iteration 2425, loss = 0.47945635
Iteration 2426, loss = 0.47989471
Iteration 2427, loss = 0.47958903
Iteration 2428, loss = 0.47801532
Iteration 2429, loss = 0.47845521
Iteration 2430, loss = 0.47997524
Iteration 2431, loss = 0.47811095
Iteration 2432, loss = 0.47748815
Iteration 2433, loss = 0.47759585
Iteration 2434, loss = 0.47786721
Iteration 2435, loss = 0.47892915
Iteration 2436, loss = 0.47847865
Iteration 2437, loss = 0.48303277
Iteration 2438, loss = 0.48075962
Iteration 2439, loss = 0.47791740
Iteration 2440, loss = 0.48035664
Iteration 2441, loss = 0.48061424
Iteration 2442, loss = 0.48024963
Iteration 2443, loss = 0.47922691
Iteration 2444, loss = 0.47899624
Iteration 2445, loss = 0.47903828
Iteration 2446, loss = 0.47907700
Iteration 2447, loss = 0.47919086
Iteration 2448, loss = 0.48117073
Iteration 2449, loss = 0.47904668
Iteration 2450, loss = 0.47904574
Iteration 2451, loss = 0.48150521
Iteration 2452, loss = 0.47905500
Iteration 2453, loss = 0.48084029
Iteration 2454, loss = 0.47836998
Iteration 2455, loss = 0.47943025
Iteration 2456, loss = 0.47881710
Iteration 2457, loss = 0.47813211
Iteration 2458, loss = 0.48291268
Iteration 2459, loss = 0.47978306
Iteration 2460, loss = 0.47772041
Iteration 2461, loss = 0.47800874
Iteration 2462, loss = 0.47813348
Iteration 2463, loss = 0.47910952
Iteration 2464, loss = 0.47745780
Iteration 2465, loss = 0.47987894
Iteration 2466, loss = 0.47965707
Iteration 2467, loss = 0.47686857
Iteration 2468, loss = 0.47817123
Iteration 2469, loss = 0.47941007
Iteration 2470, loss = 0.47723168
Iteration 2471, loss = 0.47872560
Iteration 2472, loss = 0.47910472
Iteration 2473, loss = 0.48117128
Iteration 2474, loss = 0.48239283
Iteration 2475, loss = 0.48034944
Iteration 2476, loss = 0.48051557
Iteration 2477, loss = 0.47880906
Iteration 2478, loss = 0.48394547
Iteration 2479, loss = 0.47808146
Iteration 2480, loss = 0.48055155
Iteration 2481, loss = 0.47794635
Iteration 2482, loss = 0.48178725
Iteration 2483, loss = 0.47904617
Iteration 2484, loss = 0.48162279
Iteration 2485, loss = 0.48330059
Iteration 2486, loss = 0.48096367
Iteration 2487, loss = 0.47820420
Iteration 2488, loss = 0.48095785
Iteration 2489, loss = 0.48067912
Iteration 2490, loss = 0.48061221
Iteration 2491, loss = 0.47968977
Iteration 2492, loss = 0.47839271
Iteration 2493, loss = 0.47913200
Iteration 2494, loss = 0.47805966
Iteration 2495, loss = 0.47738340
Iteration 2496, loss = 0.47624991
Iteration 2497, loss = 0.47722032
Iteration 2498, loss = 0.47813755
Iteration 2499, loss = 0.47988497
Iteration 2500, loss = 0.48020426
Iteration 2501, loss = 0.47957638
Iteration 2502, loss = 0.48008000
Iteration 2503, loss = 0.48217083
Iteration 2504, loss = 0.47666719
Iteration 2505, loss = 0.48343457
Iteration 2506, loss = 0.47880682
Iteration 2507, loss = 0.47894010
Iteration 2508, loss = 0.47697754
Iteration 2509, loss = 0.47874276
Iteration 2510, loss = 0.47814545
Iteration 2511, loss = 0.47812589
Iteration 2512, loss = 0.48001392
Iteration 2513, loss = 0.47912564
Iteration 2514, loss = 0.47564247
Iteration 2515, loss = 0.47997511
Iteration 2516, loss = 0.48379219
Iteration 2517, loss = 0.48115067
Iteration 2518, loss = 0.47998406
Iteration 2519, loss = 0.48057824
Iteration 2520, loss = 0.47767593
Iteration 2521, loss = 0.47795834
Iteration 2522, loss = 0.47917028
Iteration 2523, loss = 0.48035643
Iteration 2524, loss = 0.48100058
Iteration 2525, loss = 0.47903165
Iteration 2526, loss = 0.48187415
Iteration 2527, loss = 0.47900101
Iteration 2528, loss = 0.47699107
Iteration 2529, loss = 0.47666247
Iteration 2530, loss = 0.47781974
Iteration 2531, loss = 0.47938020
Iteration 2532, loss = 0.47734160
Iteration 2533, loss = 0.47785458
Iteration 2534, loss = 0.47926495
Iteration 2535, loss = 0.47862917
Iteration 2536, loss = 0.47936346
Iteration 2537, loss = 0.48242380
Iteration 2538, loss = 0.47725175
Iteration 2539, loss = 0.48004155
Iteration 2540, loss = 0.47785924
Iteration 2541, loss = 0.47935022
Iteration 2542, loss = 0.47820493
Iteration 2543, loss = 0.48043259
Iteration 2544, loss = 0.47901029
Iteration 2545, loss = 0.47823481
Iteration 2546, loss = 0.47727977
Iteration 2547, loss = 0.47700957
Iteration 2548, loss = 0.47871253
Iteration 2549, loss = 0.47862621
Iteration 2550, loss = 0.47714165
Iteration 2551, loss = 0.47766637
Iteration 2552, loss = 0.47781785
Iteration 2553, loss = 0.47745831
Iteration 2554, loss = 0.47891547
Iteration 2555, loss = 0.47710023
Iteration 2556, loss = 0.47719852
Iteration 2557, loss = 0.47843163
Iteration 2558, loss = 0.47914937
Iteration 2559, loss = 0.47708421
Iteration 2560, loss = 0.47780997
Iteration 2561, loss = 0.47902206
Iteration 2562, loss = 0.47979787
Iteration 2563, loss = 0.47850050
Iteration 2564, loss = 0.47886112
Iteration 2565, loss = 0.48057754
Iteration 2566, loss = 0.48055977
Iteration 2567, loss = 0.47915913
Iteration 2568, loss = 0.47757783
Iteration 2569, loss = 0.48081207
Iteration 2570, loss = 0.47986625
Iteration 2571, loss = 0.48181055
Iteration 2572, loss = 0.48097200
Iteration 2573, loss = 0.47828848
Iteration 2574, loss = 0.48117996
Iteration 2575, loss = 0.47934693
Iteration 2576, loss = 0.48152597
Iteration 2577, loss = 0.47942316
Iteration 2578, loss = 0.47892630
Iteration 2579, loss = 0.47900173
Iteration 2580, loss = 0.47640243
Iteration 2581, loss = 0.47610806
Iteration 2582, loss = 0.47739096
Iteration 2583, loss = 0.47704559
Iteration 2584, loss = 0.47879868
Iteration 2585, loss = 0.47620724
Iteration 2586, loss = 0.47753326
Iteration 2587, loss = 0.47985458
Iteration 2588, loss = 0.48111595
Iteration 2589, loss = 0.47554740
Iteration 2590, loss = 0.47997408
Iteration 2591, loss = 0.47732896
Iteration 2592, loss = 0.48023399
Iteration 2593, loss = 0.47835265
Iteration 2594, loss = 0.47707811
Iteration 2595, loss = 0.47665195
Iteration 2596, loss = 0.47685792
Iteration 2597, loss = 0.47926220
Iteration 2598, loss = 0.48001857
Iteration 2599, loss = 0.48042214
Iteration 2600, loss = 0.47760113
Iteration 2601, loss = 0.47865056
Iteration 2602, loss = 0.47834441
Iteration 2603, loss = 0.48061217
Iteration 2604, loss = 0.48065839
Iteration 2605, loss = 0.47543983
Iteration 2606, loss = 0.47568598
Iteration 2607, loss = 0.47721469
Iteration 2608, loss = 0.47818352
Iteration 2609, loss = 0.47841648
Iteration 2610, loss = 0.47617504
Iteration 2611, loss = 0.47674355
Iteration 2612, loss = 0.47726464
Iteration 2613, loss = 0.47586317
Iteration 2614, loss = 0.47730860
Iteration 2615, loss = 0.47572168
Iteration 2616, loss = 0.47640001
Iteration 2617, loss = 0.47727313
Iteration 2618, loss = 0.47799337
Iteration 2619, loss = 0.47681832
Iteration 2620, loss = 0.47799908
Iteration 2621, loss = 0.48028720
Iteration 2622, loss = 0.47709138
Iteration 2623, loss = 0.47615780
Iteration 2624, loss = 0.47668481
Iteration 2625, loss = 0.47901011
Iteration 2626, loss = 0.47466142
Iteration 2627, loss = 0.47677451
Iteration 2628, loss = 0.47530556
Iteration 2629, loss = 0.47641157
Iteration 2630, loss = 0.47855498
Iteration 2631, loss = 0.47655810
Iteration 2632, loss = 0.47839622
Iteration 2633, loss = 0.47922675
Iteration 2634, loss = 0.48027824
Iteration 2635, loss = 0.47608238
Iteration 2636, loss = 0.47929825
Iteration 2637, loss = 0.47806040
Iteration 2638, loss = 0.48125519
Iteration 2639, loss = 0.47853274
Iteration 2640, loss = 0.47808598
Iteration 2641, loss = 0.47755876
Iteration 2642, loss = 0.47754476
Iteration 2643, loss = 0.47599494
Iteration 2644, loss = 0.47819826
Iteration 2645, loss = 0.47957262
Iteration 2646, loss = 0.47886742
Iteration 2647, loss = 0.47860813
Iteration 2648, loss = 0.47675186
Iteration 2649, loss = 0.47711431
Iteration 2650, loss = 0.47773720
Iteration 2651, loss = 0.47732349
Iteration 2652, loss = 0.47544457
Iteration 2653, loss = 0.47972845
Iteration 2654, loss = 0.47784612
Iteration 2655, loss = 0.47583221
Iteration 2656, loss = 0.47809010
Iteration 2657, loss = 0.47839383
Iteration 2658, loss = 0.48188318
Iteration 2659, loss = 0.47698794
Iteration 2660, loss = 0.47662731
Iteration 2661, loss = 0.48131145
Iteration 2662, loss = 0.47593188
Iteration 2663, loss = 0.47520773
Iteration 2664, loss = 0.47642760
Iteration 2665, loss = 0.47922069
Iteration 2666, loss = 0.48096231
Iteration 2667, loss = 0.47636070
Iteration 2668, loss = 0.47772002
Iteration 2669, loss = 0.47506208
Iteration 2670, loss = 0.47424382
Iteration 2671, loss = 0.47661423
Iteration 2672, loss = 0.47638310
Iteration 2673, loss = 0.47523531
Iteration 2674, loss = 0.47505750
Iteration 2675, loss = 0.47584414
Iteration 2676, loss = 0.47510115
Iteration 2677, loss = 0.47802540
Iteration 2678, loss = 0.47530307
Iteration 2679, loss = 0.47939977
Iteration 2680, loss = 0.47928048
Iteration 2681, loss = 0.47674038
Iteration 2682, loss = 0.47475638
Iteration 2683, loss = 0.47570741
Iteration 2684, loss = 0.47833222
Iteration 2685, loss = 0.47734560
Iteration 2686, loss = 0.47655795
Iteration 2687, loss = 0.47722048
Iteration 2688, loss = 0.47752419
Iteration 2689, loss = 0.47881181
Iteration 2690, loss = 0.47799879
Iteration 2691, loss = 0.47789613
Iteration 2692, loss = 0.47997379
Iteration 2693, loss = 0.47718031
Iteration 2694, loss = 0.47985273
Iteration 2695, loss = 0.48037158
Iteration 2696, loss = 0.47979600
Iteration 2697, loss = 0.47696965
Iteration 2698, loss = 0.47615101
Iteration 2699, loss = 0.47652302
Iteration 2700, loss = 0.47638813
Iteration 2701, loss = 0.47530279
Iteration 2702, loss = 0.47856780
Iteration 2703, loss = 0.47761338
Iteration 2704, loss = 0.47752491
Iteration 2705, loss = 0.47696652
Iteration 2706, loss = 0.47720350
Iteration 2707, loss = 0.47677440
Iteration 2708, loss = 0.47755968
Iteration 2709, loss = 0.47813445
Iteration 2710, loss = 0.47640281
Iteration 2711, loss = 0.47743442
Iteration 2712, loss = 0.47589514
Iteration 2713, loss = 0.47658494
Iteration 2714, loss = 0.47627242
Iteration 2715, loss = 0.48044918
Iteration 2716, loss = 0.47622987
Iteration 2717, loss = 0.47526721
Iteration 2718, loss = 0.47728828
Iteration 2719, loss = 0.47544389
Iteration 2720, loss = 0.47748238
Iteration 2721, loss = 0.47748246
Iteration 2722, loss = 0.47775596
Iteration 2723, loss = 0.47656783
Iteration 2724, loss = 0.47690833
Iteration 2725, loss = 0.47617830
Iteration 2726, loss = 0.47495649
Iteration 2727, loss = 0.47590854
Iteration 2728, loss = 0.47607220
Iteration 2729, loss = 0.47336886
Iteration 2730, loss = 0.47727232
Iteration 2731, loss = 0.47714065
Iteration 2732, loss = 0.47606975
Iteration 2733, loss = 0.47578476
Iteration 2734, loss = 0.47480421
Iteration 2735, loss = 0.47846647
Iteration 2736, loss = 0.48008187
Iteration 2737, loss = 0.48070843
Iteration 2738, loss = 0.47605674
Iteration 2739, loss = 0.47787030
Iteration 2740, loss = 0.47587897
Iteration 2741, loss = 0.47873782
Iteration 2742, loss = 0.47747312
Iteration 2743, loss = 0.47715139
Iteration 2744, loss = 0.47782576
Iteration 2745, loss = 0.47624811
Iteration 2746, loss = 0.47748830
Iteration 2747, loss = 0.47696752
Iteration 2748, loss = 0.47676144
Iteration 2749, loss = 0.47703284
Iteration 2750, loss = 0.47948872
Iteration 2751, loss = 0.47744829
Iteration 2752, loss = 0.47792767
Iteration 2753, loss = 0.47585341
Iteration 2754, loss = 0.47561318
Iteration 2755, loss = 0.47598787
Iteration 2756, loss = 0.47706157
Iteration 2757, loss = 0.47782895
Iteration 2758, loss = 0.47665853
Iteration 2759, loss = 0.47492449
Iteration 2760, loss = 0.47657916
Iteration 2761, loss = 0.47620296
Iteration 2762, loss = 0.47759793
Iteration 2763, loss = 0.47588450
Iteration 2764, loss = 0.47738554
Iteration 2765, loss = 0.47508609
Iteration 2766, loss = 0.47584138
Iteration 2767, loss = 0.47413651
Iteration 2768, loss = 0.47563771
Iteration 2769, loss = 0.47665074
Iteration 2770, loss = 0.47655416
Iteration 2771, loss = 0.48159012
Iteration 2772, loss = 0.47925815
Iteration 2773, loss = 0.47561427
Iteration 2774, loss = 0.47579162
Iteration 2775, loss = 0.47679223
Iteration 2776, loss = 0.47723135
Iteration 2777, loss = 0.47840934
Iteration 2778, loss = 0.47467888
Iteration 2779, loss = 0.47599117
Iteration 2780, loss = 0.47812044
Iteration 2781, loss = 0.47492569
Iteration 2782, loss = 0.47985185
Iteration 2783, loss = 0.47674670
Iteration 2784, loss = 0.47829134
Iteration 2785, loss = 0.47397010
Iteration 2786, loss = 0.47506469
Iteration 2787, loss = 0.47401544
Iteration 2788, loss = 0.47502639
Iteration 2789, loss = 0.47532448
Iteration 2790, loss = 0.48069352
Iteration 2791, loss = 0.48253219
Iteration 2792, loss = 0.47873758
Iteration 2793, loss = 0.47741946
Iteration 2794, loss = 0.47599681
Iteration 2795, loss = 0.47539561
Iteration 2796, loss = 0.47555670
Iteration 2797, loss = 0.47508609
Iteration 2798, loss = 0.47532622
Iteration 2799, loss = 0.47515409
Iteration 2800, loss = 0.47524585
Iteration 2801, loss = 0.47521827
Iteration 2802, loss = 0.47813354
Iteration 2803, loss = 0.47515046
Iteration 2804, loss = 0.47354624
Iteration 2805, loss = 0.47586280
Iteration 2806, loss = 0.47302997
Iteration 2807, loss = 0.47600043
Iteration 2808, loss = 0.47772250
Iteration 2809, loss = 0.47623953
Iteration 2810, loss = 0.47548113
Iteration 2811, loss = 0.47646110
Iteration 2812, loss = 0.47566679
Iteration 2813, loss = 0.47690963
Iteration 2814, loss = 0.47779907
Iteration 2815, loss = 0.47625082
Iteration 2816, loss = 0.47551373
Iteration 2817, loss = 0.47716194
Iteration 2818, loss = 0.47732867
Iteration 2819, loss = 0.47499864
Iteration 2820, loss = 0.47684689
Iteration 2821, loss = 0.47417829
Iteration 2822, loss = 0.47660325
Iteration 2823, loss = 0.47415054
Iteration 2824, loss = 0.47383296
Iteration 2825, loss = 0.47430743
Iteration 2826, loss = 0.47559705
Iteration 2827, loss = 0.47468269
Iteration 2828, loss = 0.47368932
Iteration 2829, loss = 0.47221862
Iteration 2830, loss = 0.47572390
Iteration 2831, loss = 0.47165789
Iteration 2832, loss = 0.47520516
Iteration 2833, loss = 0.47466975
Iteration 2834, loss = 0.47614532
Iteration 2835, loss = 0.47654625
Iteration 2836, loss = 0.47684970
Iteration 2837, loss = 0.47383402
Iteration 2838, loss = 0.47786465
Iteration 2839, loss = 0.48614394
Iteration 2840, loss = 0.47810283
Iteration 2841, loss = 0.47537076
Iteration 2842, loss = 0.47622320
Iteration 2843, loss = 0.47520115
Iteration 2844, loss = 0.47683117
Iteration 2845, loss = 0.47437697
Iteration 2846, loss = 0.47331529
Iteration 2847, loss = 0.47408277
Iteration 2848, loss = 0.47386527
Iteration 2849, loss = 0.47633199
Iteration 2850, loss = 0.47850576
Iteration 2851, loss = 0.47716092
Iteration 2852, loss = 0.47641909
Iteration 2853, loss = 0.47535249
Iteration 2854, loss = 0.47466551
Iteration 2855, loss = 0.47644904
Iteration 2856, loss = 0.47573603
Iteration 2857, loss = 0.47642551
Iteration 2858, loss = 0.47359226
Iteration 2859, loss = 0.47387544
Iteration 2860, loss = 0.47309901
Iteration 2861, loss = 0.47444591
Iteration 2862, loss = 0.47454785
Iteration 2863, loss = 0.47862240
Iteration 2864, loss = 0.47722416
Iteration 2865, loss = 0.47448950
Iteration 2866, loss = 0.47343510
Iteration 2867, loss = 0.47321599
Iteration 2868, loss = 0.47497998
Iteration 2869, loss = 0.47632402
Iteration 2870, loss = 0.47692846
Iteration 2871, loss = 0.47713133
Iteration 2872, loss = 0.47423281
Iteration 2873, loss = 0.47448784
Iteration 2874, loss = 0.47651293
Iteration 2875, loss = 0.47855683
Iteration 2876, loss = 0.47549394
Iteration 2877, loss = 0.47508206
Iteration 2878, loss = 0.47237689
Iteration 2879, loss = 0.47387254
Iteration 2880, loss = 0.47313325
Iteration 2881, loss = 0.47361486
Iteration 2882, loss = 0.47613591
Iteration 2883, loss = 0.47409882
Iteration 2884, loss = 0.47273906
Iteration 2885, loss = 0.47181785
Iteration 2886, loss = 0.47470218
Iteration 2887, loss = 0.47468446
Iteration 2888, loss = 0.47509991
Iteration 2889, loss = 0.47531373
Iteration 2890, loss = 0.47311557
Iteration 2891, loss = 0.47443162
Iteration 2892, loss = 0.47778865
Iteration 2893, loss = 0.47393410
Iteration 2894, loss = 0.47701151
Iteration 2895, loss = 0.47742912
Iteration 2896, loss = 0.47635497
Iteration 2897, loss = 0.47227983
Iteration 2898, loss = 0.47515363
Iteration 2899, loss = 0.47356737
Iteration 2900, loss = 0.47285831
Iteration 2901, loss = 0.47567743
Iteration 2902, loss = 0.47273475
Iteration 2903, loss = 0.47573390
Iteration 2904, loss = 0.47833905
Iteration 2905, loss = 0.47970959
Iteration 2906, loss = 0.47461159
Iteration 2907, loss = 0.47505618
Iteration 2908, loss = 0.47700403
Iteration 2909, loss = 0.47540015
Iteration 2910, loss = 0.47356211
Iteration 2911, loss = 0.47516371
Iteration 2912, loss = 0.47304206
Iteration 2913, loss = 0.47687573
Iteration 2914, loss = 0.47410333
Iteration 2915, loss = 0.47283277
Iteration 2916, loss = 0.47252117
Iteration 2917, loss = 0.47513488
Iteration 2918, loss = 0.47459014
Iteration 2919, loss = 0.47541972
Iteration 2920, loss = 0.47656495
Iteration 2921, loss = 0.47528944
Iteration 2922, loss = 0.47577432
Iteration 2923, loss = 0.47534299
Iteration 2924, loss = 0.48293276
Iteration 2925, loss = 0.47320998
Iteration 2926, loss = 0.47332715
Iteration 2927, loss = 0.47438209
Iteration 2928, loss = 0.47269770
Iteration 2929, loss = 0.47527361
Iteration 2930, loss = 0.47353981
Iteration 2931, loss = 0.47474715
Iteration 2932, loss = 0.47390796
Iteration 2933, loss = 0.47436679
Iteration 2934, loss = 0.47474440
Iteration 2935, loss = 0.47395324
Iteration 2936, loss = 0.47536630
Iteration 2937, loss = 0.47288389
Iteration 2938, loss = 0.47360204
Iteration 2939, loss = 0.47330681
Iteration 2940, loss = 0.47243855
Iteration 2941, loss = 0.47738060
Iteration 2942, loss = 0.47281972
Iteration 2943, loss = 0.47188822
Iteration 2944, loss = 0.47341947
Iteration 2945, loss = 0.47457372
Iteration 2946, loss = 0.47450776
Iteration 2947, loss = 0.48091309
Iteration 2948, loss = 0.47488817
Iteration 2949, loss = 0.47267138
Iteration 2950, loss = 0.47421694
Iteration 2951, loss = 0.47792861
Iteration 2952, loss = 0.48117759
Iteration 2953, loss = 0.47407735
Iteration 2954, loss = 0.47328924
Iteration 2955, loss = 0.47486079
Iteration 2956, loss = 0.47724434
Iteration 2957, loss = 0.47865458
Iteration 2958, loss = 0.47513087
Iteration 2959, loss = 0.47703153
Iteration 2960, loss = 0.47361811
Iteration 2961, loss = 0.47639324
Iteration 2962, loss = 0.47331714
Iteration 2963, loss = 0.47405105
Iteration 2964, loss = 0.47302320
Iteration 2965, loss = 0.47254486
Iteration 2966, loss = 0.47420782
Iteration 2967, loss = 0.47581993
Iteration 2968, loss = 0.47390400
Iteration 2969, loss = 0.47700728
Iteration 2970, loss = 0.47201180
Iteration 2971, loss = 0.47953084
Iteration 2972, loss = 0.47299635
Iteration 2973, loss = 0.47497518
Iteration 2974, loss = 0.47501507
Iteration 2975, loss = 0.47427503
Iteration 2976, loss = 0.47218671
Iteration 2977, loss = 0.47747460
Iteration 2978, loss = 0.47408139
Iteration 2979, loss = 0.47348986
Iteration 2980, loss = 0.47476980
Iteration 2981, loss = 0.47503300
Iteration 2982, loss = 0.47152278
Iteration 2983, loss = 0.47580195
Iteration 2984, loss = 0.47307952
Iteration 2985, loss = 0.47796158
Iteration 2986, loss = 0.47376219
Iteration 2987, loss = 0.47228436
Iteration 2988, loss = 0.47741623
Iteration 2989, loss = 0.47333650
Iteration 2990, loss = 0.47272525
Iteration 2991, loss = 0.47283191
Iteration 2992, loss = 0.47381476
Iteration 2993, loss = 0.47213138
Iteration 2994, loss = 0.47359379
Iteration 2995, loss = 0.47414832
Iteration 2996, loss = 0.47333818
Iteration 2997, loss = 0.47668412
Iteration 2998, loss = 0.47353241
Iteration 2999, loss = 0.47267078
Iteration 3000, loss = 0.47297215
Iteration 3001, loss = 0.47593758
Iteration 3002, loss = 0.47192448
Iteration 3003, loss = 0.47318889
Iteration 3004, loss = 0.47132435
Iteration 3005, loss = 0.47517277
Iteration 3006, loss = 0.47444191
Iteration 3007, loss = 0.47482480
Iteration 3008, loss = 0.47253112
Iteration 3009, loss = 0.47494023
Iteration 3010, loss = 0.47219615
Iteration 3011, loss = 0.47717516
Iteration 3012, loss = 0.47565432
Iteration 3013, loss = 0.47218486
Iteration 3014, loss = 0.47239355
Iteration 3015, loss = 0.47222681
Iteration 3016, loss = 0.47299466
Iteration 3017, loss = 0.47118994
Iteration 3018, loss = 0.47446581
Iteration 3019, loss = 0.47608843
Iteration 3020, loss = 0.47458886
Iteration 3021, loss = 0.47468920
Iteration 3022, loss = 0.47604539
Iteration 3023, loss = 0.47415143
Iteration 3024, loss = 0.47320399
Iteration 3025, loss = 0.47370714
Iteration 3026, loss = 0.47189459
Iteration 3027, loss = 0.47198398
Iteration 3028, loss = 0.47311949
Iteration 3029, loss = 0.47195977
Iteration 3030, loss = 0.47330624
Iteration 3031, loss = 0.47511021
Iteration 3032, loss = 0.47400862
Iteration 3033, loss = 0.47738246
Iteration 3034, loss = 0.47463287
Iteration 3035, loss = 0.47308835
Iteration 3036, loss = 0.47502912
Iteration 3037, loss = 0.47109843
Iteration 3038, loss = 0.47428248
Iteration 3039, loss = 0.47508553
Iteration 3040, loss = 0.47424548
Iteration 3041, loss = 0.47212419
Iteration 3042, loss = 0.47265092
Iteration 3043, loss = 0.47247640
Iteration 3044, loss = 0.47660003
Iteration 3045, loss = 0.47448350
Iteration 3046, loss = 0.47321415
Iteration 3047, loss = 0.47218518
Iteration 3048, loss = 0.47046130
Iteration 3049, loss = 0.47261299
Iteration 3050, loss = 0.47714828
Iteration 3051, loss = 0.47480475
Iteration 3052, loss = 0.47393975
Iteration 3053, loss = 0.47236521
Iteration 3054, loss = 0.47344927
Iteration 3055, loss = 0.48026875
Iteration 3056, loss = 0.47749287
Iteration 3057, loss = 0.47281009
Iteration 3058, loss = 0.47243655
Iteration 3059, loss = 0.47233489
Iteration 3060, loss = 0.47383916
Iteration 3061, loss = 0.47418065
Iteration 3062, loss = 0.47623296
Iteration 3063, loss = 0.47209173
Iteration 3064, loss = 0.47192984
Iteration 3065, loss = 0.47277309
Iteration 3066, loss = 0.47283221
Iteration 3067, loss = 0.47443533
Iteration 3068, loss = 0.47282475
Iteration 3069, loss = 0.46972669
Iteration 3070, loss = 0.47326594
Iteration 3071, loss = 0.47198989
Iteration 3072, loss = 0.47451231
Iteration 3073, loss = 0.47452600
Iteration 3074, loss = 0.47318478
Iteration 3075, loss = 0.47178353
Iteration 3076, loss = 0.47422289
Iteration 3077, loss = 0.47037519
Iteration 3078, loss = 0.47315174
Iteration 3079, loss = 0.47129189
Iteration 3080, loss = 0.47236531
Iteration 3081, loss = 0.47083202
Iteration 3082, loss = 0.47276924
Iteration 3083, loss = 0.47081501
Iteration 3084, loss = 0.47300350
Iteration 3085, loss = 0.47323227
Iteration 3086, loss = 0.47469841
Iteration 3087, loss = 0.47381172
Iteration 3088, loss = 0.47402932
Iteration 3089, loss = 0.47589457
Iteration 3090, loss = 0.47737661
Iteration 3091, loss = 0.47415593
Iteration 3092, loss = 0.47297151
Iteration 3093, loss = 0.47148256
Iteration 3094, loss = 0.47181919
Iteration 3095, loss = 0.47204758
Iteration 3096, loss = 0.47466201
Iteration 3097, loss = 0.47181589
Iteration 3098, loss = 0.47334784
Iteration 3099, loss = 0.47298095
Iteration 3100, loss = 0.47150469
Iteration 3101, loss = 0.47429203
Iteration 3102, loss = 0.47194683
Iteration 3103, loss = 0.47497240
Iteration 3104, loss = 0.47165307
Iteration 3105, loss = 0.47154190
Iteration 3106, loss = 0.47035894
Iteration 3107, loss = 0.47304468
Iteration 3108, loss = 0.47396272
Iteration 3109, loss = 0.47474471
Iteration 3110, loss = 0.47303813
Iteration 3111, loss = 0.47341415
Iteration 3112, loss = 0.47465499
Iteration 3113, loss = 0.47758020
Iteration 3114, loss = 0.47254994
Iteration 3115, loss = 0.47283933
Iteration 3116, loss = 0.47368942
Iteration 3117, loss = 0.47396982
Iteration 3118, loss = 0.47308038
Iteration 3119, loss = 0.47082053
Iteration 3120, loss = 0.47448779
Iteration 3121, loss = 0.47289268
Iteration 3122, loss = 0.47299950
Iteration 3123, loss = 0.47643610
Iteration 3124, loss = 0.47348576
Iteration 3125, loss = 0.47251816
Iteration 3126, loss = 0.47079649
Iteration 3127, loss = 0.47906770
Iteration 3128, loss = 0.47461353
Iteration 3129, loss = 0.47149907
Iteration 3130, loss = 0.47138342
Iteration 3131, loss = 0.47263795
Iteration 3132, loss = 0.47151328
Iteration 3133, loss = 0.47241696
Iteration 3134, loss = 0.47537882
Iteration 3135, loss = 0.47211834
Iteration 3136, loss = 0.47127568
Iteration 3137, loss = 0.47180324
Iteration 3138, loss = 0.47263032
Iteration 3139, loss = 0.47149525
Iteration 3140, loss = 0.47074815
Iteration 3141, loss = 0.47397364
Iteration 3142, loss = 0.47442590
Iteration 3143, loss = 0.47298696
Iteration 3144, loss = 0.47171208
Iteration 3145, loss = 0.47224912
Iteration 3146, loss = 0.47063557
Iteration 3147, loss = 0.47038239
Iteration 3148, loss = 0.47160984
Iteration 3149, loss = 0.47562262
Iteration 3150, loss = 0.47086035
Iteration 3151, loss = 0.47067137
Iteration 3152, loss = 0.47216855
Iteration 3153, loss = 0.47209630
Iteration 3154, loss = 0.47145002
Iteration 3155, loss = 0.47319800
Iteration 3156, loss = 0.47420225
Iteration 3157, loss = 0.47162898
Iteration 3158, loss = 0.47249698
Iteration 3159, loss = 0.47204489
Iteration 3160, loss = 0.47045660
Iteration 3161, loss = 0.47195476
Iteration 3162, loss = 0.47403912
Iteration 3163, loss = 0.47300014
Iteration 3164, loss = 0.47392038
Iteration 3165, loss = 0.47236516
Iteration 3166, loss = 0.47172351
Iteration 3167, loss = 0.47168770
Iteration 3168, loss = 0.47367558
Iteration 3169, loss = 0.47192396
Iteration 3170, loss = 0.47418970
Iteration 3171, loss = 0.47149001
Iteration 3172, loss = 0.47457482
Iteration 3173, loss = 0.47170085
Iteration 3174, loss = 0.47375420
Iteration 3175, loss = 0.47007620
Iteration 3176, loss = 0.47024476
Iteration 3177, loss = 0.47143712
Iteration 3178, loss = 0.46956464
Iteration 3179, loss = 0.47220919
Iteration 3180, loss = 0.47304764
Iteration 3181, loss = 0.47351813
Iteration 3182, loss = 0.47276824
Iteration 3183, loss = 0.47415287
Iteration 3184, loss = 0.47430333
Iteration 3185, loss = 0.47388737
Iteration 3186, loss = 0.47381710
Iteration 3187, loss = 0.47513588
Iteration 3188, loss = 0.47381267
Iteration 3189, loss = 0.47411816
Iteration 3190, loss = 0.47101543
Iteration 3191, loss = 0.47093524
Iteration 3192, loss = 0.47164818
Iteration 3193, loss = 0.47321606
Iteration 3194, loss = 0.47243852
Iteration 3195, loss = 0.47047665
Iteration 3196, loss = 0.47091749
Iteration 3197, loss = 0.47136227
Iteration 3198, loss = 0.47012729
Iteration 3199, loss = 0.46986195
Iteration 3200, loss = 0.47122137
Iteration 3201, loss = 0.47120469
Iteration 3202, loss = 0.47382089
Iteration 3203, loss = 0.47252579
Iteration 3204, loss = 0.47227659
Iteration 3205, loss = 0.47207882
Iteration 3206, loss = 0.47052305
Iteration 3207, loss = 0.47191225
Iteration 3208, loss = 0.47153260
Iteration 3209, loss = 0.47234289
Iteration 3210, loss = 0.47123190
Iteration 3211, loss = 0.47039235
Iteration 3212, loss = 0.47131163
Iteration 3213, loss = 0.47067955
Iteration 3214, loss = 0.47459579
Iteration 3215, loss = 0.47171820
Iteration 3216, loss = 0.47212392
Iteration 3217, loss = 0.47548316
Iteration 3218, loss = 0.47191926
Iteration 3219, loss = 0.47012324
Iteration 3220, loss = 0.47304839
Iteration 3221, loss = 0.47250271
Iteration 3222, loss = 0.46954791
Iteration 3223, loss = 0.46994814
Iteration 3224, loss = 0.47041265
Iteration 3225, loss = 0.47210457
Iteration 3226, loss = 0.47032895
Iteration 3227, loss = 0.47051642
Iteration 3228, loss = 0.47186412
Iteration 3229, loss = 0.46976122
Iteration 3230, loss = 0.47108877
Iteration 3231, loss = 0.47045235
Iteration 3232, loss = 0.47189004
Iteration 3233, loss = 0.46996624
Iteration 3234, loss = 0.47054913
Iteration 3235, loss = 0.47102791
Iteration 3236, loss = 0.47276639
Iteration 3237, loss = 0.47197018
Iteration 3238, loss = 0.47010534
Iteration 3239, loss = 0.46968741
Iteration 3240, loss = 0.46815147
Iteration 3241, loss = 0.47113122
Iteration 3242, loss = 0.47184963
Iteration 3243, loss = 0.47083508
Iteration 3244, loss = 0.47429173
Iteration 3245, loss = 0.47339003
Iteration 3246, loss = 0.46911036
Iteration 3247, loss = 0.47206935
Iteration 3248, loss = 0.47042394
Iteration 3249, loss = 0.47225082
Iteration 3250, loss = 0.47095577
Iteration 3251, loss = 0.47112779
Iteration 3252, loss = 0.47435521
Iteration 3253, loss = 0.47200143
Iteration 3254, loss = 0.47216154
Iteration 3255, loss = 0.47135446
Iteration 3256, loss = 0.47094623
Iteration 3257, loss = 0.47250492
Iteration 3258, loss = 0.47254491
Iteration 3259, loss = 0.47229771
Iteration 3260, loss = 0.47180861
Iteration 3261, loss = 0.47014595
Iteration 3262, loss = 0.46959628
Iteration 3263, loss = 0.47162718
Iteration 3264, loss = 0.46828728
Iteration 3265, loss = 0.47163968
Iteration 3266, loss = 0.47286892
Iteration 3267, loss = 0.47471986
Iteration 3268, loss = 0.47384674
Iteration 3269, loss = 0.47112879
Iteration 3270, loss = 0.46948836
Iteration 3271, loss = 0.47115898
Iteration 3272, loss = 0.47022441
Iteration 3273, loss = 0.47065837
Iteration 3274, loss = 0.46929058
Iteration 3275, loss = 0.46985070
Iteration 3276, loss = 0.46936472
Iteration 3277, loss = 0.47035224
Iteration 3278, loss = 0.46839630
Iteration 3279, loss = 0.47146895
Iteration 3280, loss = 0.47341697
Iteration 3281, loss = 0.47422006
Iteration 3282, loss = 0.47011183
Iteration 3283, loss = 0.47493997
Iteration 3284, loss = 0.47184238
Iteration 3285, loss = 0.47104046
Iteration 3286, loss = 0.47344795
Iteration 3287, loss = 0.47147254
Iteration 3288, loss = 0.47069068
Iteration 3289, loss = 0.47048735
Iteration 3290, loss = 0.47036720
Iteration 3291, loss = 0.47023038
Iteration 3292, loss = 0.46996832
Iteration 3293, loss = 0.47020893
Iteration 3294, loss = 0.47156757
Iteration 3295, loss = 0.47337943
Iteration 3296, loss = 0.47293214
Iteration 3297, loss = 0.47014160
Iteration 3298, loss = 0.46930520
Iteration 3299, loss = 0.46840641
Iteration 3300, loss = 0.47295943
Iteration 3301, loss = 0.47227092
Iteration 3302, loss = 0.46991130
Iteration 3303, loss = 0.46968602
Iteration 3304, loss = 0.46929190
Iteration 3305, loss = 0.47455499
Iteration 3306, loss = 0.46904984
Iteration 3307, loss = 0.47320445
Iteration 3308, loss = 0.46953703
Iteration 3309, loss = 0.46925114
Iteration 3310, loss = 0.47174876
Iteration 3311, loss = 0.47451694
Iteration 3312, loss = 0.47043880
Iteration 3313, loss = 0.47125501
Iteration 3314, loss = 0.47272422
Iteration 3315, loss = 0.47304473
Iteration 3316, loss = 0.47096105
Iteration 3317, loss = 0.47219315
Iteration 3318, loss = 0.47042709
Iteration 3319, loss = 0.47061460
Iteration 3320, loss = 0.47029260
Iteration 3321, loss = 0.46990972
Iteration 3322, loss = 0.47207647
Iteration 3323, loss = 0.47164707
Iteration 3324, loss = 0.46990417
Iteration 3325, loss = 0.47095864
Iteration 3326, loss = 0.47034428
Iteration 3327, loss = 0.46962531
Iteration 3328, loss = 0.46765282
Iteration 3329, loss = 0.46919123
Iteration 3330, loss = 0.46984561
Iteration 3331, loss = 0.47034379
Iteration 3332, loss = 0.46997361
Iteration 3333, loss = 0.46916595
Iteration 3334, loss = 0.46895325
Iteration 3335, loss = 0.46889552
Iteration 3336, loss = 0.47196786
Iteration 3337, loss = 0.47076933
Iteration 3338, loss = 0.47487522
Iteration 3339, loss = 0.47100471
Iteration 3340, loss = 0.46947943
Iteration 3341, loss = 0.46898537
Iteration 3342, loss = 0.46964030
Iteration 3343, loss = 0.47315100
Iteration 3344, loss = 0.47466868
Iteration 3345, loss = 0.46947769
Iteration 3346, loss = 0.47017195
Iteration 3347, loss = 0.47264327
Iteration 3348, loss = 0.47375642
Iteration 3349, loss = 0.47371626
Iteration 3350, loss = 0.47396542
Iteration 3351, loss = 0.47597914
Iteration 3352, loss = 0.47241343
Iteration 3353, loss = 0.46869715
Iteration 3354, loss = 0.46948233
Iteration 3355, loss = 0.46722871
Iteration 3356, loss = 0.46981978
Iteration 3357, loss = 0.46904952
Iteration 3358, loss = 0.47012281
Iteration 3359, loss = 0.47075820
Iteration 3360, loss = 0.46928866
Iteration 3361, loss = 0.46759079
Iteration 3362, loss = 0.46804989
Iteration 3363, loss = 0.47186390
Iteration 3364, loss = 0.46884036
Iteration 3365, loss = 0.46939319
Iteration 3366, loss = 0.46787689
Iteration 3367, loss = 0.46888358
Iteration 3368, loss = 0.46825213
Iteration 3369, loss = 0.46882553
Iteration 3370, loss = 0.47193100
Iteration 3371, loss = 0.47013796
Iteration 3372, loss = 0.47222932
Iteration 3373, loss = 0.46895229
Iteration 3374, loss = 0.46988091
Iteration 3375, loss = 0.47487583
Iteration 3376, loss = 0.47768791
Iteration 3377, loss = 0.47078902
Iteration 3378, loss = 0.46856791
Iteration 3379, loss = 0.46736535
Iteration 3380, loss = 0.47043452
Iteration 3381, loss = 0.47302627
Iteration 3382, loss = 0.47020926
Iteration 3383, loss = 0.47151698
Iteration 3384, loss = 0.46852945
Iteration 3385, loss = 0.46805640
Iteration 3386, loss = 0.47013836
Iteration 3387, loss = 0.47083145
Iteration 3388, loss = 0.46882965
Iteration 3389, loss = 0.46793649
Iteration 3390, loss = 0.47047522
Iteration 3391, loss = 0.47029903
Iteration 3392, loss = 0.46999162
Iteration 3393, loss = 0.46815847
Iteration 3394, loss = 0.46760498
Iteration 3395, loss = 0.46923808
Iteration 3396, loss = 0.46869144
Iteration 3397, loss = 0.46976991
Iteration 3398, loss = 0.46866747
Iteration 3399, loss = 0.46795054
Iteration 3400, loss = 0.46838274
Iteration 3401, loss = 0.46764222
Iteration 3402, loss = 0.46890000
Iteration 3403, loss = 0.46854198
Iteration 3404, loss = 0.46605524
Iteration 3405, loss = 0.46842609
Iteration 3406, loss = 0.46841533
Iteration 3407, loss = 0.46637248
Iteration 3408, loss = 0.47086747
Iteration 3409, loss = 0.47272074
Iteration 3410, loss = 0.46930566
Iteration 3411, loss = 0.46804396
Iteration 3412, loss = 0.46826710
Iteration 3413, loss = 0.46685366
Iteration 3414, loss = 0.47166134
Iteration 3415, loss = 0.47176809
Iteration 3416, loss = 0.47148275
Iteration 3417, loss = 0.46813668
Iteration 3418, loss = 0.47237129
Iteration 3419, loss = 0.46996168
Iteration 3420, loss = 0.47151491
Iteration 3421, loss = 0.46973954
Iteration 3422, loss = 0.47024047
Iteration 3423, loss = 0.47060613
Iteration 3424, loss = 0.47010674
Iteration 3425, loss = 0.47077603
Iteration 3426, loss = 0.47024251
Iteration 3427, loss = 0.46980367
Iteration 3428, loss = 0.46829454
Iteration 3429, loss = 0.47152205
Iteration 3430, loss = 0.47185886
Iteration 3431, loss = 0.47181416
Iteration 3432, loss = 0.47111785
Iteration 3433, loss = 0.46951216
Iteration 3434, loss = 0.46976876
Iteration 3435, loss = 0.47169501
Iteration 3436, loss = 0.46789027
Iteration 3437, loss = 0.46788465
Iteration 3438, loss = 0.46864284
Iteration 3439, loss = 0.47061166
Iteration 3440, loss = 0.47206529
Iteration 3441, loss = 0.47088441
Iteration 3442, loss = 0.46817805
Iteration 3443, loss = 0.46962354
Iteration 3444, loss = 0.46817724
Iteration 3445, loss = 0.46939924
Iteration 3446, loss = 0.46729521
Iteration 3447, loss = 0.47020687
Iteration 3448, loss = 0.47006399
Iteration 3449, loss = 0.47121935
Iteration 3450, loss = 0.46961326
Iteration 3451, loss = 0.47022632
Iteration 3452, loss = 0.46951338
Iteration 3453, loss = 0.46977149
Iteration 3454, loss = 0.46798870
Iteration 3455, loss = 0.46740265
Iteration 3456, loss = 0.46675438
Iteration 3457, loss = 0.46991060
Iteration 3458, loss = 0.46991271
Iteration 3459, loss = 0.47241925
Iteration 3460, loss = 0.47014743
Iteration 3461, loss = 0.47044831
Iteration 3462, loss = 0.46851855
Iteration 3463, loss = 0.46875971
Iteration 3464, loss = 0.46642458
Iteration 3465, loss = 0.46802186
Iteration 3466, loss = 0.47028316
Iteration 3467, loss = 0.46791854
Iteration 3468, loss = 0.46644765
Iteration 3469, loss = 0.46682601
Iteration 3470, loss = 0.46965353
Iteration 3471, loss = 0.46937782
Iteration 3472, loss = 0.46914645
Iteration 3473, loss = 0.46817270
Iteration 3474, loss = 0.47023636
Iteration 3475, loss = 0.47014305
Iteration 3476, loss = 0.46819203
Iteration 3477, loss = 0.46901121
Iteration 3478, loss = 0.46746753
Iteration 3479, loss = 0.46997947
Iteration 3480, loss = 0.47296573
Iteration 3481, loss = 0.47240804
Iteration 3482, loss = 0.47087881
Iteration 3483, loss = 0.46682130
Iteration 3484, loss = 0.46858265
Iteration 3485, loss = 0.46715445
Iteration 3486, loss = 0.46924664
Iteration 3487, loss = 0.46765429
Iteration 3488, loss = 0.46705246
Iteration 3489, loss = 0.46968518
Iteration 3490, loss = 0.46687467
Iteration 3491, loss = 0.46766042
Iteration 3492, loss = 0.46629534
Iteration 3493, loss = 0.47223102
Iteration 3494, loss = 0.47073335
Iteration 3495, loss = 0.46902393
Iteration 3496, loss = 0.46865609
Iteration 3497, loss = 0.46796279
Iteration 3498, loss = 0.46801007
Iteration 3499, loss = 0.46709540
Iteration 3500, loss = 0.46934501
Iteration 3501, loss = 0.46830374
Iteration 3502, loss = 0.47068146
Iteration 3503, loss = 0.46866905
Iteration 3504, loss = 0.46882239
Iteration 3505, loss = 0.46531698
Iteration 3506, loss = 0.46564710
Iteration 3507, loss = 0.46631219
Iteration 3508, loss = 0.47035802
Iteration 3509, loss = 0.46926131
Iteration 3510, loss = 0.46877776
Iteration 3511, loss = 0.46721677
Iteration 3512, loss = 0.46982803
Iteration 3513, loss = 0.47077834
Iteration 3514, loss = 0.47018100
Iteration 3515, loss = 0.46910881
Iteration 3516, loss = 0.47119118
Iteration 3517, loss = 0.46876815
Iteration 3518, loss = 0.46765481
Iteration 3519, loss = 0.46754641
Iteration 3520, loss = 0.46720728
Iteration 3521, loss = 0.46821840
Iteration 3522, loss = 0.46942837
Iteration 3523, loss = 0.46938886
Iteration 3524, loss = 0.46996262
Iteration 3525, loss = 0.46813490
Iteration 3526, loss = 0.46912629
Iteration 3527, loss = 0.46834967
Iteration 3528, loss = 0.46823245
Iteration 3529, loss = 0.46715581
Iteration 3530, loss = 0.46833699
Iteration 3531, loss = 0.46691392
Iteration 3532, loss = 0.47109979
Iteration 3533, loss = 0.46820877
Iteration 3534, loss = 0.47346015
Iteration 3535, loss = 0.47855831
Iteration 3536, loss = 0.46910641
Iteration 3537, loss = 0.47151647
Iteration 3538, loss = 0.46923442
Iteration 3539, loss = 0.47142720
Iteration 3540, loss = 0.46657606
Iteration 3541, loss = 0.46914282
Iteration 3542, loss = 0.46879194
Iteration 3543, loss = 0.47138994
Iteration 3544, loss = 0.46965431
Iteration 3545, loss = 0.46767948
Iteration 3546, loss = 0.46783014
Iteration 3547, loss = 0.46803993
Iteration 3548, loss = 0.47050756
Iteration 3549, loss = 0.46702062
Iteration 3550, loss = 0.46996132
Iteration 3551, loss = 0.46761192
Iteration 3552, loss = 0.46891488
Iteration 3553, loss = 0.46776802
Iteration 3554, loss = 0.46771060
Iteration 3555, loss = 0.46855549
Iteration 3556, loss = 0.46958841
Iteration 3557, loss = 0.46647510
Iteration 3558, loss = 0.46964845
Iteration 3559, loss = 0.46505769
Iteration 3560, loss = 0.46872925
Iteration 3561, loss = 0.46906455
Iteration 3562, loss = 0.46724227
Iteration 3563, loss = 0.47019781
Iteration 3564, loss = 0.46688533
Iteration 3565, loss = 0.46878276
Iteration 3566, loss = 0.46845520
Iteration 3567, loss = 0.46982176
Iteration 3568, loss = 0.46705822
Iteration 3569, loss = 0.46846746
Iteration 3570, loss = 0.46887601
Iteration 3571, loss = 0.46710748
Iteration 3572, loss = 0.46960267
Iteration 3573, loss = 0.46565637
Iteration 3574, loss = 0.46736853
Iteration 3575, loss = 0.46781132
Iteration 3576, loss = 0.46788988
Iteration 3577, loss = 0.46521541
Iteration 3578, loss = 0.46760638
Iteration 3579, loss = 0.46698505
Iteration 3580, loss = 0.46627092
Iteration 3581, loss = 0.46617532
Iteration 3582, loss = 0.47026097
Iteration 3583, loss = 0.46878135
Iteration 3584, loss = 0.46570985
Iteration 3585, loss = 0.46573086
Iteration 3586, loss = 0.46638575
Iteration 3587, loss = 0.46638897
Iteration 3588, loss = 0.46980121
Iteration 3589, loss = 0.47224513
Iteration 3590, loss = 0.46789749
Iteration 3591, loss = 0.46719024
Iteration 3592, loss = 0.46738272
Iteration 3593, loss = 0.46846444
Iteration 3594, loss = 0.46632159
Iteration 3595, loss = 0.46813681
Iteration 3596, loss = 0.46776813
Iteration 3597, loss = 0.46694093
Iteration 3598, loss = 0.46770571
Iteration 3599, loss = 0.46774186
Iteration 3600, loss = 0.46913990
Iteration 3601, loss = 0.46789152
Iteration 3602, loss = 0.46659166
Iteration 3603, loss = 0.46985994
Iteration 3604, loss = 0.46968883
Iteration 3605, loss = 0.46770113
Iteration 3606, loss = 0.46637860
Iteration 3607, loss = 0.46716715
Iteration 3608, loss = 0.46846428
Iteration 3609, loss = 0.46857560
Iteration 3610, loss = 0.46504151
Iteration 3611, loss = 0.46854469
Iteration 3612, loss = 0.46901371
Iteration 3613, loss = 0.46757789
Iteration 3614, loss = 0.46735871
Iteration 3615, loss = 0.46598025
Iteration 3616, loss = 0.46671758
Iteration 3617, loss = 0.46549782
Iteration 3618, loss = 0.46543593
Iteration 3619, loss = 0.46745056
Iteration 3620, loss = 0.46727956
Iteration 3621, loss = 0.46658187
Iteration 3622, loss = 0.46571284
Iteration 3623, loss = 0.46633421
Iteration 3624, loss = 0.46715996
Iteration 3625, loss = 0.46979148
Iteration 3626, loss = 0.46705132
Iteration 3627, loss = 0.46852586
Iteration 3628, loss = 0.46969472
Iteration 3629, loss = 0.46850445
Iteration 3630, loss = 0.47033411
Iteration 3631, loss = 0.46599446
Iteration 3632, loss = 0.46761839
Iteration 3633, loss = 0.46921406
Iteration 3634, loss = 0.46725583
Iteration 3635, loss = 0.46560332
Iteration 3636, loss = 0.46545718
Iteration 3637, loss = 0.46679711
Iteration 3638, loss = 0.46512289
Iteration 3639, loss = 0.46688921
Iteration 3640, loss = 0.46926592
Iteration 3641, loss = 0.46694188
Iteration 3642, loss = 0.46754705
Iteration 3643, loss = 0.46678207
Iteration 3644, loss = 0.46695434
Iteration 3645, loss = 0.46575603
Iteration 3646, loss = 0.46910860
Iteration 3647, loss = 0.46829709
Iteration 3648, loss = 0.46639121
Iteration 3649, loss = 0.46881438
Iteration 3650, loss = 0.46569806
Iteration 3651, loss = 0.46571416
Iteration 3652, loss = 0.46608601
Iteration 3653, loss = 0.46631109
Iteration 3654, loss = 0.46743973
Iteration 3655, loss = 0.46913317
Iteration 3656, loss = 0.46709745
Iteration 3657, loss = 0.46631296
Iteration 3658, loss = 0.46661665
Iteration 3659, loss = 0.46694134
Iteration 3660, loss = 0.46647128
Iteration 3661, loss = 0.46715457
Iteration 3662, loss = 0.46658095
Iteration 3663, loss = 0.46726645
Iteration 3664, loss = 0.46776258
Iteration 3665, loss = 0.46680989
Iteration 3666, loss = 0.46638506
Iteration 3667, loss = 0.46668659
Iteration 3668, loss = 0.46517095
Iteration 3669, loss = 0.46527996
Iteration 3670, loss = 0.46747774
Iteration 3671, loss = 0.46543771
Iteration 3672, loss = 0.46729251
Iteration 3673, loss = 0.46796334
Iteration 3674, loss = 0.46710691
Iteration 3675, loss = 0.46639925
Iteration 3676, loss = 0.47149159
Iteration 3677, loss = 0.46568747
Iteration 3678, loss = 0.46937237
Iteration 3679, loss = 0.46440287
Iteration 3680, loss = 0.46797310
Iteration 3681, loss = 0.46624039
Iteration 3682, loss = 0.46767240
Iteration 3683, loss = 0.46824296
Iteration 3684, loss = 0.46823778
Iteration 3685, loss = 0.46746123
Iteration 3686, loss = 0.46746283
Iteration 3687, loss = 0.46638546
Iteration 3688, loss = 0.46445935
Iteration 3689, loss = 0.46370580
Iteration 3690, loss = 0.46342103
Iteration 3691, loss = 0.46815048
Iteration 3692, loss = 0.46734809
Iteration 3693, loss = 0.46575014
Iteration 3694, loss = 0.46570920
Iteration 3695, loss = 0.46804461
Iteration 3696, loss = 0.46880976
Iteration 3697, loss = 0.46656892
Iteration 3698, loss = 0.46558733
Iteration 3699, loss = 0.46417341
Iteration 3700, loss = 0.46471288
Iteration 3701, loss = 0.46878967
Iteration 3702, loss = 0.46400578
Iteration 3703, loss = 0.46903988
Iteration 3704, loss = 0.46708313
Iteration 3705, loss = 0.46683785
Iteration 3706, loss = 0.46875581
Iteration 3707, loss = 0.46567193
Iteration 3708, loss = 0.46557675
Iteration 3709, loss = 0.46504965
Iteration 3710, loss = 0.46595758
Iteration 3711, loss = 0.46577981
Iteration 3712, loss = 0.46698504
Iteration 3713, loss = 0.46285972
Iteration 3714, loss = 0.46858584
Iteration 3715, loss = 0.46877321
Iteration 3716, loss = 0.46581285
Iteration 3717, loss = 0.46861114
Iteration 3718, loss = 0.46786406
Iteration 3719, loss = 0.46537594
Iteration 3720, loss = 0.46555755
Iteration 3721, loss = 0.46585801
Iteration 3722, loss = 0.46611999
Iteration 3723, loss = 0.46406648
Iteration 3724, loss = 0.46371675
Iteration 3725, loss = 0.46457444
Iteration 3726, loss = 0.46975982
Iteration 3727, loss = 0.46535897
Iteration 3728, loss = 0.46802277
Iteration 3729, loss = 0.46550301
Iteration 3730, loss = 0.46377219
Iteration 3731, loss = 0.46563632
Iteration 3732, loss = 0.46881133
Iteration 3733, loss = 0.46456977
Iteration 3734, loss = 0.46678526
Iteration 3735, loss = 0.46918371
Iteration 3736, loss = 0.46600163
Iteration 3737, loss = 0.46616734
Iteration 3738, loss = 0.46453750
Iteration 3739, loss = 0.46670752
Iteration 3740, loss = 0.46776901
Iteration 3741, loss = 0.46500964
Iteration 3742, loss = 0.46631997
Iteration 3743, loss = 0.46612923
Iteration 3744, loss = 0.46533492
Iteration 3745, loss = 0.46824001
Iteration 3746, loss = 0.46875665
Iteration 3747, loss = 0.46709581
Iteration 3748, loss = 0.46397926
Iteration 3749, loss = 0.46487007
Iteration 3750, loss = 0.46593169
Iteration 3751, loss = 0.46420448
Iteration 3752, loss = 0.46692326
Iteration 3753, loss = 0.46446558
Iteration 3754, loss = 0.46446573
Iteration 3755, loss = 0.46521196
Iteration 3756, loss = 0.46530345
Iteration 3757, loss = 0.47063433
Iteration 3758, loss = 0.46743406
Iteration 3759, loss = 0.46595110
Iteration 3760, loss = 0.46683733
Iteration 3761, loss = 0.46617159
Iteration 3762, loss = 0.46685294
Iteration 3763, loss = 0.46591979
Iteration 3764, loss = 0.46377924
Iteration 3765, loss = 0.46839690
Iteration 3766, loss = 0.46546331
Iteration 3767, loss = 0.46602565
Iteration 3768, loss = 0.46581370
Iteration 3769, loss = 0.46287175
Iteration 3770, loss = 0.46423713
Iteration 3771, loss = 0.46464187
Iteration 3772, loss = 0.46408555
Iteration 3773, loss = 0.46732409
Iteration 3774, loss = 0.46644332
Iteration 3775, loss = 0.47065176
Iteration 3776, loss = 0.46732578
Iteration 3777, loss = 0.46913383
Iteration 3778, loss = 0.46813604
Iteration 3779, loss = 0.46270253
Iteration 3780, loss = 0.46299744
Iteration 3781, loss = 0.46305204
Iteration 3782, loss = 0.46221876
Iteration 3783, loss = 0.46432047
Iteration 3784, loss = 0.46682409
Iteration 3785, loss = 0.46524168
Iteration 3786, loss = 0.46587719
Iteration 3787, loss = 0.46624245
Iteration 3788, loss = 0.46321030
Iteration 3789, loss = 0.46568473
Iteration 3790, loss = 0.46823843
Iteration 3791, loss = 0.47110256
Iteration 3792, loss = 0.46909924
Iteration 3793, loss = 0.46596589
Iteration 3794, loss = 0.46691372
Iteration 3795, loss = 0.46481508
Iteration 3796, loss = 0.46577101
Iteration 3797, loss = 0.46492612
Iteration 3798, loss = 0.46515962
Iteration 3799, loss = 0.46844640
Iteration 3800, loss = 0.46571163
Iteration 3801, loss = 0.46403290
Iteration 3802, loss = 0.46456849
Iteration 3803, loss = 0.46432735
Iteration 3804, loss = 0.46493192
Iteration 3805, loss = 0.46864483
Iteration 3806, loss = 0.46341008
Iteration 3807, loss = 0.46926672
Iteration 3808, loss = 0.46457704
Iteration 3809, loss = 0.46626165
Iteration 3810, loss = 0.46743889
Iteration 3811, loss = 0.46499148
Iteration 3812, loss = 0.46674252
Iteration 3813, loss = 0.46448098
Iteration 3814, loss = 0.46685770
Iteration 3815, loss = 0.46762439
Iteration 3816, loss = 0.46705983
Iteration 3817, loss = 0.46551165
Iteration 3818, loss = 0.46789258
Iteration 3819, loss = 0.46378384
Iteration 3820, loss = 0.46592064
Iteration 3821, loss = 0.46788890
Iteration 3822, loss = 0.46674990
Iteration 3823, loss = 0.46614891
Iteration 3824, loss = 0.46740250
Iteration 3825, loss = 0.46533709
Iteration 3826, loss = 0.46800806
Iteration 3827, loss = 0.46485856
Iteration 3828, loss = 0.46427918
Iteration 3829, loss = 0.46505596
Iteration 3830, loss = 0.46660727
Iteration 3831, loss = 0.46343575
Iteration 3832, loss = 0.46290397
Iteration 3833, loss = 0.46753589
Iteration 3834, loss = 0.46962091
Iteration 3835, loss = 0.46470164
Iteration 3836, loss = 0.46473168
Iteration 3837, loss = 0.46467442
Iteration 3838, loss = 0.46503312
Iteration 3839, loss = 0.46621373
Iteration 3840, loss = 0.46405123
Iteration 3841, loss = 0.46474588
Iteration 3842, loss = 0.46427702
Iteration 3843, loss = 0.46415213
Iteration 3844, loss = 0.46310587
Iteration 3845, loss = 0.46280267
Iteration 3846, loss = 0.46653899
Iteration 3847, loss = 0.46422272
Iteration 3848, loss = 0.46723623
Iteration 3849, loss = 0.46350324
Iteration 3850, loss = 0.46494697
Iteration 3851, loss = 0.46278497
Iteration 3852, loss = 0.46461074
Iteration 3853, loss = 0.46471418
Iteration 3854, loss = 0.46280313
Iteration 3855, loss = 0.46842702
Iteration 3856, loss = 0.46585115
Iteration 3857, loss = 0.46928742
Iteration 3858, loss = 0.46578131
Iteration 3859, loss = 0.46474383
Iteration 3860, loss = 0.46857173
Iteration 3861, loss = 0.46442144
Iteration 3862, loss = 0.46506908
Iteration 3863, loss = 0.46381939
Iteration 3864, loss = 0.46567182
Iteration 3865, loss = 0.46498380
Iteration 3866, loss = 0.46488634
Iteration 3867, loss = 0.46398553
Iteration 3868, loss = 0.46240635
Iteration 3869, loss = 0.46632438
Iteration 3870, loss = 0.46500291
Iteration 3871, loss = 0.46610868
Iteration 3872, loss = 0.46410681
Iteration 3873, loss = 0.46662121
Iteration 3874, loss = 0.46370398
Iteration 3875, loss = 0.46276851
Iteration 3876, loss = 0.46400421
Iteration 3877, loss = 0.46309863
Iteration 3878, loss = 0.46310194
Iteration 3879, loss = 0.46341232
Iteration 3880, loss = 0.46653241
Iteration 3881, loss = 0.46514413
Iteration 3882, loss = 0.46312445
Iteration 3883, loss = 0.46882649
Iteration 3884, loss = 0.46594600
Iteration 3885, loss = 0.46552943
Iteration 3886, loss = 0.47143176
Iteration 3887, loss = 0.46922376
Iteration 3888, loss = 0.46618468
Iteration 3889, loss = 0.46510264
Iteration 3890, loss = 0.46326921
Iteration 3891, loss = 0.46281107
Iteration 3892, loss = 0.46224974
Iteration 3893, loss = 0.46602702
Iteration 3894, loss = 0.46458089
Iteration 3895, loss = 0.46548483
Iteration 3896, loss = 0.46664308
Iteration 3897, loss = 0.46782385
Iteration 3898, loss = 0.46936464
Iteration 3899, loss = 0.46925595
Iteration 3900, loss = 0.46812825
Iteration 3901, loss = 0.46273527
Iteration 3902, loss = 0.46133294
Iteration 3903, loss = 0.46656611
Iteration 3904, loss = 0.46503167
Iteration 3905, loss = 0.46533678
Iteration 3906, loss = 0.46430730
Iteration 3907, loss = 0.46572192
Iteration 3908, loss = 0.46419586
Iteration 3909, loss = 0.46516130
Iteration 3910, loss = 0.46639510
Iteration 3911, loss = 0.46371159
Iteration 3912, loss = 0.46605850
Iteration 3913, loss = 0.47045903
Iteration 3914, loss = 0.46958043
Iteration 3915, loss = 0.46459479
Iteration 3916, loss = 0.46385999
Iteration 3917, loss = 0.46342919
Iteration 3918, loss = 0.46373273
Iteration 3919, loss = 0.46469768
Iteration 3920, loss = 0.46546151
Iteration 3921, loss = 0.46416870
Iteration 3922, loss = 0.46595732
Iteration 3923, loss = 0.46456383
Iteration 3924, loss = 0.46591455
Iteration 3925, loss = 0.46632873
Iteration 3926, loss = 0.46496659
Iteration 3927, loss = 0.46440138
Iteration 3928, loss = 0.46232162
Iteration 3929, loss = 0.46276249
Iteration 3930, loss = 0.46413929
Iteration 3931, loss = 0.46576534
Iteration 3932, loss = 0.46595483
Iteration 3933, loss = 0.46571383
Iteration 3934, loss = 0.46289326
Iteration 3935, loss = 0.46423123
Iteration 3936, loss = 0.46272063
Iteration 3937, loss = 0.46229891
Iteration 3938, loss = 0.46357111
Iteration 3939, loss = 0.46563500
Iteration 3940, loss = 0.46420509
Iteration 3941, loss = 0.46351400
Iteration 3942, loss = 0.46464823
Iteration 3943, loss = 0.46369637
Iteration 3944, loss = 0.46238680
Iteration 3945, loss = 0.46242235
Iteration 3946, loss = 0.46450047
Iteration 3947, loss = 0.46428415
Iteration 3948, loss = 0.46847445
Iteration 3949, loss = 0.47234791
Iteration 3950, loss = 0.46635017
Iteration 3951, loss = 0.46456295
Iteration 3952, loss = 0.46441582
Iteration 3953, loss = 0.46297343
Iteration 3954, loss = 0.46215237
Iteration 3955, loss = 0.46384602
Iteration 3956, loss = 0.46332187
Iteration 3957, loss = 0.46112781
Iteration 3958, loss = 0.46403091
Iteration 3959, loss = 0.46459191
Iteration 3960, loss = 0.46390355
Iteration 3961, loss = 0.46550042
Iteration 3962, loss = 0.46345133
Iteration 3963, loss = 0.46216212
Iteration 3964, loss = 0.46297457
Iteration 3965, loss = 0.47222626
Iteration 3966, loss = 0.46409820
Iteration 3967, loss = 0.46308988
Iteration 3968, loss = 0.46608089
Iteration 3969, loss = 0.46230732
Iteration 3970, loss = 0.46101020
Iteration 3971, loss = 0.46621684
Iteration 3972, loss = 0.46352486
Iteration 3973, loss = 0.46221282
Iteration 3974, loss = 0.46582455
Iteration 3975, loss = 0.46295595
Iteration 3976, loss = 0.46351255
Iteration 3977, loss = 0.46238341
Iteration 3978, loss = 0.46642282
Iteration 3979, loss = 0.46312345
Iteration 3980, loss = 0.46312616
Iteration 3981, loss = 0.46383591
Iteration 3982, loss = 0.46215079
Iteration 3983, loss = 0.46381634
Iteration 3984, loss = 0.46211283
Iteration 3985, loss = 0.46374928
Iteration 3986, loss = 0.46536392
Iteration 3987, loss = 0.47124006
Iteration 3988, loss = 0.46355211
Iteration 3989, loss = 0.46459771
Iteration 3990, loss = 0.46571037
Iteration 3991, loss = 0.46617473
Iteration 3992, loss = 0.46720306
Iteration 3993, loss = 0.46286991
Iteration 3994, loss = 0.46632798
Iteration 3995, loss = 0.46293060
Iteration 3996, loss = 0.46394140
Iteration 3997, loss = 0.46421762
Iteration 3998, loss = 0.46869610
Iteration 3999, loss = 0.46443735
Iteration 4000, loss = 0.46313764
Iteration 4001, loss = 0.46322442
Iteration 4002, loss = 0.46222845
Iteration 4003, loss = 0.46507860
Iteration 4004, loss = 0.46668269
Iteration 4005, loss = 0.46359208
Iteration 4006, loss = 0.47026644
Iteration 4007, loss = 0.46329977
Iteration 4008, loss = 0.46549725
Iteration 4009, loss = 0.46313922
Iteration 4010, loss = 0.46433505
Iteration 4011, loss = 0.46359005
Iteration 4012, loss = 0.46850010
Iteration 4013, loss = 0.46495022
Iteration 4014, loss = 0.46342789
Iteration 4015, loss = 0.46283322
Iteration 4016, loss = 0.46442376
Iteration 4017, loss = 0.46610032
Iteration 4018, loss = 0.46489375
Iteration 4019, loss = 0.46456176
Iteration 4020, loss = 0.46308751
Iteration 4021, loss = 0.46537813
Iteration 4022, loss = 0.46228700
Iteration 4023, loss = 0.46585355
Iteration 4024, loss = 0.46238353
Iteration 4025, loss = 0.46432476
Iteration 4026, loss = 0.46196272
Iteration 4027, loss = 0.46390965
Iteration 4028, loss = 0.46587565
Iteration 4029, loss = 0.46408469
Iteration 4030, loss = 0.46267969
Iteration 4031, loss = 0.46392519
Iteration 4032, loss = 0.46292277
Iteration 4033, loss = 0.46363775
Iteration 4034, loss = 0.46397999
Iteration 4035, loss = 0.46249633
Iteration 4036, loss = 0.46149613
Iteration 4037, loss = 0.46166414
Iteration 4038, loss = 0.46236927
Iteration 4039, loss = 0.46618662
Iteration 4040, loss = 0.46750103
Iteration 4041, loss = 0.46311852
Iteration 4042, loss = 0.46124459
Iteration 4043, loss = 0.46534570
Iteration 4044, loss = 0.46390195
Iteration 4045, loss = 0.46251462
Iteration 4046, loss = 0.46132741
Iteration 4047, loss = 0.46230456
Iteration 4048, loss = 0.46125212
Iteration 4049, loss = 0.46392360
Iteration 4050, loss = 0.46313723
Iteration 4051, loss = 0.46400503
Iteration 4052, loss = 0.46409508
Iteration 4053, loss = 0.46320422
Iteration 4054, loss = 0.46247790
Iteration 4055, loss = 0.46375429
Iteration 4056, loss = 0.46397949
Iteration 4057, loss = 0.46200108
Iteration 4058, loss = 0.46444935
Iteration 4059, loss = 0.46374607
Iteration 4060, loss = 0.46214199
Iteration 4061, loss = 0.46125989
Iteration 4062, loss = 0.46481941
Iteration 4063, loss = 0.46448074
Iteration 4064, loss = 0.46673846
Iteration 4065, loss = 0.46375312
Iteration 4066, loss = 0.46347053
Iteration 4067, loss = 0.46193668
Iteration 4068, loss = 0.46371661
Iteration 4069, loss = 0.46346530
Iteration 4070, loss = 0.46265788
Iteration 4071, loss = 0.46334849
Iteration 4072, loss = 0.46482042
Iteration 4073, loss = 0.46317797
Iteration 4074, loss = 0.46282542
Iteration 4075, loss = 0.46382457
Iteration 4076, loss = 0.46625227
Iteration 4077, loss = 0.46448929
Iteration 4078, loss = 0.46452025
Iteration 4079, loss = 0.46338355
Iteration 4080, loss = 0.46445384
Iteration 4081, loss = 0.46339441
Iteration 4082, loss = 0.46417034
Iteration 4083, loss = 0.46427966
Iteration 4084, loss = 0.46481072
Iteration 4085, loss = 0.46257598
Iteration 4086, loss = 0.46715804
Iteration 4087, loss = 0.46387026
Iteration 4088, loss = 0.46403781
Iteration 4089, loss = 0.46254105
Iteration 4090, loss = 0.46212752
Iteration 4091, loss = 0.46299146
Iteration 4092, loss = 0.46569416
Iteration 4093, loss = 0.46260708
Iteration 4094, loss = 0.46240118
Iteration 4095, loss = 0.46463422
Iteration 4096, loss = 0.46160814
Iteration 4097, loss = 0.46179383
Iteration 4098, loss = 0.46636988
Iteration 4099, loss = 0.46363465
Iteration 4100, loss = 0.46266245
Iteration 4101, loss = 0.46412636
Iteration 4102, loss = 0.46172857
Iteration 4103, loss = 0.46604795
Iteration 4104, loss = 0.46653548
Iteration 4105, loss = 0.46543889
Iteration 4106, loss = 0.46629898
Iteration 4107, loss = 0.46148959
Iteration 4108, loss = 0.46134793
Iteration 4109, loss = 0.46292120
Iteration 4110, loss = 0.46570441
Iteration 4111, loss = 0.47294314
Iteration 4112, loss = 0.45887281
Iteration 4113, loss = 0.46111886
Iteration 4114, loss = 0.46299322
Iteration 4115, loss = 0.46455362
Iteration 4116, loss = 0.46326067
Iteration 4117, loss = 0.46498590
Iteration 4118, loss = 0.46290564
Iteration 4119, loss = 0.46555196
Iteration 4120, loss = 0.47102974
Iteration 4121, loss = 0.46988613
Iteration 4122, loss = 0.46447314
Iteration 4123, loss = 0.46336204
Iteration 4124, loss = 0.46199985
Iteration 4125, loss = 0.46157856
Iteration 4126, loss = 0.46184768
Iteration 4127, loss = 0.46251827
Iteration 4128, loss = 0.46239604
Iteration 4129, loss = 0.46317449
Iteration 4130, loss = 0.46138315
Iteration 4131, loss = 0.46180594
Iteration 4132, loss = 0.46212095
Iteration 4133, loss = 0.46094481
Iteration 4134, loss = 0.46636186
Iteration 4135, loss = 0.46283231
Iteration 4136, loss = 0.46228197
Iteration 4137, loss = 0.46378100
Iteration 4138, loss = 0.46157077
Iteration 4139, loss = 0.46416077
Iteration 4140, loss = 0.46283946
Iteration 4141, loss = 0.46484786
Iteration 4142, loss = 0.46230268
Iteration 4143, loss = 0.46688723
Iteration 4144, loss = 0.46618343
Iteration 4145, loss = 0.46782629
Iteration 4146, loss = 0.46104207
Iteration 4147, loss = 0.46751449
Iteration 4148, loss = 0.46333118
Iteration 4149, loss = 0.46228148
Iteration 4150, loss = 0.46460178
Iteration 4151, loss = 0.46282716
Iteration 4152, loss = 0.46352150
Iteration 4153, loss = 0.46471394
Iteration 4154, loss = 0.46139971
Iteration 4155, loss = 0.46224595
Iteration 4156, loss = 0.46500271
Iteration 4157, loss = 0.46375780
Iteration 4158, loss = 0.46276635
Iteration 4159, loss = 0.46511031
Iteration 4160, loss = 0.46533302
Iteration 4161, loss = 0.46114642
Iteration 4162, loss = 0.46138839
Iteration 4163, loss = 0.46198496
Iteration 4164, loss = 0.46257311
Iteration 4165, loss = 0.46473321
Iteration 4166, loss = 0.46081314
Iteration 4167, loss = 0.46133025
Iteration 4168, loss = 0.46450718
Iteration 4169, loss = 0.46189213
Iteration 4170, loss = 0.46165171
Iteration 4171, loss = 0.46316003
Iteration 4172, loss = 0.46273745
Iteration 4173, loss = 0.46212277
Iteration 4174, loss = 0.46165764
Iteration 4175, loss = 0.46072812
Iteration 4176, loss = 0.46208397
Iteration 4177, loss = 0.46314798
Iteration 4178, loss = 0.46007439
Iteration 4179, loss = 0.46175191
Iteration 4180, loss = 0.46077637
Iteration 4181, loss = 0.46053752
Iteration 4182, loss = 0.46149042
Iteration 4183, loss = 0.46166768
Iteration 4184, loss = 0.46179637
Iteration 4185, loss = 0.46328852
Iteration 4186, loss = 0.46220993
Iteration 4187, loss = 0.46114641
Iteration 4188, loss = 0.46849094
Iteration 4189, loss = 0.46653187
Iteration 4190, loss = 0.46130480
Iteration 4191, loss = 0.46182848
Iteration 4192, loss = 0.46172569
Iteration 4193, loss = 0.46203781
Iteration 4194, loss = 0.45936013
Iteration 4195, loss = 0.46078114
Iteration 4196, loss = 0.46349596
Iteration 4197, loss = 0.46166276
Iteration 4198, loss = 0.46191367
Iteration 4199, loss = 0.46334918
Iteration 4200, loss = 0.46335136
Iteration 4201, loss = 0.46129450
Iteration 4202, loss = 0.45997152
Iteration 4203, loss = 0.46154900
Iteration 4204, loss = 0.46264026
Iteration 4205, loss = 0.45815523
Iteration 4206, loss = 0.46711630
Iteration 4207, loss = 0.46200387
Iteration 4208, loss = 0.46467345
Iteration 4209, loss = 0.46379847
Iteration 4210, loss = 0.46329326
Iteration 4211, loss = 0.46413880
Iteration 4212, loss = 0.46251917
Iteration 4213, loss = 0.46252968
Iteration 4214, loss = 0.46010606
Iteration 4215, loss = 0.45992730
Iteration 4216, loss = 0.46011431
Iteration 4217, loss = 0.46326164
Iteration 4218, loss = 0.46111390
Iteration 4219, loss = 0.46156653
Iteration 4220, loss = 0.46238828
Iteration 4221, loss = 0.46143388
Iteration 4222, loss = 0.45931222
Iteration 4223, loss = 0.46050452
Iteration 4224, loss = 0.46332193
Iteration 4225, loss = 0.46295061
Iteration 4226, loss = 0.46096071
Iteration 4227, loss = 0.46296147
Iteration 4228, loss = 0.46224222
Iteration 4229, loss = 0.45992078
Iteration 4230, loss = 0.46070081
Iteration 4231, loss = 0.46430661
Iteration 4232, loss = 0.46532516
Iteration 4233, loss = 0.46220531
Iteration 4234, loss = 0.46147591
Iteration 4235, loss = 0.45954517
Iteration 4236, loss = 0.46414187
Iteration 4237, loss = 0.46013545
Iteration 4238, loss = 0.46155802
Iteration 4239, loss = 0.46012352
Iteration 4240, loss = 0.46044994
Iteration 4241, loss = 0.46203315
Iteration 4242, loss = 0.46155750
Iteration 4243, loss = 0.46046596
Iteration 4244, loss = 0.46125170
Iteration 4245, loss = 0.46041172
Iteration 4246, loss = 0.46164443
Iteration 4247, loss = 0.46379164
Iteration 4248, loss = 0.46284764
Iteration 4249, loss = 0.46039837
Iteration 4250, loss = 0.46138526
Iteration 4251, loss = 0.46300921
Iteration 4252, loss = 0.46466959
Iteration 4253, loss = 0.46359570
Iteration 4254, loss = 0.46302587
Iteration 4255, loss = 0.46421311
Iteration 4256, loss = 0.46373739
Iteration 4257, loss = 0.46696014
Iteration 4258, loss = 0.46691630
Iteration 4259, loss = 0.46603996
Iteration 4260, loss = 0.46630989
Iteration 4261, loss = 0.46652324
Iteration 4262, loss = 0.46030882
Iteration 4263, loss = 0.46276638
Iteration 4264, loss = 0.46090323
Iteration 4265, loss = 0.45993581
Iteration 4266, loss = 0.45826918
Iteration 4267, loss = 0.46103509
Iteration 4268, loss = 0.46179568
Iteration 4269, loss = 0.46206754
Iteration 4270, loss = 0.46308073
Iteration 4271, loss = 0.46089075
Iteration 4272, loss = 0.46190825
Iteration 4273, loss = 0.46395555
Iteration 4274, loss = 0.46145567
Iteration 4275, loss = 0.46122953
Iteration 4276, loss = 0.45931550
Iteration 4277, loss = 0.46064624
Iteration 4278, loss = 0.46122825
Iteration 4279, loss = 0.46212308
Iteration 4280, loss = 0.46061995
Iteration 4281, loss = 0.46047122
Iteration 4282, loss = 0.46046333
Iteration 4283, loss = 0.45889313
Iteration 4284, loss = 0.46113724
Iteration 4285, loss = 0.46517867
Iteration 4286, loss = 0.46998327
Iteration 4287, loss = 0.46366518
Iteration 4288, loss = 0.46367648
Iteration 4289, loss = 0.46253820
Iteration 4290, loss = 0.46045214
Iteration 4291, loss = 0.46043625
Iteration 4292, loss = 0.46474182
Iteration 4293, loss = 0.46194588
Iteration 4294, loss = 0.46152790
Iteration 4295, loss = 0.45904551
Iteration 4296, loss = 0.46391926
Iteration 4297, loss = 0.46183283
Iteration 4298, loss = 0.46102645
Iteration 4299, loss = 0.45922438
Iteration 4300, loss = 0.46139824
Iteration 4301, loss = 0.46103445
Iteration 4302, loss = 0.46042752
Iteration 4303, loss = 0.46033541
Iteration 4304, loss = 0.46022207
Iteration 4305, loss = 0.46176180
Iteration 4306, loss = 0.46251449
Iteration 4307, loss = 0.46287089
Iteration 4308, loss = 0.46049920
Iteration 4309, loss = 0.46044146
Iteration 4310, loss = 0.46417994
Iteration 4311, loss = 0.46116508
Iteration 4312, loss = 0.46062399
Iteration 4313, loss = 0.46049561
Iteration 4314, loss = 0.45886765
Iteration 4315, loss = 0.46097662
Iteration 4316, loss = 0.45980194
Iteration 4317, loss = 0.46125114
Iteration 4318, loss = 0.46191485
Iteration 4319, loss = 0.46288809
Iteration 4320, loss = 0.46177091
Iteration 4321, loss = 0.46125289
Iteration 4322, loss = 0.46356790
Iteration 4323, loss = 0.46178055
Iteration 4324, loss = 0.46260317
Iteration 4325, loss = 0.46102901
Iteration 4326, loss = 0.45830226
Iteration 4327, loss = 0.46081784
Iteration 4328, loss = 0.46161800
Iteration 4329, loss = 0.46124010
Iteration 4330, loss = 0.46750066
Iteration 4331, loss = 0.46091147
Iteration 4332, loss = 0.45954348
Iteration 4333, loss = 0.45973457
Iteration 4334, loss = 0.46028847
Iteration 4335, loss = 0.46325272
Iteration 4336, loss = 0.45930903
Iteration 4337, loss = 0.46187906
Iteration 4338, loss = 0.46365087
Iteration 4339, loss = 0.46322413
Iteration 4340, loss = 0.46089109
Iteration 4341, loss = 0.46211964
Iteration 4342, loss = 0.46010000
Iteration 4343, loss = 0.46046190
Iteration 4344, loss = 0.46272997
Iteration 4345, loss = 0.46161463
Iteration 4346, loss = 0.46036800
Iteration 4347, loss = 0.46172263
Iteration 4348, loss = 0.46370989
Iteration 4349, loss = 0.46181535
Iteration 4350, loss = 0.46527412
Iteration 4351, loss = 0.46200496
Iteration 4352, loss = 0.46284275
Iteration 4353, loss = 0.46161117
Iteration 4354, loss = 0.46117802
Iteration 4355, loss = 0.46185562
Iteration 4356, loss = 0.46108607
Iteration 4357, loss = 0.46186675
Iteration 4358, loss = 0.45952333
Iteration 4359, loss = 0.46001269
Iteration 4360, loss = 0.46252141
Iteration 4361, loss = 0.45904033
Iteration 4362, loss = 0.45941905
Iteration 4363, loss = 0.45852737
Iteration 4364, loss = 0.46104726
Iteration 4365, loss = 0.45938271
Iteration 4366, loss = 0.46102655
Iteration 4367, loss = 0.46232977
Iteration 4368, loss = 0.46127418
Iteration 4369, loss = 0.45983901
Iteration 4370, loss = 0.46464462
Iteration 4371, loss = 0.46641903
Iteration 4372, loss = 0.46520960
Iteration 4373, loss = 0.46373883
Iteration 4374, loss = 0.45997103
Iteration 4375, loss = 0.46163117
Iteration 4376, loss = 0.46270045
Iteration 4377, loss = 0.46508423
Iteration 4378, loss = 0.46334898
Iteration 4379, loss = 0.46119317
Iteration 4380, loss = 0.46111837
Iteration 4381, loss = 0.46174322
Iteration 4382, loss = 0.46061888
Iteration 4383, loss = 0.45823336
Iteration 4384, loss = 0.45831912
Iteration 4385, loss = 0.46275999
Iteration 4386, loss = 0.46521393
Iteration 4387, loss = 0.46107035
Iteration 4388, loss = 0.46381338
Iteration 4389, loss = 0.45891945
Iteration 4390, loss = 0.46092586
Iteration 4391, loss = 0.45918644
Iteration 4392, loss = 0.46163986
Iteration 4393, loss = 0.46030033
Iteration 4394, loss = 0.46159777
Iteration 4395, loss = 0.45904831
Iteration 4396, loss = 0.46131696
Iteration 4397, loss = 0.46109673
Iteration 4398, loss = 0.46006068
Iteration 4399, loss = 0.46353087
Iteration 4400, loss = 0.45969386
Iteration 4401, loss = 0.46101136
Iteration 4402, loss = 0.46030674
Iteration 4403, loss = 0.46126381
Iteration 4404, loss = 0.46046445
Iteration 4405, loss = 0.46054049
Iteration 4406, loss = 0.46051035
Training loss did not improve more than tol=0.000100 for 200 consecutive epochs. Stopping.
MLP accuracy 0.778056741149887
MLP accuracy 0.7527826596367897
0.778056741149887
TN, FN, TP, FP 639 239 646 183
neg score 0.7277904328018223
pos score 0.7792521109770808
accuracy 0.7527826596367897
