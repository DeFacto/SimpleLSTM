5514
5514
5522
[0, 0, 1, 1000, 0, 0.0, 1.0, 0.5416666666666666]
Iteration 1, loss = 0.61661663
Iteration 2, loss = 0.51617355
Iteration 3, loss = 0.49574589
Iteration 4, loss = 0.49113122
Iteration 5, loss = 0.48730438
Iteration 6, loss = 0.48517003
Iteration 7, loss = 0.48456269
Iteration 8, loss = 0.48513130
Iteration 9, loss = 0.48292210
Iteration 10, loss = 0.48420471
Iteration 11, loss = 0.48090208
Iteration 12, loss = 0.47841220
Iteration 13, loss = 0.48516459
Iteration 14, loss = 0.47975736
Iteration 15, loss = 0.48010952
Iteration 16, loss = 0.47902256
Iteration 17, loss = 0.47853929
Iteration 18, loss = 0.47947448
Iteration 19, loss = 0.47861687
Iteration 20, loss = 0.47866693
Iteration 21, loss = 0.47685567
Iteration 22, loss = 0.47367742
Iteration 23, loss = 0.47451298
Iteration 24, loss = 0.47326240
Iteration 25, loss = 0.47252513
Iteration 26, loss = 0.47198737
Iteration 27, loss = 0.47103787
Iteration 28, loss = 0.47002777
Iteration 29, loss = 0.47333916
Iteration 30, loss = 0.47124912
Iteration 31, loss = 0.47286980
Iteration 32, loss = 0.47220492
Iteration 33, loss = 0.46972543
Iteration 34, loss = 0.47126546
Iteration 35, loss = 0.47086421
Iteration 36, loss = 0.46968626
Iteration 37, loss = 0.46739601
Iteration 38, loss = 0.46910938
Iteration 39, loss = 0.46834979
Iteration 40, loss = 0.46932738
Iteration 41, loss = 0.46862748
Iteration 42, loss = 0.46627865
Iteration 43, loss = 0.46585066
Iteration 44, loss = 0.46638314
Iteration 45, loss = 0.46652339
Iteration 46, loss = 0.46422584
Iteration 47, loss = 0.46552647
Iteration 48, loss = 0.46415451
Iteration 49, loss = 0.46421835
Iteration 50, loss = 0.46382725
Iteration 51, loss = 0.46456278
Iteration 52, loss = 0.46484184
Iteration 53, loss = 0.46495961
Iteration 54, loss = 0.46452122
Iteration 55, loss = 0.46640122
Iteration 56, loss = 0.46319384
Iteration 57, loss = 0.46368660
Iteration 58, loss = 0.46367968
Iteration 59, loss = 0.46266782
Iteration 60, loss = 0.46478276
Iteration 61, loss = 0.46365508
Iteration 62, loss = 0.46495311
Iteration 63, loss = 0.46331198
Iteration 64, loss = 0.46393681
Iteration 65, loss = 0.46302514
Iteration 66, loss = 0.46116300
Iteration 67, loss = 0.46159958
Iteration 68, loss = 0.46054092
Iteration 69, loss = 0.46026396
Iteration 70, loss = 0.46152028
Iteration 71, loss = 0.46283567
Iteration 72, loss = 0.46005611
Iteration 73, loss = 0.45868153
Iteration 74, loss = 0.45877575
Iteration 75, loss = 0.46114951
Iteration 76, loss = 0.45996860
Iteration 77, loss = 0.45790663
Iteration 78, loss = 0.45819587
Iteration 79, loss = 0.45894932
Iteration 80, loss = 0.45634664
Iteration 81, loss = 0.45791454
Iteration 82, loss = 0.45879723
Iteration 83, loss = 0.45720379
Iteration 84, loss = 0.46006129
Iteration 85, loss = 0.46007146
Iteration 86, loss = 0.45855108
Iteration 87, loss = 0.45753283
Iteration 88, loss = 0.45680026
Iteration 89, loss = 0.45742629
Iteration 90, loss = 0.45891060
Iteration 91, loss = 0.45626458
Iteration 92, loss = 0.45668163
Iteration 93, loss = 0.45936850
Iteration 94, loss = 0.45833421
Iteration 95, loss = 0.45624579
Iteration 96, loss = 0.45690652
Iteration 97, loss = 0.45867850
Iteration 98, loss = 0.45542266
Iteration 99, loss = 0.45529544
Iteration 100, loss = 0.45437236
Iteration 101, loss = 0.45397123
Iteration 102, loss = 0.45624180
Iteration 103, loss = 0.45604192
Iteration 104, loss = 0.45442406
Iteration 105, loss = 0.45774212
Iteration 106, loss = 0.46134722
Iteration 107, loss = 0.45323673
Iteration 108, loss = 0.45330228
Iteration 109, loss = 0.45815803
Iteration 110, loss = 0.46119131
Iteration 111, loss = 0.45615062
Iteration 112, loss = 0.45585809
Iteration 113, loss = 0.45381581
Iteration 114, loss = 0.45833809
Iteration 115, loss = 0.45957173
Iteration 116, loss = 0.45318904
Iteration 117, loss = 0.45367064
Iteration 118, loss = 0.45411408
Iteration 119, loss = 0.45380073
Iteration 120, loss = 0.45338651
Iteration 121, loss = 0.45383829
Iteration 122, loss = 0.45264339
Iteration 123, loss = 0.46273899
Iteration 124, loss = 0.45865821
Iteration 125, loss = 0.45434725
Iteration 126, loss = 0.45133859
Iteration 127, loss = 0.45491024
Iteration 128, loss = 0.45256205
Iteration 129, loss = 0.45212531
Iteration 130, loss = 0.45062614
Iteration 131, loss = 0.45407772
Iteration 132, loss = 0.45210821
Iteration 133, loss = 0.45117098
Iteration 134, loss = 0.45177120
Iteration 135, loss = 0.45115654
Iteration 136, loss = 0.45070496
Iteration 137, loss = 0.45048871
Iteration 138, loss = 0.45240776
Iteration 139, loss = 0.44952556
Iteration 140, loss = 0.45003630
Iteration 141, loss = 0.44962674
Iteration 142, loss = 0.44954258
Iteration 143, loss = 0.45075976
Iteration 144, loss = 0.44929892
Iteration 145, loss = 0.45109724
Iteration 146, loss = 0.45113167
Iteration 147, loss = 0.45198840
Iteration 148, loss = 0.44858095
Iteration 149, loss = 0.44752358
Iteration 150, loss = 0.45083727
Iteration 151, loss = 0.44865146
Iteration 152, loss = 0.45031170
Iteration 153, loss = 0.45182563
Iteration 154, loss = 0.45007028
Iteration 155, loss = 0.44919447
Iteration 156, loss = 0.44855767
Iteration 157, loss = 0.45337487
Iteration 158, loss = 0.45117073
Iteration 159, loss = 0.44858247
Iteration 160, loss = 0.45113667
Iteration 161, loss = 0.44922786
Iteration 162, loss = 0.44888193
Iteration 163, loss = 0.44818419
Iteration 164, loss = 0.44780578
Iteration 165, loss = 0.44578008
Iteration 166, loss = 0.44750029
Iteration 167, loss = 0.44835594
Iteration 168, loss = 0.44658778
Iteration 169, loss = 0.44992789
Iteration 170, loss = 0.45007579
Iteration 171, loss = 0.44841723
Iteration 172, loss = 0.44608016
Iteration 173, loss = 0.44907893
Iteration 174, loss = 0.44776757
Iteration 175, loss = 0.44955767
Iteration 176, loss = 0.44776930
Iteration 177, loss = 0.44671772
Iteration 178, loss = 0.45092173
Iteration 179, loss = 0.45327920
Iteration 180, loss = 0.44614103
Iteration 181, loss = 0.44523101
Iteration 182, loss = 0.44635427
Iteration 183, loss = 0.44918117
Iteration 184, loss = 0.44542660
Iteration 185, loss = 0.44515647
Iteration 186, loss = 0.44431140
Iteration 187, loss = 0.44648491
Iteration 188, loss = 0.44878059
Iteration 189, loss = 0.44415857
Iteration 190, loss = 0.44589394
Iteration 191, loss = 0.44572319
Iteration 192, loss = 0.44519818
Iteration 193, loss = 0.44532201
Iteration 194, loss = 0.44616524
Iteration 195, loss = 0.44560975
Iteration 196, loss = 0.44732648
Iteration 197, loss = 0.44613454
Iteration 198, loss = 0.44443129
Iteration 199, loss = 0.44494529
Iteration 200, loss = 0.44570319
Iteration 201, loss = 0.44587340
Iteration 202, loss = 0.44382885
Iteration 203, loss = 0.44608820
Iteration 204, loss = 0.44596706
Iteration 205, loss = 0.44354410
Iteration 206, loss = 0.44418338
Iteration 207, loss = 0.44540713
Iteration 208, loss = 0.44524996
Iteration 209, loss = 0.44898031
Iteration 210, loss = 0.44599816
Iteration 211, loss = 0.44312435
Iteration 212, loss = 0.44251455
Iteration 213, loss = 0.44543585
Iteration 214, loss = 0.44382029
Iteration 215, loss = 0.44323285
Iteration 216, loss = 0.45112625
Iteration 217, loss = 0.44348541
Iteration 218, loss = 0.44415772
Iteration 219, loss = 0.44218946
Iteration 220, loss = 0.44230275
Iteration 221, loss = 0.44327192
Iteration 222, loss = 0.44168699
Iteration 223, loss = 0.44237832
Iteration 224, loss = 0.44277115
Iteration 225, loss = 0.44100345
Iteration 226, loss = 0.44316742
Iteration 227, loss = 0.44325649
Iteration 228, loss = 0.44164875
Iteration 229, loss = 0.44428795
Iteration 230, loss = 0.44228485
Iteration 231, loss = 0.44557717
Iteration 232, loss = 0.44476247
Iteration 233, loss = 0.44275737
Iteration 234, loss = 0.44440035
Iteration 235, loss = 0.44300837
Iteration 236, loss = 0.44160447
Iteration 237, loss = 0.44371892
Iteration 238, loss = 0.44443794
Iteration 239, loss = 0.44405068
Iteration 240, loss = 0.44369759
Iteration 241, loss = 0.44688809
Iteration 242, loss = 0.44235378
Iteration 243, loss = 0.44360875
Iteration 244, loss = 0.44272384
Iteration 245, loss = 0.44236400
Iteration 246, loss = 0.44224660
Iteration 247, loss = 0.44153582
Iteration 248, loss = 0.44385449
Iteration 249, loss = 0.44148517
Iteration 250, loss = 0.44344897
Iteration 251, loss = 0.44180593
Iteration 252, loss = 0.44219918
Iteration 253, loss = 0.43966105
Iteration 254, loss = 0.44057594
Iteration 255, loss = 0.44190068
Iteration 256, loss = 0.44032230
Iteration 257, loss = 0.44054858
Iteration 258, loss = 0.44085634
Iteration 259, loss = 0.44247959
Iteration 260, loss = 0.44139287
Iteration 261, loss = 0.44330369
Iteration 262, loss = 0.44295207
Iteration 263, loss = 0.44215282
Iteration 264, loss = 0.44073989
Iteration 265, loss = 0.44432994
Iteration 266, loss = 0.44017026
Iteration 267, loss = 0.44061208
Iteration 268, loss = 0.44180764
Iteration 269, loss = 0.44503877
Iteration 270, loss = 0.44279250
Iteration 271, loss = 0.44131133
Iteration 272, loss = 0.44066509
Iteration 273, loss = 0.44077373
Iteration 274, loss = 0.44008574
Iteration 275, loss = 0.44082383
Iteration 276, loss = 0.44012421
Iteration 277, loss = 0.44072879
Iteration 278, loss = 0.44075855
Iteration 279, loss = 0.44067833
Iteration 280, loss = 0.44176879
Iteration 281, loss = 0.44001204
Iteration 282, loss = 0.44279000
Iteration 283, loss = 0.44313208
Iteration 284, loss = 0.44293951
Iteration 285, loss = 0.44263507
Iteration 286, loss = 0.43935345
Iteration 287, loss = 0.44024042
Iteration 288, loss = 0.43991249
Iteration 289, loss = 0.43736603
Iteration 290, loss = 0.43864821
Iteration 291, loss = 0.43994963
Iteration 292, loss = 0.44152101
Iteration 293, loss = 0.43906316
Iteration 294, loss = 0.43874926
Iteration 295, loss = 0.43995258
Iteration 296, loss = 0.43955137
Iteration 297, loss = 0.43778741
Iteration 298, loss = 0.43929979
Iteration 299, loss = 0.44092047
Iteration 300, loss = 0.44500335
Iteration 301, loss = 0.44051725
Iteration 302, loss = 0.43900938
Iteration 303, loss = 0.44099115
Iteration 304, loss = 0.44507579
Iteration 305, loss = 0.43980985
Iteration 306, loss = 0.44242033
Iteration 307, loss = 0.44103511
Iteration 308, loss = 0.44111517
Iteration 309, loss = 0.44155400
Iteration 310, loss = 0.43883334
Iteration 311, loss = 0.43726415
Iteration 312, loss = 0.43985529
Iteration 313, loss = 0.43774975
Iteration 314, loss = 0.44319616
Iteration 315, loss = 0.43947454
Iteration 316, loss = 0.44239704
Iteration 317, loss = 0.43892280
Iteration 318, loss = 0.43980251
Iteration 319, loss = 0.43781347
Iteration 320, loss = 0.43801200
Iteration 321, loss = 0.43793356
Iteration 322, loss = 0.43784297
Iteration 323, loss = 0.43812525
Iteration 324, loss = 0.43797606
Iteration 325, loss = 0.44284891
Iteration 326, loss = 0.44046281
Iteration 327, loss = 0.44109360
Iteration 328, loss = 0.44471014
Iteration 329, loss = 0.44163299
Iteration 330, loss = 0.44032488
Iteration 331, loss = 0.44012797
Iteration 332, loss = 0.43931289
Iteration 333, loss = 0.43725101
Iteration 334, loss = 0.43788411
Iteration 335, loss = 0.43714332
Iteration 336, loss = 0.43825493
Iteration 337, loss = 0.43999315
Iteration 338, loss = 0.43889531
Iteration 339, loss = 0.43765237
Iteration 340, loss = 0.43905246
Iteration 341, loss = 0.43961737
Iteration 342, loss = 0.43671704
Iteration 343, loss = 0.43903120
Iteration 344, loss = 0.43751381
Iteration 345, loss = 0.43920478
Iteration 346, loss = 0.43808397
Iteration 347, loss = 0.43668285
Iteration 348, loss = 0.43751629
Iteration 349, loss = 0.43631627
Iteration 350, loss = 0.43779953
Iteration 351, loss = 0.43720038
Iteration 352, loss = 0.43840134
Iteration 353, loss = 0.43696190
Iteration 354, loss = 0.43680978
Iteration 355, loss = 0.43695053
Iteration 356, loss = 0.43862917
Iteration 357, loss = 0.43997808
Iteration 358, loss = 0.43692795
Iteration 359, loss = 0.43805478
Iteration 360, loss = 0.43616147
Iteration 361, loss = 0.43530708
Iteration 362, loss = 0.43805339
Iteration 363, loss = 0.44137766
Iteration 364, loss = 0.43786743
Iteration 365, loss = 0.44072341
Iteration 366, loss = 0.43496898
Iteration 367, loss = 0.43981446
Iteration 368, loss = 0.43695603
Iteration 369, loss = 0.43621555
Iteration 370, loss = 0.43889611
Iteration 371, loss = 0.43575164
Iteration 372, loss = 0.43632858
Iteration 373, loss = 0.43840542
Iteration 374, loss = 0.43636059
Iteration 375, loss = 0.43748405
Iteration 376, loss = 0.43561069
Iteration 377, loss = 0.43573344
Iteration 378, loss = 0.43889666
Iteration 379, loss = 0.43799110
Iteration 380, loss = 0.43902951
Iteration 381, loss = 0.43521589
Iteration 382, loss = 0.43648594
Iteration 383, loss = 0.43610285
Iteration 384, loss = 0.43436817
Iteration 385, loss = 0.43485294
Iteration 386, loss = 0.43598744
Iteration 387, loss = 0.43744740
Iteration 388, loss = 0.43722911
Iteration 389, loss = 0.43609176
Iteration 390, loss = 0.43518434
Iteration 391, loss = 0.43732167
Iteration 392, loss = 0.43578109
Iteration 393, loss = 0.43629558
Iteration 394, loss = 0.43906996
Iteration 395, loss = 0.43815641
Iteration 396, loss = 0.44332485
Iteration 397, loss = 0.43664856
Iteration 398, loss = 0.43621655
Iteration 399, loss = 0.43430127
Iteration 400, loss = 0.43511941
Iteration 401, loss = 0.43515807
Iteration 402, loss = 0.44257270
Iteration 403, loss = 0.43857033
Iteration 404, loss = 0.44084964
Iteration 405, loss = 0.43504931
Iteration 406, loss = 0.43573548
Iteration 407, loss = 0.43482398
Iteration 408, loss = 0.43671970
Iteration 409, loss = 0.43830094
Iteration 410, loss = 0.43690876
Iteration 411, loss = 0.43898852
Iteration 412, loss = 0.43718437
Iteration 413, loss = 0.43424821
Iteration 414, loss = 0.43644149
Iteration 415, loss = 0.43499911
Iteration 416, loss = 0.43420325
Iteration 417, loss = 0.43487583
Iteration 418, loss = 0.44068378
Iteration 419, loss = 0.43444813
Iteration 420, loss = 0.43384806
Iteration 421, loss = 0.43257469
Iteration 422, loss = 0.43419532
Iteration 423, loss = 0.43490199
Iteration 424, loss = 0.43295931
Iteration 425, loss = 0.43445955
Iteration 426, loss = 0.43836585
Iteration 427, loss = 0.43375900
Iteration 428, loss = 0.43442418
Iteration 429, loss = 0.43433874
Iteration 430, loss = 0.43430019
Iteration 431, loss = 0.43437028
Iteration 432, loss = 0.43504190
Iteration 433, loss = 0.43406554
Iteration 434, loss = 0.43583049
Iteration 435, loss = 0.43494065
Iteration 436, loss = 0.43616474
Iteration 437, loss = 0.43358933
Iteration 438, loss = 0.43672770
Iteration 439, loss = 0.43240586
Iteration 440, loss = 0.43360587
Iteration 441, loss = 0.43359156
Iteration 442, loss = 0.43270866
Iteration 443, loss = 0.43450595
Iteration 444, loss = 0.43519893
Iteration 445, loss = 0.43383922
Iteration 446, loss = 0.43334669
Iteration 447, loss = 0.43367028
Iteration 448, loss = 0.43441261
Iteration 449, loss = 0.43289134
Iteration 450, loss = 0.43313282
Iteration 451, loss = 0.43539586
Iteration 452, loss = 0.43439164
Iteration 453, loss = 0.43382111
Iteration 454, loss = 0.43265879
Iteration 455, loss = 0.43500400
Iteration 456, loss = 0.43508292
Iteration 457, loss = 0.43746873
Iteration 458, loss = 0.44073004
Iteration 459, loss = 0.43476591
Iteration 460, loss = 0.43629381
Iteration 461, loss = 0.43447900
Iteration 462, loss = 0.43578609
Iteration 463, loss = 0.43510278
Iteration 464, loss = 0.43469496
Iteration 465, loss = 0.43468252
Iteration 466, loss = 0.43593578
Iteration 467, loss = 0.43324748
Iteration 468, loss = 0.43388104
Iteration 469, loss = 0.43507747
Iteration 470, loss = 0.43208621
Iteration 471, loss = 0.43309739
Iteration 472, loss = 0.43175287
Iteration 473, loss = 0.44179228
Iteration 474, loss = 0.43614504
Iteration 475, loss = 0.43153004
Iteration 476, loss = 0.43483409
Iteration 477, loss = 0.43503846
Iteration 478, loss = 0.43328962
Iteration 479, loss = 0.43336488
Iteration 480, loss = 0.43246255
Iteration 481, loss = 0.43282312
Iteration 482, loss = 0.43314548
Iteration 483, loss = 0.43400548
Iteration 484, loss = 0.43442149
Iteration 485, loss = 0.43281856
Iteration 486, loss = 0.43249768
Iteration 487, loss = 0.43158046
Iteration 488, loss = 0.43112410
Iteration 489, loss = 0.43227345
Iteration 490, loss = 0.43230750
Iteration 491, loss = 0.43597469
Iteration 492, loss = 0.43451622
Iteration 493, loss = 0.43144397
Iteration 494, loss = 0.43554448
Iteration 495, loss = 0.43467023
Iteration 496, loss = 0.43133739
Iteration 497, loss = 0.43153887
Iteration 498, loss = 0.43085011
Iteration 499, loss = 0.43120009
Iteration 500, loss = 0.43279567
Iteration 501, loss = 0.43206000
Iteration 502, loss = 0.43272482
Iteration 503, loss = 0.43350794
Iteration 504, loss = 0.43379439
Iteration 505, loss = 0.43366010
Iteration 506, loss = 0.43464507
Iteration 507, loss = 0.43310326
Iteration 508, loss = 0.43318151
Iteration 509, loss = 0.43298463
Iteration 510, loss = 0.43299899
Iteration 511, loss = 0.43221728
Iteration 512, loss = 0.43041552
Iteration 513, loss = 0.43215901
Iteration 514, loss = 0.43515153
Iteration 515, loss = 0.43467837
Iteration 516, loss = 0.43293885
Iteration 517, loss = 0.43034331
Iteration 518, loss = 0.43621799
Iteration 519, loss = 0.43412684
Iteration 520, loss = 0.43406680
Iteration 521, loss = 0.43450473
Iteration 522, loss = 0.43036915
Iteration 523, loss = 0.43021695
Iteration 524, loss = 0.43319002
Iteration 525, loss = 0.43223941
Iteration 526, loss = 0.43329306
Iteration 527, loss = 0.43494329
Iteration 528, loss = 0.43242569
Iteration 529, loss = 0.43056167
Iteration 530, loss = 0.43630522
Iteration 531, loss = 0.43159425
Iteration 532, loss = 0.43095547
Iteration 533, loss = 0.43165827
Iteration 534, loss = 0.43621388
Iteration 535, loss = 0.42926562
Iteration 536, loss = 0.42902241
Iteration 537, loss = 0.43126314
Iteration 538, loss = 0.43212211
Iteration 539, loss = 0.43077017
Iteration 540, loss = 0.43015153
Iteration 541, loss = 0.43111545
Iteration 542, loss = 0.42995694
Iteration 543, loss = 0.43046489
Iteration 544, loss = 0.43181955
Iteration 545, loss = 0.43257243
Iteration 546, loss = 0.43004675
Iteration 547, loss = 0.42988671
Iteration 548, loss = 0.43119604
Iteration 549, loss = 0.43016407
Iteration 550, loss = 0.43073386
Iteration 551, loss = 0.43127838
Iteration 552, loss = 0.43163993
Iteration 553, loss = 0.43204761
Iteration 554, loss = 0.43252874
Iteration 555, loss = 0.43096559
Iteration 556, loss = 0.43050652
Iteration 557, loss = 0.42947870
Iteration 558, loss = 0.43075550
Iteration 559, loss = 0.43333794
Iteration 560, loss = 0.42963273
Iteration 561, loss = 0.43150422
Iteration 562, loss = 0.43295141
Iteration 563, loss = 0.43117079
Iteration 564, loss = 0.43252766
Iteration 565, loss = 0.43124538
Iteration 566, loss = 0.42865054
Iteration 567, loss = 0.42989604
Iteration 568, loss = 0.43147060
Iteration 569, loss = 0.43574134
Iteration 570, loss = 0.42994303
Iteration 571, loss = 0.43081778
Iteration 572, loss = 0.43245115
Iteration 573, loss = 0.43459770
Iteration 574, loss = 0.43115598
Iteration 575, loss = 0.43195532
Iteration 576, loss = 0.43134864
Iteration 577, loss = 0.43205400
Iteration 578, loss = 0.43047944
Iteration 579, loss = 0.43191835
Iteration 580, loss = 0.42952503
Iteration 581, loss = 0.42924267
Iteration 582, loss = 0.42854584
Iteration 583, loss = 0.42807906
Iteration 584, loss = 0.43007420
Iteration 585, loss = 0.42962331
Iteration 586, loss = 0.42785971
Iteration 587, loss = 0.43648979
Iteration 588, loss = 0.43009307
Iteration 589, loss = 0.43099091
Iteration 590, loss = 0.43153714
Iteration 591, loss = 0.43009366
Iteration 592, loss = 0.42809812
Iteration 593, loss = 0.42914589
Iteration 594, loss = 0.42851657
Iteration 595, loss = 0.43217269
Iteration 596, loss = 0.42928788
Iteration 597, loss = 0.42926407
Iteration 598, loss = 0.42778368
Iteration 599, loss = 0.43076768
Iteration 600, loss = 0.42983198
Iteration 601, loss = 0.42908403
Iteration 602, loss = 0.42998832
Iteration 603, loss = 0.43079755
Iteration 604, loss = 0.42884525
Iteration 605, loss = 0.42776285
Iteration 606, loss = 0.43056066
Iteration 607, loss = 0.42834005
Iteration 608, loss = 0.42917382
Iteration 609, loss = 0.43180568
Iteration 610, loss = 0.43091582
Iteration 611, loss = 0.42946926
Iteration 612, loss = 0.42855659
Iteration 613, loss = 0.43067295
Iteration 614, loss = 0.43100845
Iteration 615, loss = 0.43337522
Iteration 616, loss = 0.43084746
Iteration 617, loss = 0.42796993
Iteration 618, loss = 0.43015871
Iteration 619, loss = 0.42935630
Iteration 620, loss = 0.42858436
Iteration 621, loss = 0.42910374
Iteration 622, loss = 0.43004767
Iteration 623, loss = 0.43370012
Iteration 624, loss = 0.42949776
Iteration 625, loss = 0.43049701
Iteration 626, loss = 0.42855522
Iteration 627, loss = 0.42796152
Iteration 628, loss = 0.42737905
Iteration 629, loss = 0.42846828
Iteration 630, loss = 0.43040210
Iteration 631, loss = 0.42890730
Iteration 632, loss = 0.42779708
Iteration 633, loss = 0.42776342
Iteration 634, loss = 0.42770517
Iteration 635, loss = 0.42704810
Iteration 636, loss = 0.42746711
Iteration 637, loss = 0.42833566
Iteration 638, loss = 0.42722173
Iteration 639, loss = 0.42697788
Iteration 640, loss = 0.43080840
Iteration 641, loss = 0.42875021
Iteration 642, loss = 0.42794317
Iteration 643, loss = 0.43184129
Iteration 644, loss = 0.42875614
Iteration 645, loss = 0.42836837
Iteration 646, loss = 0.42688832
Iteration 647, loss = 0.42855097
Iteration 648, loss = 0.42929954
Iteration 649, loss = 0.42833361
Iteration 650, loss = 0.42722633
Iteration 651, loss = 0.43018115
Iteration 652, loss = 0.42995378
Iteration 653, loss = 0.43361130
Iteration 654, loss = 0.42880621
Iteration 655, loss = 0.42787000
Iteration 656, loss = 0.42667655
Iteration 657, loss = 0.42672552
Iteration 658, loss = 0.42741201
Iteration 659, loss = 0.42976410
Iteration 660, loss = 0.43024813
Iteration 661, loss = 0.42573365
Iteration 662, loss = 0.42738851
Iteration 663, loss = 0.42634261
Iteration 664, loss = 0.42728807
Iteration 665, loss = 0.42704115
Iteration 666, loss = 0.42855269
Iteration 667, loss = 0.42808084
Iteration 668, loss = 0.42853250
Iteration 669, loss = 0.42793866
Iteration 670, loss = 0.42905816
Iteration 671, loss = 0.42903790
Iteration 672, loss = 0.42680095
Iteration 673, loss = 0.42767427
Iteration 674, loss = 0.42763939
Iteration 675, loss = 0.42606057
Iteration 676, loss = 0.42888260
Iteration 677, loss = 0.42755173
Iteration 678, loss = 0.42772468
Iteration 679, loss = 0.42611670
Iteration 680, loss = 0.42714396
Iteration 681, loss = 0.42757779
Iteration 682, loss = 0.42724704
Iteration 683, loss = 0.42896570
Iteration 684, loss = 0.42764621
Iteration 685, loss = 0.42642158
Iteration 686, loss = 0.42936526
Iteration 687, loss = 0.43055420
Iteration 688, loss = 0.42718833
Iteration 689, loss = 0.42465987
Iteration 690, loss = 0.42584415
Iteration 691, loss = 0.42615919
Iteration 692, loss = 0.43283714
Iteration 693, loss = 0.42925395
Iteration 694, loss = 0.42669446
Iteration 695, loss = 0.42865024
Iteration 696, loss = 0.42699004
Iteration 697, loss = 0.42469162
Iteration 698, loss = 0.42605588
Iteration 699, loss = 0.42719144
Iteration 700, loss = 0.42728123
Iteration 701, loss = 0.42637253
Iteration 702, loss = 0.42526802
Iteration 703, loss = 0.42446331
Iteration 704, loss = 0.42669949
Iteration 705, loss = 0.42492345
Iteration 706, loss = 0.42592045
Iteration 707, loss = 0.42921077
Iteration 708, loss = 0.42614188
Iteration 709, loss = 0.42680614
Iteration 710, loss = 0.42584936
Iteration 711, loss = 0.42611851
Iteration 712, loss = 0.42607014
Iteration 713, loss = 0.42535391
Iteration 714, loss = 0.42715085
Iteration 715, loss = 0.42546427
Iteration 716, loss = 0.42616103
Iteration 717, loss = 0.42737651
Iteration 718, loss = 0.42621213
Iteration 719, loss = 0.42717599
Iteration 720, loss = 0.42776721
Iteration 721, loss = 0.42554278
Iteration 722, loss = 0.42576089
Iteration 723, loss = 0.42493555
Iteration 724, loss = 0.42606713
Iteration 725, loss = 0.42465846
Iteration 726, loss = 0.42550890
Iteration 727, loss = 0.42404414
Iteration 728, loss = 0.42468732
Iteration 729, loss = 0.42532764
Iteration 730, loss = 0.42658999
Iteration 731, loss = 0.42726537
Iteration 732, loss = 0.42799426
Iteration 733, loss = 0.42670709
Iteration 734, loss = 0.42825813
Iteration 735, loss = 0.42558690
Iteration 736, loss = 0.42747473
Iteration 737, loss = 0.42938772
Iteration 738, loss = 0.42402854
Iteration 739, loss = 0.42384848
Iteration 740, loss = 0.42471891
Iteration 741, loss = 0.42493740
Iteration 742, loss = 0.42582096
Iteration 743, loss = 0.42511388
Iteration 744, loss = 0.42503709
Iteration 745, loss = 0.42284686
Iteration 746, loss = 0.42463774
Iteration 747, loss = 0.42541512
Iteration 748, loss = 0.42368294
Iteration 749, loss = 0.42600035
Iteration 750, loss = 0.42402776
Iteration 751, loss = 0.42435068
Iteration 752, loss = 0.42415553
Iteration 753, loss = 0.42420714
Iteration 754, loss = 0.42487875
Iteration 755, loss = 0.42346427
Iteration 756, loss = 0.42738721
Iteration 757, loss = 0.42437836
Iteration 758, loss = 0.42336343
Iteration 759, loss = 0.42447647
Iteration 760, loss = 0.42625679
Iteration 761, loss = 0.42564155
Iteration 762, loss = 0.42367431
Iteration 763, loss = 0.42452097
Iteration 764, loss = 0.42688527
Iteration 765, loss = 0.42198238
Iteration 766, loss = 0.42760245
Iteration 767, loss = 0.42515555
Iteration 768, loss = 0.42548537
Iteration 769, loss = 0.42432766
Iteration 770, loss = 0.42697073
Iteration 771, loss = 0.42374465
Iteration 772, loss = 0.42959917
Iteration 773, loss = 0.42751466
Iteration 774, loss = 0.42353529
Iteration 775, loss = 0.42410443
Iteration 776, loss = 0.42346009
Iteration 777, loss = 0.42461404
Iteration 778, loss = 0.42455856
Iteration 779, loss = 0.42675311
Iteration 780, loss = 0.42753629
Iteration 781, loss = 0.42282995
Iteration 782, loss = 0.42583725
Iteration 783, loss = 0.42346359
Iteration 784, loss = 0.42444733
Iteration 785, loss = 0.42470490
Iteration 786, loss = 0.42311213
Iteration 787, loss = 0.42369912
Iteration 788, loss = 0.42493903
Iteration 789, loss = 0.42509173
Iteration 790, loss = 0.42255389
Iteration 791, loss = 0.42353503
Iteration 792, loss = 0.42269337
Iteration 793, loss = 0.42278532
Iteration 794, loss = 0.42185797
Iteration 795, loss = 0.42614503
Iteration 796, loss = 0.42274898
Iteration 797, loss = 0.42308127
Iteration 798, loss = 0.42346362
Iteration 799, loss = 0.42458277
Iteration 800, loss = 0.42220894
Iteration 801, loss = 0.42185561
Iteration 802, loss = 0.42745105
Iteration 803, loss = 0.42416131
Iteration 804, loss = 0.42599870
Iteration 805, loss = 0.42567004
Iteration 806, loss = 0.42441345
Iteration 807, loss = 0.42225398
Iteration 808, loss = 0.42509387
Iteration 809, loss = 0.42678208
Iteration 810, loss = 0.42360728
Iteration 811, loss = 0.42382989
Iteration 812, loss = 0.42500544
Iteration 813, loss = 0.42374094
Iteration 814, loss = 0.42557918
Iteration 815, loss = 0.42521315
Iteration 816, loss = 0.42318711
Iteration 817, loss = 0.42437869
Iteration 818, loss = 0.42537714
Iteration 819, loss = 0.42201987
Iteration 820, loss = 0.42279343
Iteration 821, loss = 0.42226014
Iteration 822, loss = 0.42347536
Iteration 823, loss = 0.42241544
Iteration 824, loss = 0.42323487
Iteration 825, loss = 0.42062880
Iteration 826, loss = 0.42412605
Iteration 827, loss = 0.42431873
Iteration 828, loss = 0.42211788
Iteration 829, loss = 0.42231562
Iteration 830, loss = 0.42388754
Iteration 831, loss = 0.42182977
Iteration 832, loss = 0.42247879
Iteration 833, loss = 0.42243867
Iteration 834, loss = 0.42316589
Iteration 835, loss = 0.42440798
Iteration 836, loss = 0.42294016
Iteration 837, loss = 0.42322341
Iteration 838, loss = 0.42535989
Iteration 839, loss = 0.42173420
Iteration 840, loss = 0.42086602
Iteration 841, loss = 0.42394350
Iteration 842, loss = 0.42066686
Iteration 843, loss = 0.42360239
Iteration 844, loss = 0.42417775
Iteration 845, loss = 0.42151702
Iteration 846, loss = 0.42200859
Iteration 847, loss = 0.42293978
Iteration 848, loss = 0.42340362
Iteration 849, loss = 0.42149297
Iteration 850, loss = 0.42224603
Iteration 851, loss = 0.42178129
Iteration 852, loss = 0.42336861
Iteration 853, loss = 0.42412694
Iteration 854, loss = 0.42196985
Iteration 855, loss = 0.42142652
Iteration 856, loss = 0.42200421
Iteration 857, loss = 0.42178267
Iteration 858, loss = 0.42104958
Iteration 859, loss = 0.42435561
Iteration 860, loss = 0.42390160
Iteration 861, loss = 0.42391439
Iteration 862, loss = 0.42023985
Iteration 863, loss = 0.42118376
Iteration 864, loss = 0.42114099
Iteration 865, loss = 0.42090254
Iteration 866, loss = 0.42119045
Iteration 867, loss = 0.42121004
Iteration 868, loss = 0.42537659
Iteration 869, loss = 0.42308915
Iteration 870, loss = 0.42094720
Iteration 871, loss = 0.42507017
Iteration 872, loss = 0.42310944
Iteration 873, loss = 0.42062392
Iteration 874, loss = 0.41983246
Iteration 875, loss = 0.42124440
Iteration 876, loss = 0.42328863
Iteration 877, loss = 0.42438337
Iteration 878, loss = 0.42294173
Iteration 879, loss = 0.42267543
Iteration 880, loss = 0.42153301
Iteration 881, loss = 0.42607845
Iteration 882, loss = 0.42080810
Iteration 883, loss = 0.42290526
Iteration 884, loss = 0.42287781
Iteration 885, loss = 0.42137449
Iteration 886, loss = 0.42185340
Iteration 887, loss = 0.42008779
Iteration 888, loss = 0.42167941
Iteration 889, loss = 0.42077056
Iteration 890, loss = 0.42028987
Iteration 891, loss = 0.42139085
Iteration 892, loss = 0.42016637
Iteration 893, loss = 0.42246562
Iteration 894, loss = 0.41983320
Iteration 895, loss = 0.42388280
Iteration 896, loss = 0.42112135
Iteration 897, loss = 0.42373467
Iteration 898, loss = 0.42201348
Iteration 899, loss = 0.42459021
Iteration 900, loss = 0.42207494
Iteration 901, loss = 0.42127213
Iteration 902, loss = 0.42064520
Iteration 903, loss = 0.41958461
Iteration 904, loss = 0.41941735
Iteration 905, loss = 0.42086215
Iteration 906, loss = 0.41988553
Iteration 907, loss = 0.41936695
Iteration 908, loss = 0.42017236
Iteration 909, loss = 0.41999960
Iteration 910, loss = 0.42081431
Iteration 911, loss = 0.41938343
Iteration 912, loss = 0.41980209
Iteration 913, loss = 0.41982088
Iteration 914, loss = 0.42181860
Iteration 915, loss = 0.42095774
Iteration 916, loss = 0.42064119
Iteration 917, loss = 0.42112604
Iteration 918, loss = 0.42138441
Iteration 919, loss = 0.42075993
Iteration 920, loss = 0.42369081
Iteration 921, loss = 0.42091952
Iteration 922, loss = 0.42339980
Iteration 923, loss = 0.42050861
Iteration 924, loss = 0.41878280
Iteration 925, loss = 0.42146208
Iteration 926, loss = 0.42082932
Iteration 927, loss = 0.42053399
Iteration 928, loss = 0.42011463
Iteration 929, loss = 0.41987460
Iteration 930, loss = 0.42014058
Iteration 931, loss = 0.42217426
Iteration 932, loss = 0.42044069
Iteration 933, loss = 0.42442520
Iteration 934, loss = 0.41921491
Iteration 935, loss = 0.42141040
Iteration 936, loss = 0.42090132
Iteration 937, loss = 0.42070335
Iteration 938, loss = 0.42017117
Iteration 939, loss = 0.42288711
Iteration 940, loss = 0.41948838
Iteration 941, loss = 0.42151361
Iteration 942, loss = 0.42241837
Iteration 943, loss = 0.41975596
Iteration 944, loss = 0.41837032
Iteration 945, loss = 0.41977409
Iteration 946, loss = 0.41959290
Iteration 947, loss = 0.42071289
Iteration 948, loss = 0.41779129
Iteration 949, loss = 0.42550657
Iteration 950, loss = 0.42127080
Iteration 951, loss = 0.41744394
Iteration 952, loss = 0.41854150
Iteration 953, loss = 0.41963132
Iteration 954, loss = 0.42145182
Iteration 955, loss = 0.42140609
Iteration 956, loss = 0.41881439
Iteration 957, loss = 0.41941264
Iteration 958, loss = 0.42116505
Iteration 959, loss = 0.41971451
Iteration 960, loss = 0.41852935
Iteration 961, loss = 0.41947681
Iteration 962, loss = 0.42107001
Iteration 963, loss = 0.42057094
Iteration 964, loss = 0.41852938
Iteration 965, loss = 0.41902131
Iteration 966, loss = 0.41936301
Iteration 967, loss = 0.41918870
Iteration 968, loss = 0.42020838
Iteration 969, loss = 0.41808019
Iteration 970, loss = 0.41880189
Iteration 971, loss = 0.42061560
Iteration 972, loss = 0.42127764
Iteration 973, loss = 0.41988211
Iteration 974, loss = 0.41888215
Iteration 975, loss = 0.41967760
Iteration 976, loss = 0.41776808
Iteration 977, loss = 0.41742163
Iteration 978, loss = 0.42114831
Iteration 979, loss = 0.41726766
Iteration 980, loss = 0.41878241
Iteration 981, loss = 0.41855782
Iteration 982, loss = 0.41922798
Iteration 983, loss = 0.42200905
Iteration 984, loss = 0.41917031
Iteration 985, loss = 0.42056396
Iteration 986, loss = 0.41756180
Iteration 987, loss = 0.41954706
Iteration 988, loss = 0.42056842
Iteration 989, loss = 0.42012176
Iteration 990, loss = 0.42069396
Iteration 991, loss = 0.41922106
Iteration 992, loss = 0.41988149
Iteration 993, loss = 0.41672060
Iteration 994, loss = 0.41770927
Iteration 995, loss = 0.42122435
Iteration 996, loss = 0.41981268
Iteration 997, loss = 0.41603702
Iteration 998, loss = 0.41720124
Iteration 999, loss = 0.41782953
Iteration 1000, loss = 0.42171461
Iteration 1001, loss = 0.41828589
Iteration 1002, loss = 0.41943754
Iteration 1003, loss = 0.41585336
Iteration 1004, loss = 0.41645445
Iteration 1005, loss = 0.41747799
Iteration 1006, loss = 0.42230817
Iteration 1007, loss = 0.41984467
Iteration 1008, loss = 0.41926882
Iteration 1009, loss = 0.41884319
Iteration 1010, loss = 0.41802814
Iteration 1011, loss = 0.41658816
Iteration 1012, loss = 0.41740296
Iteration 1013, loss = 0.41952046
Iteration 1014, loss = 0.41959465
Iteration 1015, loss = 0.41830082
Iteration 1016, loss = 0.41845391
Iteration 1017, loss = 0.42019842
Iteration 1018, loss = 0.42218961
Iteration 1019, loss = 0.41896174
Iteration 1020, loss = 0.41957744
Iteration 1021, loss = 0.41961852
Iteration 1022, loss = 0.41666619
Iteration 1023, loss = 0.41761391
Iteration 1024, loss = 0.42230409
Iteration 1025, loss = 0.42149999
Iteration 1026, loss = 0.41769815
Iteration 1027, loss = 0.41756037
Iteration 1028, loss = 0.41859625
Iteration 1029, loss = 0.41873447
Iteration 1030, loss = 0.41842481
Iteration 1031, loss = 0.41876179
Iteration 1032, loss = 0.41712340
Iteration 1033, loss = 0.41840254
Iteration 1034, loss = 0.41710784
Iteration 1035, loss = 0.41705920
Iteration 1036, loss = 0.41777585
Iteration 1037, loss = 0.41636289
Iteration 1038, loss = 0.41735626
Iteration 1039, loss = 0.42012575
Iteration 1040, loss = 0.41866353
Iteration 1041, loss = 0.41638325
Iteration 1042, loss = 0.41558048
Iteration 1043, loss = 0.41519387
Iteration 1044, loss = 0.41973671
Iteration 1045, loss = 0.41517609
Iteration 1046, loss = 0.41931248
Iteration 1047, loss = 0.41887313
Iteration 1048, loss = 0.41692688
Iteration 1049, loss = 0.41617140
Iteration 1050, loss = 0.41717678
Iteration 1051, loss = 0.41975869
Iteration 1052, loss = 0.41651212
Iteration 1053, loss = 0.41586789
Iteration 1054, loss = 0.42032158
Iteration 1055, loss = 0.41717096
Iteration 1056, loss = 0.41651432
Iteration 1057, loss = 0.41891760
Iteration 1058, loss = 0.41792642
Iteration 1059, loss = 0.41785850
Iteration 1060, loss = 0.41868572
Iteration 1061, loss = 0.41677019
Iteration 1062, loss = 0.41529179
Iteration 1063, loss = 0.41544281
Iteration 1064, loss = 0.41570863
Iteration 1065, loss = 0.41871831
Iteration 1066, loss = 0.41845865
Iteration 1067, loss = 0.41898317
Iteration 1068, loss = 0.41603299
Iteration 1069, loss = 0.41692550
Iteration 1070, loss = 0.41686932
Iteration 1071, loss = 0.41573526
Iteration 1072, loss = 0.42009968
Iteration 1073, loss = 0.41681116
Iteration 1074, loss = 0.41689296
Iteration 1075, loss = 0.41872274
Iteration 1076, loss = 0.41607251
Iteration 1077, loss = 0.41778743
Iteration 1078, loss = 0.41587872
Iteration 1079, loss = 0.41676796
Iteration 1080, loss = 0.41670102
Iteration 1081, loss = 0.41837040
Iteration 1082, loss = 0.41544981
Iteration 1083, loss = 0.41490425
Iteration 1084, loss = 0.41572797
Iteration 1085, loss = 0.41564476
Iteration 1086, loss = 0.41636764
Iteration 1087, loss = 0.41632487
Iteration 1088, loss = 0.41565525
Iteration 1089, loss = 0.41434931
Iteration 1090, loss = 0.41985621
Iteration 1091, loss = 0.41741178
Iteration 1092, loss = 0.41478552
Iteration 1093, loss = 0.41654224
Iteration 1094, loss = 0.41758775
Iteration 1095, loss = 0.41625901
Iteration 1096, loss = 0.41940155
Iteration 1097, loss = 0.41572825
Iteration 1098, loss = 0.41718149
Iteration 1099, loss = 0.41604179
Iteration 1100, loss = 0.41720124
Iteration 1101, loss = 0.41720344
Iteration 1102, loss = 0.41690427
Iteration 1103, loss = 0.41765397
Iteration 1104, loss = 0.41663401
Iteration 1105, loss = 0.41567163
Iteration 1106, loss = 0.41404890
Iteration 1107, loss = 0.41537232
Iteration 1108, loss = 0.41580939
Iteration 1109, loss = 0.41671941
Iteration 1110, loss = 0.41419547
Iteration 1111, loss = 0.41797779
Iteration 1112, loss = 0.41640524
Iteration 1113, loss = 0.41654987
Iteration 1114, loss = 0.41557195
Iteration 1115, loss = 0.42158906
Iteration 1116, loss = 0.41371243
Iteration 1117, loss = 0.41559236
Iteration 1118, loss = 0.41638361
Iteration 1119, loss = 0.41793275
Iteration 1120, loss = 0.41362237
Iteration 1121, loss = 0.41383795
Iteration 1122, loss = 0.41375471
Iteration 1123, loss = 0.41459234
Iteration 1124, loss = 0.41460174
Iteration 1125, loss = 0.41543725
Iteration 1126, loss = 0.41623411
Iteration 1127, loss = 0.41493145
Iteration 1128, loss = 0.41687379
Iteration 1129, loss = 0.41413402
Iteration 1130, loss = 0.41421795
Iteration 1131, loss = 0.41338780
Iteration 1132, loss = 0.41438898
Iteration 1133, loss = 0.41497681
Iteration 1134, loss = 0.41524928
Iteration 1135, loss = 0.41420534
Iteration 1136, loss = 0.41527483
Iteration 1137, loss = 0.41687762
Iteration 1138, loss = 0.41788845
Iteration 1139, loss = 0.41630101
Iteration 1140, loss = 0.41400091
Iteration 1141, loss = 0.41626575
Iteration 1142, loss = 0.41427645
Iteration 1143, loss = 0.41789613
Iteration 1144, loss = 0.41673949
Iteration 1145, loss = 0.41511426
Iteration 1146, loss = 0.41510765
Iteration 1147, loss = 0.41657718
Iteration 1148, loss = 0.41560241
Iteration 1149, loss = 0.41752892
Iteration 1150, loss = 0.41521189
Iteration 1151, loss = 0.41610322
Iteration 1152, loss = 0.41506583
Iteration 1153, loss = 0.41556281
Iteration 1154, loss = 0.41610565
Iteration 1155, loss = 0.41462459
Iteration 1156, loss = 0.41628254
Iteration 1157, loss = 0.41625157
Iteration 1158, loss = 0.41243991
Iteration 1159, loss = 0.41335324
Iteration 1160, loss = 0.41424410
Iteration 1161, loss = 0.41543772
Iteration 1162, loss = 0.41532712
Iteration 1163, loss = 0.41508641
Iteration 1164, loss = 0.41622690
Iteration 1165, loss = 0.41439145
Iteration 1166, loss = 0.41733230
Iteration 1167, loss = 0.41497110
Iteration 1168, loss = 0.41477812
Iteration 1169, loss = 0.41245394
Iteration 1170, loss = 0.41345755
Iteration 1171, loss = 0.41445329
Iteration 1172, loss = 0.41328361
Iteration 1173, loss = 0.41370701
Iteration 1174, loss = 0.41636245
Iteration 1175, loss = 0.41399352
Iteration 1176, loss = 0.41655497
Iteration 1177, loss = 0.41423599
Iteration 1178, loss = 0.41536201
Iteration 1179, loss = 0.41577469
Iteration 1180, loss = 0.41434051
Iteration 1181, loss = 0.41383003
Iteration 1182, loss = 0.41660971
Iteration 1183, loss = 0.41494117
Iteration 1184, loss = 0.41661329
Iteration 1185, loss = 0.41435937
Iteration 1186, loss = 0.41515432
Iteration 1187, loss = 0.41729856
Iteration 1188, loss = 0.41393563
Iteration 1189, loss = 0.41348674
Iteration 1190, loss = 0.41660682
Iteration 1191, loss = 0.41555150
Iteration 1192, loss = 0.41628081
Iteration 1193, loss = 0.41226502
Iteration 1194, loss = 0.41433631
Iteration 1195, loss = 0.41473897
Iteration 1196, loss = 0.41472417
Iteration 1197, loss = 0.41652690
Iteration 1198, loss = 0.41697626
Iteration 1199, loss = 0.41833136
Iteration 1200, loss = 0.41324156
Iteration 1201, loss = 0.41568965
Iteration 1202, loss = 0.41450980
Iteration 1203, loss = 0.41346890
Iteration 1204, loss = 0.41514791
Iteration 1205, loss = 0.41523991
Iteration 1206, loss = 0.41678763
Iteration 1207, loss = 0.41484328
Iteration 1208, loss = 0.41292867
Iteration 1209, loss = 0.41202642
Iteration 1210, loss = 0.41242979
Iteration 1211, loss = 0.41360854
Iteration 1212, loss = 0.41219334
Iteration 1213, loss = 0.41101823
Iteration 1214, loss = 0.41284448
Iteration 1215, loss = 0.41163791
Iteration 1216, loss = 0.41313541
Iteration 1217, loss = 0.41376032
Iteration 1218, loss = 0.41040556
Iteration 1219, loss = 0.41368598
Iteration 1220, loss = 0.41356229
Iteration 1221, loss = 0.41496440
Iteration 1222, loss = 0.41452798
Iteration 1223, loss = 0.41368462
Iteration 1224, loss = 0.41273799
Iteration 1225, loss = 0.41236980
Iteration 1226, loss = 0.41358925
Iteration 1227, loss = 0.41180473
Iteration 1228, loss = 0.41300488
Iteration 1229, loss = 0.41288525
Iteration 1230, loss = 0.41285457
Iteration 1231, loss = 0.41266215
Iteration 1232, loss = 0.41268155
Iteration 1233, loss = 0.41272875
Iteration 1234, loss = 0.41055892
Iteration 1235, loss = 0.41400248
Iteration 1236, loss = 0.41184455
Iteration 1237, loss = 0.41296428
Iteration 1238, loss = 0.41366850
Iteration 1239, loss = 0.41076178
Iteration 1240, loss = 0.41268743
Iteration 1241, loss = 0.41249084
Iteration 1242, loss = 0.41455249
Iteration 1243, loss = 0.41190250
Iteration 1244, loss = 0.41096338
Iteration 1245, loss = 0.41193865
Iteration 1246, loss = 0.41428133
Iteration 1247, loss = 0.41458658
Iteration 1248, loss = 0.41266666
Iteration 1249, loss = 0.41386820
Iteration 1250, loss = 0.41300267
Iteration 1251, loss = 0.41133539
Iteration 1252, loss = 0.41121575
Iteration 1253, loss = 0.41150611
Iteration 1254, loss = 0.41351899
Iteration 1255, loss = 0.41374594
Iteration 1256, loss = 0.41094885
Iteration 1257, loss = 0.41068188
Iteration 1258, loss = 0.41340126
Iteration 1259, loss = 0.41391436
Iteration 1260, loss = 0.41124744
Iteration 1261, loss = 0.41134052
Iteration 1262, loss = 0.41169822
Iteration 1263, loss = 0.41191841
Iteration 1264, loss = 0.40938506
Iteration 1265, loss = 0.41073244
Iteration 1266, loss = 0.41273404
Iteration 1267, loss = 0.41243154
Iteration 1268, loss = 0.41183115
Iteration 1269, loss = 0.41268923
Iteration 1270, loss = 0.41329052
Iteration 1271, loss = 0.41410751
Iteration 1272, loss = 0.41180262
Iteration 1273, loss = 0.41125246
Iteration 1274, loss = 0.41283978
Iteration 1275, loss = 0.40983044
Iteration 1276, loss = 0.41224117
Iteration 1277, loss = 0.41171781
Iteration 1278, loss = 0.41370500
Iteration 1279, loss = 0.41267372
Iteration 1280, loss = 0.41277490
Iteration 1281, loss = 0.41168280
Iteration 1282, loss = 0.41157035
Iteration 1283, loss = 0.41240959
Iteration 1284, loss = 0.41272690
Iteration 1285, loss = 0.41233236
Iteration 1286, loss = 0.41070177
Iteration 1287, loss = 0.41051984
Iteration 1288, loss = 0.41118967
Iteration 1289, loss = 0.41074509
Iteration 1290, loss = 0.41021704
Iteration 1291, loss = 0.41529030
Iteration 1292, loss = 0.41723625
Iteration 1293, loss = 0.41123879
Iteration 1294, loss = 0.41272160
Iteration 1295, loss = 0.41301597
Iteration 1296, loss = 0.41150811
Iteration 1297, loss = 0.41071501
Iteration 1298, loss = 0.41203785
Iteration 1299, loss = 0.41103000
Iteration 1300, loss = 0.41214146
Iteration 1301, loss = 0.41289433
Iteration 1302, loss = 0.41168046
Iteration 1303, loss = 0.41089565
Iteration 1304, loss = 0.41632899
Iteration 1305, loss = 0.41132426
Iteration 1306, loss = 0.41186467
Iteration 1307, loss = 0.41114611
Iteration 1308, loss = 0.41372242
Iteration 1309, loss = 0.41106311
Iteration 1310, loss = 0.41087906
Iteration 1311, loss = 0.41017593
Iteration 1312, loss = 0.41254035
Iteration 1313, loss = 0.41036570
Iteration 1314, loss = 0.40891666
Iteration 1315, loss = 0.41287972
Iteration 1316, loss = 0.41065560
Iteration 1317, loss = 0.41256376
Iteration 1318, loss = 0.41009198
Iteration 1319, loss = 0.40956926
Iteration 1320, loss = 0.40874917
Iteration 1321, loss = 0.41105797
Iteration 1322, loss = 0.41053997
Iteration 1323, loss = 0.41137069
Iteration 1324, loss = 0.41072571
Iteration 1325, loss = 0.41093029
Iteration 1326, loss = 0.40874013
Iteration 1327, loss = 0.40938211
Iteration 1328, loss = 0.40931138
Iteration 1329, loss = 0.41006010
Iteration 1330, loss = 0.40831938
Iteration 1331, loss = 0.41143504
Iteration 1332, loss = 0.41123039
Iteration 1333, loss = 0.40959276
Iteration 1334, loss = 0.40979047
Iteration 1335, loss = 0.41102614
Iteration 1336, loss = 0.41111250
Iteration 1337, loss = 0.41259537
Iteration 1338, loss = 0.41254206
Iteration 1339, loss = 0.40957064
Iteration 1340, loss = 0.41044784
Iteration 1341, loss = 0.40919265
Iteration 1342, loss = 0.41057535
Iteration 1343, loss = 0.41222018
Iteration 1344, loss = 0.41477911
Iteration 1345, loss = 0.41195694
Iteration 1346, loss = 0.41061310
Iteration 1347, loss = 0.41268745
Iteration 1348, loss = 0.40984059
Iteration 1349, loss = 0.40954023
Iteration 1350, loss = 0.41289989
Iteration 1351, loss = 0.40799073
Iteration 1352, loss = 0.41087892
Iteration 1353, loss = 0.41052070
Iteration 1354, loss = 0.40930462
Iteration 1355, loss = 0.41109980
Iteration 1356, loss = 0.40930509
Iteration 1357, loss = 0.41003557
Iteration 1358, loss = 0.41342944
Iteration 1359, loss = 0.40842162
Iteration 1360, loss = 0.40831810
Iteration 1361, loss = 0.41167383
Iteration 1362, loss = 0.41019532
Iteration 1363, loss = 0.41062447
Iteration 1364, loss = 0.41181970
Iteration 1365, loss = 0.40899093
Iteration 1366, loss = 0.41290473
Iteration 1367, loss = 0.40812276
Iteration 1368, loss = 0.41076208
Iteration 1369, loss = 0.41146125
Iteration 1370, loss = 0.41463027
Iteration 1371, loss = 0.41294512
Iteration 1372, loss = 0.40884043
Iteration 1373, loss = 0.40736966
Iteration 1374, loss = 0.41031342
Iteration 1375, loss = 0.40970741
Iteration 1376, loss = 0.41227712
Iteration 1377, loss = 0.40959690
Iteration 1378, loss = 0.40977143
Iteration 1379, loss = 0.40987937
Iteration 1380, loss = 0.41175425
Iteration 1381, loss = 0.41054319
Iteration 1382, loss = 0.40761538
Iteration 1383, loss = 0.40918096
Iteration 1384, loss = 0.40833865
Iteration 1385, loss = 0.41159295
Iteration 1386, loss = 0.41128171
Iteration 1387, loss = 0.41140330
Iteration 1388, loss = 0.40889141
Iteration 1389, loss = 0.40858093
Iteration 1390, loss = 0.40796749
Iteration 1391, loss = 0.41162645
Iteration 1392, loss = 0.41010488
Iteration 1393, loss = 0.40629535
Iteration 1394, loss = 0.40758764
Iteration 1395, loss = 0.40757872
Iteration 1396, loss = 0.40968358
Iteration 1397, loss = 0.40826260
Iteration 1398, loss = 0.41018928
Iteration 1399, loss = 0.40748572
Iteration 1400, loss = 0.40652983
Iteration 1401, loss = 0.40966728
Iteration 1402, loss = 0.40780096
Iteration 1403, loss = 0.41337773
Iteration 1404, loss = 0.40788908
Iteration 1405, loss = 0.41241496
Iteration 1406, loss = 0.40990473
Iteration 1407, loss = 0.40625984
Iteration 1408, loss = 0.40896540
Iteration 1409, loss = 0.40803982
Iteration 1410, loss = 0.40883079
Iteration 1411, loss = 0.41199905
Iteration 1412, loss = 0.40956452
Iteration 1413, loss = 0.40737308
Iteration 1414, loss = 0.40831161
Iteration 1415, loss = 0.41016607
Iteration 1416, loss = 0.41752529
Iteration 1417, loss = 0.41101687
Iteration 1418, loss = 0.40811877
Iteration 1419, loss = 0.41223697
Iteration 1420, loss = 0.40753303
Iteration 1421, loss = 0.40941195
Iteration 1422, loss = 0.40722182
Iteration 1423, loss = 0.40813393
Iteration 1424, loss = 0.40539259
Iteration 1425, loss = 0.40780207
Iteration 1426, loss = 0.41162032
Iteration 1427, loss = 0.40802568
Iteration 1428, loss = 0.40664900
Iteration 1429, loss = 0.40751711
Iteration 1430, loss = 0.40942023
Iteration 1431, loss = 0.40842374
Iteration 1432, loss = 0.40893209
Iteration 1433, loss = 0.40737211
Iteration 1434, loss = 0.40822514
Iteration 1435, loss = 0.40800259
Iteration 1436, loss = 0.41123050
Iteration 1437, loss = 0.40767443
Iteration 1438, loss = 0.40718111
Iteration 1439, loss = 0.40701709
Iteration 1440, loss = 0.40654160
Iteration 1441, loss = 0.40792049
Iteration 1442, loss = 0.40732616
Iteration 1443, loss = 0.40627084
Iteration 1444, loss = 0.40650102
Iteration 1445, loss = 0.40624112
Iteration 1446, loss = 0.40675152
Iteration 1447, loss = 0.40677443
Iteration 1448, loss = 0.40706048
Iteration 1449, loss = 0.40785597
Iteration 1450, loss = 0.40723986
Iteration 1451, loss = 0.40553713
Iteration 1452, loss = 0.40942440
Iteration 1453, loss = 0.40660697
Iteration 1454, loss = 0.40648738
Iteration 1455, loss = 0.40674403
Iteration 1456, loss = 0.40888820
Iteration 1457, loss = 0.41107672
Iteration 1458, loss = 0.40812478
Iteration 1459, loss = 0.40944085
Iteration 1460, loss = 0.41012030
Iteration 1461, loss = 0.40734544
Iteration 1462, loss = 0.40690750
Iteration 1463, loss = 0.40809881
Iteration 1464, loss = 0.40708421
Iteration 1465, loss = 0.40655732
Iteration 1466, loss = 0.40693394
Iteration 1467, loss = 0.40734899
Iteration 1468, loss = 0.40679368
Iteration 1469, loss = 0.40676885
Iteration 1470, loss = 0.40638053
Iteration 1471, loss = 0.40727106
Iteration 1472, loss = 0.40637508
Iteration 1473, loss = 0.40871551
Iteration 1474, loss = 0.40591181
Iteration 1475, loss = 0.40762935
Iteration 1476, loss = 0.40834491
Iteration 1477, loss = 0.40858083
Iteration 1478, loss = 0.40700643
Iteration 1479, loss = 0.40594058
Iteration 1480, loss = 0.40636482
Iteration 1481, loss = 0.40790853
Iteration 1482, loss = 0.40615292
Iteration 1483, loss = 0.40524268
Iteration 1484, loss = 0.40706002
Iteration 1485, loss = 0.40490154
Iteration 1486, loss = 0.40607267
Iteration 1487, loss = 0.40590689
Iteration 1488, loss = 0.40482271
Iteration 1489, loss = 0.40706771
Iteration 1490, loss = 0.40634517
Iteration 1491, loss = 0.40934361
Iteration 1492, loss = 0.40866405
Iteration 1493, loss = 0.40846039
Iteration 1494, loss = 0.41251100
Iteration 1495, loss = 0.40911362
Iteration 1496, loss = 0.40826482
Iteration 1497, loss = 0.40874866
Iteration 1498, loss = 0.40749707
Iteration 1499, loss = 0.40844524
Iteration 1500, loss = 0.40381165
Iteration 1501, loss = 0.40434390
Iteration 1502, loss = 0.40544425
Iteration 1503, loss = 0.41362822
Iteration 1504, loss = 0.40326698
Iteration 1505, loss = 0.40637186
Iteration 1506, loss = 0.40725844
Iteration 1507, loss = 0.40530097
Iteration 1508, loss = 0.40615297
Iteration 1509, loss = 0.40653597
Iteration 1510, loss = 0.40458917
Iteration 1511, loss = 0.40574342
Iteration 1512, loss = 0.40370749
Iteration 1513, loss = 0.40759936
Iteration 1514, loss = 0.40910441
Iteration 1515, loss = 0.40922662
Iteration 1516, loss = 0.40619220
Iteration 1517, loss = 0.40654333
Iteration 1518, loss = 0.40826577
Iteration 1519, loss = 0.40417353
Iteration 1520, loss = 0.40341607
Iteration 1521, loss = 0.40273773
Iteration 1522, loss = 0.40652603
Iteration 1523, loss = 0.40492015
Iteration 1524, loss = 0.40770166
Iteration 1525, loss = 0.40870935
Iteration 1526, loss = 0.40396542
Iteration 1527, loss = 0.40621802
Iteration 1528, loss = 0.40404233
Iteration 1529, loss = 0.40636412
Iteration 1530, loss = 0.40435035
Iteration 1531, loss = 0.40522258
Iteration 1532, loss = 0.40404088
Iteration 1533, loss = 0.40833145
Iteration 1534, loss = 0.40974541
Iteration 1535, loss = 0.40987769
Iteration 1536, loss = 0.40728604
Iteration 1537, loss = 0.40570823
Iteration 1538, loss = 0.40603138
Iteration 1539, loss = 0.40496684
Iteration 1540, loss = 0.40466851
Iteration 1541, loss = 0.40664124
Iteration 1542, loss = 0.40739654
Iteration 1543, loss = 0.40448629
Iteration 1544, loss = 0.40769408
Iteration 1545, loss = 0.40366976
Iteration 1546, loss = 0.40557556
Iteration 1547, loss = 0.40578254
Iteration 1548, loss = 0.40460997
Iteration 1549, loss = 0.40341921
Iteration 1550, loss = 0.40377928
Iteration 1551, loss = 0.40460966
Iteration 1552, loss = 0.40474308
Iteration 1553, loss = 0.40606972
Iteration 1554, loss = 0.40318325
Iteration 1555, loss = 0.40629502
Iteration 1556, loss = 0.41095214
Iteration 1557, loss = 0.40340912
Iteration 1558, loss = 0.40268508
Iteration 1559, loss = 0.40471373
Iteration 1560, loss = 0.40366936
Iteration 1561, loss = 0.40372601
Iteration 1562, loss = 0.40281223
Iteration 1563, loss = 0.40416751
Iteration 1564, loss = 0.40469010
Iteration 1565, loss = 0.40409319
Iteration 1566, loss = 0.40503389
Iteration 1567, loss = 0.40386653
Iteration 1568, loss = 0.40436092
Iteration 1569, loss = 0.40401383
Iteration 1570, loss = 0.40591850
Iteration 1571, loss = 0.40330456
Iteration 1572, loss = 0.40449612
Iteration 1573, loss = 0.40515504
Iteration 1574, loss = 0.40693432
Iteration 1575, loss = 0.40450023
Iteration 1576, loss = 0.40470978
Iteration 1577, loss = 0.40267076
Iteration 1578, loss = 0.40621110
Iteration 1579, loss = 0.40256729
Iteration 1580, loss = 0.40354887
Iteration 1581, loss = 0.40950484
Iteration 1582, loss = 0.40521275
Iteration 1583, loss = 0.40237900
Iteration 1584, loss = 0.40474932
Iteration 1585, loss = 0.40393667
Iteration 1586, loss = 0.40542973
Iteration 1587, loss = 0.40539966
Iteration 1588, loss = 0.40329336
Iteration 1589, loss = 0.40500170
Iteration 1590, loss = 0.40396239
Iteration 1591, loss = 0.40341319
Iteration 1592, loss = 0.40482652
Iteration 1593, loss = 0.40443133
Iteration 1594, loss = 0.40375055
Iteration 1595, loss = 0.40648305
Iteration 1596, loss = 0.40577774
Iteration 1597, loss = 0.40410184
Iteration 1598, loss = 0.40400242
Iteration 1599, loss = 0.40322782
Iteration 1600, loss = 0.40111478
Iteration 1601, loss = 0.40322187
Iteration 1602, loss = 0.40633847
Iteration 1603, loss = 0.40380944
Iteration 1604, loss = 0.40417828
Iteration 1605, loss = 0.40307300
Iteration 1606, loss = 0.40472002
Iteration 1607, loss = 0.40334796
Iteration 1608, loss = 0.40553656
Iteration 1609, loss = 0.40468579
Iteration 1610, loss = 0.40246384
Iteration 1611, loss = 0.40059334
Iteration 1612, loss = 0.40251233
Iteration 1613, loss = 0.40333004
Iteration 1614, loss = 0.40659773
Iteration 1615, loss = 0.40262211
Iteration 1616, loss = 0.40427471
Iteration 1617, loss = 0.40412100
Iteration 1618, loss = 0.40509852
Iteration 1619, loss = 0.40557529
Iteration 1620, loss = 0.40272942
Iteration 1621, loss = 0.40174611
Iteration 1622, loss = 0.40307874
Iteration 1623, loss = 0.40430454
Iteration 1624, loss = 0.40641941
Iteration 1625, loss = 0.40295189
Iteration 1626, loss = 0.40131617
Iteration 1627, loss = 0.40194612
Iteration 1628, loss = 0.40136320
Iteration 1629, loss = 0.40102785
Iteration 1630, loss = 0.40366882
Iteration 1631, loss = 0.40236481
Iteration 1632, loss = 0.40690206
Iteration 1633, loss = 0.40394057
Iteration 1634, loss = 0.40425484
Iteration 1635, loss = 0.40575074
Iteration 1636, loss = 0.40496379
Iteration 1637, loss = 0.40526790
Iteration 1638, loss = 0.39990155
Iteration 1639, loss = 0.40323446
Iteration 1640, loss = 0.40129107
Iteration 1641, loss = 0.40285408
Iteration 1642, loss = 0.40295933
Iteration 1643, loss = 0.40388457
Iteration 1644, loss = 0.40448834
Iteration 1645, loss = 0.40303081
Iteration 1646, loss = 0.40350919
Iteration 1647, loss = 0.40499566
Iteration 1648, loss = 0.40384149
Iteration 1649, loss = 0.40230694
Iteration 1650, loss = 0.40169482
Iteration 1651, loss = 0.40705778
Iteration 1652, loss = 0.40329978
Iteration 1653, loss = 0.40413565
Iteration 1654, loss = 0.40544329
Iteration 1655, loss = 0.40305579
Iteration 1656, loss = 0.40546095
Iteration 1657, loss = 0.40044573
Iteration 1658, loss = 0.40202214
Iteration 1659, loss = 0.40227979
Iteration 1660, loss = 0.40432464
Iteration 1661, loss = 0.40421016
Iteration 1662, loss = 0.40152908
Iteration 1663, loss = 0.40265965
Iteration 1664, loss = 0.40100825
Iteration 1665, loss = 0.40327821
Iteration 1666, loss = 0.40252010
Iteration 1667, loss = 0.40259808
Iteration 1668, loss = 0.39911403
Iteration 1669, loss = 0.40420756
Iteration 1670, loss = 0.40199335
Iteration 1671, loss = 0.40197402
Iteration 1672, loss = 0.40278856
Iteration 1673, loss = 0.40189592
Iteration 1674, loss = 0.40537317
Iteration 1675, loss = 0.40312070
Iteration 1676, loss = 0.40056769
Iteration 1677, loss = 0.40546556
Iteration 1678, loss = 0.40395107
Iteration 1679, loss = 0.40552573
Iteration 1680, loss = 0.40437185
Iteration 1681, loss = 0.40492285
Iteration 1682, loss = 0.40092630
Iteration 1683, loss = 0.39988384
Iteration 1684, loss = 0.40166167
Iteration 1685, loss = 0.40174200
Iteration 1686, loss = 0.40259073
Iteration 1687, loss = 0.40083425
Iteration 1688, loss = 0.40467787
Iteration 1689, loss = 0.40624026
Iteration 1690, loss = 0.40255840
Iteration 1691, loss = 0.40159270
Iteration 1692, loss = 0.40369003
Iteration 1693, loss = 0.40165083
Iteration 1694, loss = 0.40149313
Iteration 1695, loss = 0.39867549
Iteration 1696, loss = 0.40161048
Iteration 1697, loss = 0.40552955
Iteration 1698, loss = 0.40497464
Iteration 1699, loss = 0.40326507
Iteration 1700, loss = 0.40147901
Iteration 1701, loss = 0.40278624
Iteration 1702, loss = 0.40269133
Iteration 1703, loss = 0.40645174
Iteration 1704, loss = 0.40555658
Iteration 1705, loss = 0.40143450
Iteration 1706, loss = 0.40127473
Iteration 1707, loss = 0.40056750
Iteration 1708, loss = 0.39992647
Iteration 1709, loss = 0.39929756
Iteration 1710, loss = 0.39995700
Iteration 1711, loss = 0.40181164
Iteration 1712, loss = 0.40377632
Iteration 1713, loss = 0.40288717
Iteration 1714, loss = 0.40282945
Iteration 1715, loss = 0.40124822
Iteration 1716, loss = 0.39920274
Iteration 1717, loss = 0.39899175
Iteration 1718, loss = 0.39937349
Iteration 1719, loss = 0.39880398
Iteration 1720, loss = 0.40145898
Iteration 1721, loss = 0.39931536
Iteration 1722, loss = 0.40021969
Iteration 1723, loss = 0.40022210
Iteration 1724, loss = 0.40399836
Iteration 1725, loss = 0.40612467
Iteration 1726, loss = 0.41064743
Iteration 1727, loss = 0.39956920
Iteration 1728, loss = 0.40233990
Iteration 1729, loss = 0.40156818
Iteration 1730, loss = 0.40308163
Iteration 1731, loss = 0.40039619
Iteration 1732, loss = 0.40170281
Iteration 1733, loss = 0.40273633
Iteration 1734, loss = 0.39948584
Iteration 1735, loss = 0.40069038
Iteration 1736, loss = 0.40596795
Iteration 1737, loss = 0.39889069
Iteration 1738, loss = 0.39976121
Iteration 1739, loss = 0.40065419
Iteration 1740, loss = 0.40178664
Iteration 1741, loss = 0.40253740
Iteration 1742, loss = 0.39877870
Iteration 1743, loss = 0.40189061
Iteration 1744, loss = 0.40036699
Iteration 1745, loss = 0.40064532
Iteration 1746, loss = 0.40298145
Iteration 1747, loss = 0.40143407
Iteration 1748, loss = 0.40098686
Iteration 1749, loss = 0.39869445
Iteration 1750, loss = 0.40132999
Iteration 1751, loss = 0.40452814
Iteration 1752, loss = 0.40291200
Iteration 1753, loss = 0.40212845
Iteration 1754, loss = 0.40152770
Iteration 1755, loss = 0.40040717
Iteration 1756, loss = 0.39881948
Iteration 1757, loss = 0.40110290
Iteration 1758, loss = 0.40380529
Iteration 1759, loss = 0.40078667
Iteration 1760, loss = 0.40529149
Iteration 1761, loss = 0.40068164
Iteration 1762, loss = 0.39875387
Iteration 1763, loss = 0.40024527
Iteration 1764, loss = 0.39994563
Iteration 1765, loss = 0.40159933
Iteration 1766, loss = 0.40273659
Iteration 1767, loss = 0.39806649
Iteration 1768, loss = 0.40169557
Iteration 1769, loss = 0.40221095
Iteration 1770, loss = 0.40441376
Iteration 1771, loss = 0.39910633
Iteration 1772, loss = 0.39891997
Iteration 1773, loss = 0.40022698
Iteration 1774, loss = 0.39964736
Iteration 1775, loss = 0.39864135
Iteration 1776, loss = 0.40030043
Iteration 1777, loss = 0.40278360
Iteration 1778, loss = 0.39846877
Iteration 1779, loss = 0.39920991
Iteration 1780, loss = 0.40305094
Iteration 1781, loss = 0.39973224
Iteration 1782, loss = 0.39812295
Iteration 1783, loss = 0.40281100
Iteration 1784, loss = 0.39832461
Iteration 1785, loss = 0.39942614
Iteration 1786, loss = 0.39879365
Iteration 1787, loss = 0.40311444
Iteration 1788, loss = 0.39844816
Iteration 1789, loss = 0.39769912
Iteration 1790, loss = 0.39958395
Iteration 1791, loss = 0.39830829
Iteration 1792, loss = 0.39880707
Iteration 1793, loss = 0.39897617
Iteration 1794, loss = 0.40033065
Iteration 1795, loss = 0.39871351
Iteration 1796, loss = 0.40030289
Iteration 1797, loss = 0.40130804
Iteration 1798, loss = 0.40331784
Iteration 1799, loss = 0.39945197
Iteration 1800, loss = 0.39897536
Iteration 1801, loss = 0.39943116
Iteration 1802, loss = 0.39862492
Iteration 1803, loss = 0.40237186
Iteration 1804, loss = 0.40333364
Iteration 1805, loss = 0.39913533
Iteration 1806, loss = 0.40003054
Iteration 1807, loss = 0.39870097
Iteration 1808, loss = 0.39945807
Iteration 1809, loss = 0.39865501
Iteration 1810, loss = 0.39801125
Iteration 1811, loss = 0.40114762
Iteration 1812, loss = 0.40261390
Iteration 1813, loss = 0.39858188
Iteration 1814, loss = 0.39965433
Iteration 1815, loss = 0.40141364
Iteration 1816, loss = 0.39693655
Iteration 1817, loss = 0.39763482
Iteration 1818, loss = 0.39814223
Iteration 1819, loss = 0.39904097
Iteration 1820, loss = 0.39865371
Iteration 1821, loss = 0.40193914
Iteration 1822, loss = 0.40121886
Iteration 1823, loss = 0.39836658
Iteration 1824, loss = 0.40081302
Iteration 1825, loss = 0.40044595
Iteration 1826, loss = 0.39940177
Iteration 1827, loss = 0.39942908
Iteration 1828, loss = 0.40300873
Iteration 1829, loss = 0.40542316
Iteration 1830, loss = 0.40002457
Iteration 1831, loss = 0.40016713
Iteration 1832, loss = 0.39994461
Iteration 1833, loss = 0.39945593
Iteration 1834, loss = 0.40032289
Iteration 1835, loss = 0.40150179
Iteration 1836, loss = 0.39981918
Iteration 1837, loss = 0.39824917
Iteration 1838, loss = 0.39708846
Iteration 1839, loss = 0.39952007
Iteration 1840, loss = 0.39906672
Iteration 1841, loss = 0.39868495
Iteration 1842, loss = 0.39843612
Iteration 1843, loss = 0.40145079
Iteration 1844, loss = 0.39971480
Iteration 1845, loss = 0.39634741
Iteration 1846, loss = 0.40000785
Iteration 1847, loss = 0.40012583
Iteration 1848, loss = 0.39633241
Iteration 1849, loss = 0.39702672
Iteration 1850, loss = 0.39758463
Iteration 1851, loss = 0.40006565
Iteration 1852, loss = 0.39917665
Iteration 1853, loss = 0.40071491
Iteration 1854, loss = 0.39733645
Iteration 1855, loss = 0.40209921
Iteration 1856, loss = 0.39937101
Iteration 1857, loss = 0.39574594
Iteration 1858, loss = 0.39707615
Iteration 1859, loss = 0.39581649
Iteration 1860, loss = 0.39877661
Iteration 1861, loss = 0.39578032
Iteration 1862, loss = 0.39823065
Iteration 1863, loss = 0.39781338
Iteration 1864, loss = 0.39767591
Iteration 1865, loss = 0.40440638
Iteration 1866, loss = 0.39532457
Iteration 1867, loss = 0.40144888
Iteration 1868, loss = 0.39801698
Iteration 1869, loss = 0.39597081
Iteration 1870, loss = 0.40233112
Iteration 1871, loss = 0.39859790
Iteration 1872, loss = 0.39728255
Iteration 1873, loss = 0.40332365
Iteration 1874, loss = 0.40081352
Iteration 1875, loss = 0.39967894
Iteration 1876, loss = 0.39741867
Iteration 1877, loss = 0.39649069
Iteration 1878, loss = 0.39537804
Iteration 1879, loss = 0.39820591
Iteration 1880, loss = 0.39880620
Iteration 1881, loss = 0.39688879
Iteration 1882, loss = 0.39824319
Iteration 1883, loss = 0.39918619
Iteration 1884, loss = 0.39829900
Iteration 1885, loss = 0.39989335
Iteration 1886, loss = 0.39625000
Iteration 1887, loss = 0.39761846
Iteration 1888, loss = 0.39753636
Iteration 1889, loss = 0.39755230
Iteration 1890, loss = 0.39928225
Iteration 1891, loss = 0.39685520
Iteration 1892, loss = 0.39964150
Iteration 1893, loss = 0.40331224
Iteration 1894, loss = 0.39750867
Iteration 1895, loss = 0.39895220
Iteration 1896, loss = 0.40592157
Iteration 1897, loss = 0.39994975
Iteration 1898, loss = 0.39788011
Iteration 1899, loss = 0.39981070
Iteration 1900, loss = 0.39774715
Iteration 1901, loss = 0.39739953
Iteration 1902, loss = 0.39993149
Iteration 1903, loss = 0.39980063
Iteration 1904, loss = 0.40263915
Iteration 1905, loss = 0.39760745
Iteration 1906, loss = 0.39673682
Iteration 1907, loss = 0.40133874
Iteration 1908, loss = 0.39951199
Iteration 1909, loss = 0.39651259
Iteration 1910, loss = 0.39730361
Iteration 1911, loss = 0.39692950
Iteration 1912, loss = 0.39523291
Iteration 1913, loss = 0.39579316
Iteration 1914, loss = 0.39780104
Iteration 1915, loss = 0.39818796
Iteration 1916, loss = 0.40138318
Iteration 1917, loss = 0.39899823
Iteration 1918, loss = 0.39934559
Iteration 1919, loss = 0.39635477
Iteration 1920, loss = 0.39526774
Iteration 1921, loss = 0.39707215
Iteration 1922, loss = 0.39806713
Iteration 1923, loss = 0.39875981
Iteration 1924, loss = 0.39688461
Iteration 1925, loss = 0.39415237
Iteration 1926, loss = 0.39811082
Iteration 1927, loss = 0.39753080
Iteration 1928, loss = 0.39818254
Iteration 1929, loss = 0.39804724
Iteration 1930, loss = 0.39671120
Iteration 1931, loss = 0.39933813
Iteration 1932, loss = 0.39689428
Iteration 1933, loss = 0.39571459
Iteration 1934, loss = 0.39885192
Iteration 1935, loss = 0.40130275
Iteration 1936, loss = 0.39524586
Iteration 1937, loss = 0.39610994
Iteration 1938, loss = 0.39404438
Iteration 1939, loss = 0.39614379
Iteration 1940, loss = 0.39496626
Iteration 1941, loss = 0.39583531
Iteration 1942, loss = 0.39923826
Iteration 1943, loss = 0.39616208
Iteration 1944, loss = 0.39604384
Iteration 1945, loss = 0.39794445
Iteration 1946, loss = 0.39697006
Iteration 1947, loss = 0.39855996
Iteration 1948, loss = 0.39662887
Iteration 1949, loss = 0.40056192
Iteration 1950, loss = 0.39867254
Iteration 1951, loss = 0.39660874
Iteration 1952, loss = 0.39717082
Iteration 1953, loss = 0.39629924
Iteration 1954, loss = 0.39660019
Iteration 1955, loss = 0.39513050
Iteration 1956, loss = 0.39716955
Iteration 1957, loss = 0.40001216
Iteration 1958, loss = 0.39799958
Iteration 1959, loss = 0.39393546
Iteration 1960, loss = 0.39784240
Iteration 1961, loss = 0.39502471
Iteration 1962, loss = 0.39560028
Iteration 1963, loss = 0.39587258
Iteration 1964, loss = 0.39799464
Iteration 1965, loss = 0.39560561
Iteration 1966, loss = 0.40014689
Iteration 1967, loss = 0.39689948
Iteration 1968, loss = 0.39652793
Iteration 1969, loss = 0.39623756
Iteration 1970, loss = 0.39612243
Iteration 1971, loss = 0.39541510
Iteration 1972, loss = 0.39809420
Iteration 1973, loss = 0.39690761
Iteration 1974, loss = 0.39702010
Iteration 1975, loss = 0.39593208
Iteration 1976, loss = 0.39752830
Iteration 1977, loss = 0.39913090
Iteration 1978, loss = 0.39456099
Iteration 1979, loss = 0.39629136
Iteration 1980, loss = 0.39571241
Iteration 1981, loss = 0.39803055
Iteration 1982, loss = 0.39503397
Iteration 1983, loss = 0.39818207
Iteration 1984, loss = 0.39708877
Iteration 1985, loss = 0.39527506
Iteration 1986, loss = 0.39613965
Iteration 1987, loss = 0.39415202
Iteration 1988, loss = 0.39327323
Iteration 1989, loss = 0.39600345
Iteration 1990, loss = 0.39538964
Iteration 1991, loss = 0.39577126
Iteration 1992, loss = 0.39470650
Iteration 1993, loss = 0.39461386
Iteration 1994, loss = 0.39745563
Iteration 1995, loss = 0.39674363
Iteration 1996, loss = 0.39708257
Iteration 1997, loss = 0.39306767
Iteration 1998, loss = 0.39547650
Iteration 1999, loss = 0.39603065
Iteration 2000, loss = 0.39497079
Iteration 2001, loss = 0.39459464
Iteration 2002, loss = 0.39415379
Iteration 2003, loss = 0.40057749
Iteration 2004, loss = 0.39782126
Iteration 2005, loss = 0.39762985
Iteration 2006, loss = 0.39700543
Iteration 2007, loss = 0.39553293
Iteration 2008, loss = 0.39756166
Iteration 2009, loss = 0.39653049
Iteration 2010, loss = 0.39498937
Iteration 2011, loss = 0.39519757
Iteration 2012, loss = 0.39696600
Iteration 2013, loss = 0.39550560
Iteration 2014, loss = 0.39396214
Iteration 2015, loss = 0.39467737
Iteration 2016, loss = 0.39292083
Iteration 2017, loss = 0.39704782
Iteration 2018, loss = 0.39512468
Iteration 2019, loss = 0.39553499
Iteration 2020, loss = 0.39526168
Iteration 2021, loss = 0.39790566
Iteration 2022, loss = 0.39349807
Iteration 2023, loss = 0.39457293
Iteration 2024, loss = 0.39572927
Iteration 2025, loss = 0.39562477
Iteration 2026, loss = 0.39420242
Iteration 2027, loss = 0.39372315
Iteration 2028, loss = 0.39535623
Iteration 2029, loss = 0.39604621
Iteration 2030, loss = 0.39640095
Iteration 2031, loss = 0.39656767
Iteration 2032, loss = 0.39611976
Iteration 2033, loss = 0.39705964
Iteration 2034, loss = 0.39619576
Iteration 2035, loss = 0.39624278
Iteration 2036, loss = 0.39630113
Iteration 2037, loss = 0.39480614
Iteration 2038, loss = 0.39280590
Iteration 2039, loss = 0.39563988
Iteration 2040, loss = 0.39931268
Iteration 2041, loss = 0.39625714
Iteration 2042, loss = 0.39693986
Iteration 2043, loss = 0.39599779
Iteration 2044, loss = 0.39446972
Iteration 2045, loss = 0.39459010
Iteration 2046, loss = 0.39380916
Iteration 2047, loss = 0.39618651
Iteration 2048, loss = 0.39410576
Iteration 2049, loss = 0.39584431
Iteration 2050, loss = 0.39325827
Iteration 2051, loss = 0.39132308
Iteration 2052, loss = 0.39414153
Iteration 2053, loss = 0.39567019
Iteration 2054, loss = 0.39840576
Iteration 2055, loss = 0.39983897
Iteration 2056, loss = 0.39940933
Iteration 2057, loss = 0.39298555
Iteration 2058, loss = 0.39319985
Iteration 2059, loss = 0.39691394
Iteration 2060, loss = 0.39387554
Iteration 2061, loss = 0.39334017
Iteration 2062, loss = 0.39731561
Iteration 2063, loss = 0.39667092
Iteration 2064, loss = 0.39602676
Iteration 2065, loss = 0.39309750
Iteration 2066, loss = 0.39362829
Iteration 2067, loss = 0.39362071
Iteration 2068, loss = 0.39560590
Iteration 2069, loss = 0.39593834
Iteration 2070, loss = 0.39404311
Iteration 2071, loss = 0.39457997
Iteration 2072, loss = 0.39229332
Iteration 2073, loss = 0.39490355
Iteration 2074, loss = 0.39609674
Iteration 2075, loss = 0.39549364
Iteration 2076, loss = 0.39428002
Iteration 2077, loss = 0.39391570
Iteration 2078, loss = 0.39270594
Iteration 2079, loss = 0.39577799
Iteration 2080, loss = 0.39355752
Iteration 2081, loss = 0.39521085
Iteration 2082, loss = 0.39525296
Iteration 2083, loss = 0.39500226
Iteration 2084, loss = 0.39571659
Iteration 2085, loss = 0.39099199
Iteration 2086, loss = 0.39155114
Iteration 2087, loss = 0.39077773
Iteration 2088, loss = 0.39331722
Iteration 2089, loss = 0.39370053
Iteration 2090, loss = 0.39425925
Iteration 2091, loss = 0.39476356
Iteration 2092, loss = 0.39355685
Iteration 2093, loss = 0.39264961
Iteration 2094, loss = 0.39825120
Iteration 2095, loss = 0.39588087
Iteration 2096, loss = 0.39278776
Iteration 2097, loss = 0.39787711
Iteration 2098, loss = 0.39660779
Iteration 2099, loss = 0.39324829
Iteration 2100, loss = 0.39714188
Iteration 2101, loss = 0.39430027
Iteration 2102, loss = 0.39053335
Iteration 2103, loss = 0.39332657
Iteration 2104, loss = 0.39196392
Iteration 2105, loss = 0.39222245
Iteration 2106, loss = 0.39436254
Iteration 2107, loss = 0.40125379
Iteration 2108, loss = 0.39413473
Iteration 2109, loss = 0.39395110
Iteration 2110, loss = 0.39448671
Iteration 2111, loss = 0.39332973
Iteration 2112, loss = 0.39303040
Iteration 2113, loss = 0.39067915
Iteration 2114, loss = 0.39307775
Iteration 2115, loss = 0.39333469
Iteration 2116, loss = 0.39557469
Iteration 2117, loss = 0.39493503
Iteration 2118, loss = 0.39440019
Iteration 2119, loss = 0.39329269
Iteration 2120, loss = 0.39455713
Iteration 2121, loss = 0.39191786
Iteration 2122, loss = 0.39405952
Iteration 2123, loss = 0.39315318
Iteration 2124, loss = 0.39358535
Iteration 2125, loss = 0.39449360
Iteration 2126, loss = 0.39430464
Iteration 2127, loss = 0.39656078
Iteration 2128, loss = 0.39880787
Iteration 2129, loss = 0.39424355
Iteration 2130, loss = 0.39180318
Iteration 2131, loss = 0.39322305
Iteration 2132, loss = 0.39177344
Iteration 2133, loss = 0.39226184
Iteration 2134, loss = 0.39296933
Iteration 2135, loss = 0.39432155
Iteration 2136, loss = 0.39668449
Iteration 2137, loss = 0.39245817
Iteration 2138, loss = 0.39402079
Iteration 2139, loss = 0.39723015
Iteration 2140, loss = 0.39361654
Iteration 2141, loss = 0.39339698
Iteration 2142, loss = 0.40064349
Iteration 2143, loss = 0.39607819
Iteration 2144, loss = 0.39192304
Iteration 2145, loss = 0.39424220
Iteration 2146, loss = 0.39133068
Iteration 2147, loss = 0.39242977
Iteration 2148, loss = 0.39251886
Iteration 2149, loss = 0.39452652
Iteration 2150, loss = 0.39342320
Iteration 2151, loss = 0.39170692
Iteration 2152, loss = 0.39395284
Iteration 2153, loss = 0.39359585
Iteration 2154, loss = 0.39414990
Iteration 2155, loss = 0.39093380
Iteration 2156, loss = 0.39043053
Iteration 2157, loss = 0.39035069
Iteration 2158, loss = 0.39159214
Iteration 2159, loss = 0.39232310
Iteration 2160, loss = 0.39400038
Iteration 2161, loss = 0.39214068
Iteration 2162, loss = 0.39423395
Iteration 2163, loss = 0.39275786
Iteration 2164, loss = 0.39445448
Iteration 2165, loss = 0.39102621
Iteration 2166, loss = 0.39116350
Iteration 2167, loss = 0.39742920
Iteration 2168, loss = 0.39223539
Iteration 2169, loss = 0.39098956
Iteration 2170, loss = 0.39208426
Iteration 2171, loss = 0.39291856
Iteration 2172, loss = 0.39342145
Iteration 2173, loss = 0.39079662
Iteration 2174, loss = 0.39348205
Iteration 2175, loss = 0.39054929
Iteration 2176, loss = 0.39441748
Iteration 2177, loss = 0.39290481
Iteration 2178, loss = 0.39501399
Iteration 2179, loss = 0.39497646
Iteration 2180, loss = 0.39369237
Iteration 2181, loss = 0.39249029
Iteration 2182, loss = 0.39463899
Iteration 2183, loss = 0.39530999
Iteration 2184, loss = 0.39360973
Iteration 2185, loss = 0.39282726
Iteration 2186, loss = 0.39361247
Iteration 2187, loss = 0.39389001
Iteration 2188, loss = 0.39034425
Iteration 2189, loss = 0.39107930
Iteration 2190, loss = 0.39350855
Iteration 2191, loss = 0.39420870
Iteration 2192, loss = 0.39278844
Iteration 2193, loss = 0.39645534
Iteration 2194, loss = 0.39266917
Iteration 2195, loss = 0.39142973
Iteration 2196, loss = 0.38918679
Iteration 2197, loss = 0.39261112
Iteration 2198, loss = 0.39285490
Iteration 2199, loss = 0.39145407
Iteration 2200, loss = 0.39233198
Iteration 2201, loss = 0.39324853
Iteration 2202, loss = 0.39291042
Iteration 2203, loss = 0.39124103
Iteration 2204, loss = 0.39683342
Iteration 2205, loss = 0.39343132
Iteration 2206, loss = 0.39185600
Iteration 2207, loss = 0.39019572
Iteration 2208, loss = 0.39145942
Iteration 2209, loss = 0.39080853
Iteration 2210, loss = 0.38910091
Iteration 2211, loss = 0.40117575
Iteration 2212, loss = 0.39266242
Iteration 2213, loss = 0.39179289
Iteration 2214, loss = 0.39268867
Iteration 2215, loss = 0.39144377
Iteration 2216, loss = 0.39397524
Iteration 2217, loss = 0.38955719
Iteration 2218, loss = 0.39768075
Iteration 2219, loss = 0.39337558
Iteration 2220, loss = 0.39196270
Iteration 2221, loss = 0.39037256
Iteration 2222, loss = 0.38864709
Iteration 2223, loss = 0.39234611
Iteration 2224, loss = 0.39661026
Iteration 2225, loss = 0.39281555
Iteration 2226, loss = 0.39177202
Iteration 2227, loss = 0.39192226
Iteration 2228, loss = 0.39100472
Iteration 2229, loss = 0.38928991
Iteration 2230, loss = 0.39169151
Iteration 2231, loss = 0.39338647
Iteration 2232, loss = 0.39057597
Iteration 2233, loss = 0.39511606
Iteration 2234, loss = 0.39505554
Iteration 2235, loss = 0.39200052
Iteration 2236, loss = 0.39202337
Iteration 2237, loss = 0.39024630
Iteration 2238, loss = 0.39012137
Iteration 2239, loss = 0.39300957
Iteration 2240, loss = 0.39410388
Iteration 2241, loss = 0.39153888
Iteration 2242, loss = 0.39225389
Iteration 2243, loss = 0.39194689
Iteration 2244, loss = 0.39159747
Iteration 2245, loss = 0.39280324
Iteration 2246, loss = 0.39442510
Iteration 2247, loss = 0.39374268
Iteration 2248, loss = 0.39191279
Iteration 2249, loss = 0.39212574
Iteration 2250, loss = 0.39199891
Iteration 2251, loss = 0.39203382
Iteration 2252, loss = 0.39190806
Iteration 2253, loss = 0.39015751
Iteration 2254, loss = 0.39015587
Iteration 2255, loss = 0.38995052
Iteration 2256, loss = 0.39086368
Iteration 2257, loss = 0.39409083
Iteration 2258, loss = 0.39097129
Iteration 2259, loss = 0.39069126
Iteration 2260, loss = 0.38971181
Iteration 2261, loss = 0.39119217
Iteration 2262, loss = 0.39093221
Iteration 2263, loss = 0.39012833
Iteration 2264, loss = 0.39151942
Iteration 2265, loss = 0.39201893
Iteration 2266, loss = 0.39166357
Iteration 2267, loss = 0.39307634
Iteration 2268, loss = 0.38995512
Iteration 2269, loss = 0.38908811
Iteration 2270, loss = 0.38984418
Iteration 2271, loss = 0.39142961
Iteration 2272, loss = 0.39051279
Iteration 2273, loss = 0.39013530
Iteration 2274, loss = 0.39119116
Iteration 2275, loss = 0.38997438
Iteration 2276, loss = 0.38887588
Iteration 2277, loss = 0.39322804
Iteration 2278, loss = 0.39103226
Iteration 2279, loss = 0.39144861
Iteration 2280, loss = 0.39162298
Iteration 2281, loss = 0.39028981
Iteration 2282, loss = 0.38949173
Iteration 2283, loss = 0.39261717
Iteration 2284, loss = 0.39436394
Iteration 2285, loss = 0.39308075
Iteration 2286, loss = 0.39207336
Iteration 2287, loss = 0.39074563
Iteration 2288, loss = 0.38989369
Iteration 2289, loss = 0.39134445
Iteration 2290, loss = 0.38939398
Iteration 2291, loss = 0.39278927
Iteration 2292, loss = 0.39199413
Iteration 2293, loss = 0.38902602
Iteration 2294, loss = 0.39032476
Iteration 2295, loss = 0.38955262
Iteration 2296, loss = 0.38940773
Iteration 2297, loss = 0.39098432
Iteration 2298, loss = 0.39302925
Iteration 2299, loss = 0.39124247
Iteration 2300, loss = 0.38743797
Iteration 2301, loss = 0.39021734
Iteration 2302, loss = 0.39050250
Iteration 2303, loss = 0.39569919
Iteration 2304, loss = 0.38973630
Iteration 2305, loss = 0.38976022
Iteration 2306, loss = 0.39302481
Iteration 2307, loss = 0.39220014
Iteration 2308, loss = 0.39059727
Iteration 2309, loss = 0.39099440
Iteration 2310, loss = 0.38952043
Iteration 2311, loss = 0.39056448
Iteration 2312, loss = 0.38990271
Iteration 2313, loss = 0.38847017
Iteration 2314, loss = 0.39141095
Iteration 2315, loss = 0.38651240
Iteration 2316, loss = 0.38822821
Iteration 2317, loss = 0.39016202
Iteration 2318, loss = 0.39305581
Iteration 2319, loss = 0.38954732
Iteration 2320, loss = 0.38853719
Iteration 2321, loss = 0.38924780
Iteration 2322, loss = 0.39168753
Iteration 2323, loss = 0.38945257
Iteration 2324, loss = 0.39271811
Iteration 2325, loss = 0.39151774
Iteration 2326, loss = 0.38872493
Iteration 2327, loss = 0.39069459
Iteration 2328, loss = 0.38825726
Iteration 2329, loss = 0.39022170
Iteration 2330, loss = 0.39055824
Iteration 2331, loss = 0.39010110
Iteration 2332, loss = 0.38993151
Iteration 2333, loss = 0.38708636
Iteration 2334, loss = 0.38960032
Iteration 2335, loss = 0.38763363
Iteration 2336, loss = 0.39040068
Iteration 2337, loss = 0.39001192
Iteration 2338, loss = 0.38941083
Iteration 2339, loss = 0.39040610
Iteration 2340, loss = 0.39090004
Iteration 2341, loss = 0.38844273
Iteration 2342, loss = 0.39174676
Iteration 2343, loss = 0.38793265
Iteration 2344, loss = 0.38988844
Iteration 2345, loss = 0.38958486
Iteration 2346, loss = 0.39002621
Iteration 2347, loss = 0.38974458
Iteration 2348, loss = 0.39142968
Iteration 2349, loss = 0.39125624
Iteration 2350, loss = 0.39363120
Iteration 2351, loss = 0.39037538
Iteration 2352, loss = 0.39289266
Iteration 2353, loss = 0.38951075
Iteration 2354, loss = 0.38800818
Iteration 2355, loss = 0.39044497
Iteration 2356, loss = 0.39071415
Iteration 2357, loss = 0.38720416
Iteration 2358, loss = 0.39122855
Iteration 2359, loss = 0.38991562
Iteration 2360, loss = 0.38760677
Iteration 2361, loss = 0.39301849
Iteration 2362, loss = 0.39431661
Iteration 2363, loss = 0.38937897
Iteration 2364, loss = 0.39583509
Iteration 2365, loss = 0.38809522
Iteration 2366, loss = 0.39102230
Iteration 2367, loss = 0.38659194
Iteration 2368, loss = 0.38835186
Iteration 2369, loss = 0.39033177
Iteration 2370, loss = 0.39245469
Iteration 2371, loss = 0.39058401
Iteration 2372, loss = 0.38733507
Iteration 2373, loss = 0.38860282
Iteration 2374, loss = 0.38708401
Iteration 2375, loss = 0.38693947
Iteration 2376, loss = 0.38788340
Iteration 2377, loss = 0.39114879
Iteration 2378, loss = 0.39069643
Iteration 2379, loss = 0.39249956
Iteration 2380, loss = 0.38887829
Iteration 2381, loss = 0.39305521
Iteration 2382, loss = 0.39083526
Iteration 2383, loss = 0.39081154
Iteration 2384, loss = 0.38892476
Iteration 2385, loss = 0.39060880
Iteration 2386, loss = 0.39121181
Iteration 2387, loss = 0.39648957
Iteration 2388, loss = 0.38910102
Iteration 2389, loss = 0.38744488
Iteration 2390, loss = 0.39186794
Iteration 2391, loss = 0.38873063
Iteration 2392, loss = 0.39307503
Iteration 2393, loss = 0.39124997
Iteration 2394, loss = 0.39028302
Iteration 2395, loss = 0.38952828
Iteration 2396, loss = 0.39089674
Iteration 2397, loss = 0.39150169
Iteration 2398, loss = 0.38803148
Iteration 2399, loss = 0.38847064
Iteration 2400, loss = 0.38822529
Iteration 2401, loss = 0.39056062
Iteration 2402, loss = 0.38871807
Iteration 2403, loss = 0.38987918
Iteration 2404, loss = 0.38755372
Iteration 2405, loss = 0.38837292
Iteration 2406, loss = 0.38815197
Iteration 2407, loss = 0.38741568
Iteration 2408, loss = 0.38621864
Iteration 2409, loss = 0.38765067
Iteration 2410, loss = 0.38876171
Iteration 2411, loss = 0.38946784
Iteration 2412, loss = 0.39052894
Iteration 2413, loss = 0.38800125
Iteration 2414, loss = 0.39000562
Iteration 2415, loss = 0.38890228
Iteration 2416, loss = 0.38794991
Iteration 2417, loss = 0.38603406
Iteration 2418, loss = 0.38962308
Iteration 2419, loss = 0.38898860
Iteration 2420, loss = 0.39182143
Iteration 2421, loss = 0.38835438
Iteration 2422, loss = 0.38850870
Iteration 2423, loss = 0.38779930
Iteration 2424, loss = 0.38815659
Iteration 2425, loss = 0.38811111
Iteration 2426, loss = 0.39063712
Iteration 2427, loss = 0.39160760
Iteration 2428, loss = 0.38793024
Iteration 2429, loss = 0.38915058
Iteration 2430, loss = 0.39032896
Iteration 2431, loss = 0.38833992
Iteration 2432, loss = 0.38835396
Iteration 2433, loss = 0.38948381
Iteration 2434, loss = 0.38619050
Iteration 2435, loss = 0.38777583
Iteration 2436, loss = 0.38998708
Iteration 2437, loss = 0.38859032
Iteration 2438, loss = 0.38669011
Iteration 2439, loss = 0.38706406
Iteration 2440, loss = 0.38836375
Iteration 2441, loss = 0.38590169
Iteration 2442, loss = 0.38942137
Iteration 2443, loss = 0.38959325
Iteration 2444, loss = 0.38843141
Iteration 2445, loss = 0.38806139
Iteration 2446, loss = 0.38720221
Iteration 2447, loss = 0.38891526
Iteration 2448, loss = 0.38789700
Iteration 2449, loss = 0.38910464
Iteration 2450, loss = 0.38901245
Iteration 2451, loss = 0.38767927
Iteration 2452, loss = 0.38583344
Iteration 2453, loss = 0.38998560
Iteration 2454, loss = 0.38823309
Iteration 2455, loss = 0.38723845
Iteration 2456, loss = 0.38711397
Iteration 2457, loss = 0.38691986
Iteration 2458, loss = 0.38886217
Iteration 2459, loss = 0.38857251
Iteration 2460, loss = 0.38961158
Iteration 2461, loss = 0.39007696
Iteration 2462, loss = 0.38590684
Iteration 2463, loss = 0.38716306
Iteration 2464, loss = 0.38666008
Iteration 2465, loss = 0.38878934
Iteration 2466, loss = 0.38731310
Iteration 2467, loss = 0.38998473
Iteration 2468, loss = 0.38943743
Iteration 2469, loss = 0.38890092
Iteration 2470, loss = 0.38759275
Iteration 2471, loss = 0.38790408
Iteration 2472, loss = 0.38955482
Iteration 2473, loss = 0.38859180
Iteration 2474, loss = 0.38981410
Iteration 2475, loss = 0.39009041
Iteration 2476, loss = 0.38820882
Iteration 2477, loss = 0.38543405
Iteration 2478, loss = 0.38387594
Iteration 2479, loss = 0.38800255
Iteration 2480, loss = 0.38946178
Iteration 2481, loss = 0.38768848
Iteration 2482, loss = 0.38600086
Iteration 2483, loss = 0.38779286
Iteration 2484, loss = 0.39231136
Iteration 2485, loss = 0.38916170
Iteration 2486, loss = 0.39238707
Iteration 2487, loss = 0.38887695
Iteration 2488, loss = 0.38778925
Iteration 2489, loss = 0.38882570
Iteration 2490, loss = 0.39067956
Iteration 2491, loss = 0.38776127
Iteration 2492, loss = 0.38835030
Iteration 2493, loss = 0.38951688
Iteration 2494, loss = 0.39058372
Iteration 2495, loss = 0.38793451
Iteration 2496, loss = 0.38552933
Iteration 2497, loss = 0.39106184
Iteration 2498, loss = 0.38825495
Iteration 2499, loss = 0.38492546
Iteration 2500, loss = 0.38457613
Iteration 2501, loss = 0.38634417
Iteration 2502, loss = 0.39029680
Iteration 2503, loss = 0.39146018
Iteration 2504, loss = 0.38762966
Iteration 2505, loss = 0.39112988
Iteration 2506, loss = 0.38912446
Iteration 2507, loss = 0.38962437
Iteration 2508, loss = 0.38963956
Iteration 2509, loss = 0.38686870
Iteration 2510, loss = 0.38601058
Iteration 2511, loss = 0.38428555
Iteration 2512, loss = 0.38718425
Iteration 2513, loss = 0.38548586
Iteration 2514, loss = 0.38465449
Iteration 2515, loss = 0.38603862
Iteration 2516, loss = 0.39149588
Iteration 2517, loss = 0.38876083
Iteration 2518, loss = 0.38939992
Iteration 2519, loss = 0.38632535
Iteration 2520, loss = 0.38704701
Iteration 2521, loss = 0.38935734
Iteration 2522, loss = 0.38692186
Iteration 2523, loss = 0.38606483
Iteration 2524, loss = 0.38745466
Iteration 2525, loss = 0.38600418
Iteration 2526, loss = 0.38545449
Iteration 2527, loss = 0.38911398
Iteration 2528, loss = 0.38871572
Iteration 2529, loss = 0.38662565
Iteration 2530, loss = 0.38943312
Iteration 2531, loss = 0.38785121
Iteration 2532, loss = 0.38388094
Iteration 2533, loss = 0.38536828
Iteration 2534, loss = 0.38487913
Iteration 2535, loss = 0.38754697
Iteration 2536, loss = 0.38896292
Iteration 2537, loss = 0.38816325
Iteration 2538, loss = 0.38638566
Iteration 2539, loss = 0.38472932
Iteration 2540, loss = 0.38815307
Iteration 2541, loss = 0.38702438
Iteration 2542, loss = 0.38615543
Iteration 2543, loss = 0.39008118
Iteration 2544, loss = 0.38626056
Iteration 2545, loss = 0.38751444
Iteration 2546, loss = 0.38780436
Iteration 2547, loss = 0.38392620
Iteration 2548, loss = 0.38486417
Iteration 2549, loss = 0.38698723
Iteration 2550, loss = 0.38651886
Iteration 2551, loss = 0.38634602
Iteration 2552, loss = 0.38658600
Iteration 2553, loss = 0.38608313
Iteration 2554, loss = 0.38773819
Iteration 2555, loss = 0.38460958
Iteration 2556, loss = 0.38988742
Iteration 2557, loss = 0.38696317
Iteration 2558, loss = 0.38550559
Iteration 2559, loss = 0.38725070
Iteration 2560, loss = 0.38583575
Iteration 2561, loss = 0.38572653
Iteration 2562, loss = 0.38297101
Iteration 2563, loss = 0.38707012
Iteration 2564, loss = 0.38692910
Iteration 2565, loss = 0.38430788
Iteration 2566, loss = 0.38424129
Iteration 2567, loss = 0.38849882
Iteration 2568, loss = 0.38702148
Iteration 2569, loss = 0.38296621
Iteration 2570, loss = 0.38713115
Iteration 2571, loss = 0.38738112
Iteration 2572, loss = 0.38796970
Iteration 2573, loss = 0.38611469
Iteration 2574, loss = 0.38460699
Iteration 2575, loss = 0.38493784
Iteration 2576, loss = 0.38434403
Iteration 2577, loss = 0.38473252
Iteration 2578, loss = 0.38359424
Iteration 2579, loss = 0.38380867
Iteration 2580, loss = 0.38410286
Iteration 2581, loss = 0.38624729
Iteration 2582, loss = 0.38811994
Iteration 2583, loss = 0.38630548
Iteration 2584, loss = 0.38567370
Iteration 2585, loss = 0.38583615
Iteration 2586, loss = 0.38465372
Iteration 2587, loss = 0.38268188
Iteration 2588, loss = 0.38774758
Iteration 2589, loss = 0.38741025
Iteration 2590, loss = 0.38781371
Iteration 2591, loss = 0.38531921
Iteration 2592, loss = 0.38786252
Iteration 2593, loss = 0.38709316
Iteration 2594, loss = 0.38538760
Iteration 2595, loss = 0.38579249
Iteration 2596, loss = 0.38778274
Iteration 2597, loss = 0.38970576
Iteration 2598, loss = 0.38916812
Iteration 2599, loss = 0.38787725
Iteration 2600, loss = 0.38651555
Iteration 2601, loss = 0.38555037
Iteration 2602, loss = 0.38830532
Iteration 2603, loss = 0.38588871
Iteration 2604, loss = 0.38563404
Iteration 2605, loss = 0.38381999
Iteration 2606, loss = 0.38506058
Iteration 2607, loss = 0.38637288
Iteration 2608, loss = 0.38525263
Iteration 2609, loss = 0.38656610
Iteration 2610, loss = 0.38833403
Iteration 2611, loss = 0.38910386
Iteration 2612, loss = 0.38772078
Iteration 2613, loss = 0.38744572
Iteration 2614, loss = 0.39044947
Iteration 2615, loss = 0.38530626
Iteration 2616, loss = 0.38323509
Iteration 2617, loss = 0.38960056
Iteration 2618, loss = 0.38529332
Iteration 2619, loss = 0.38375360
Iteration 2620, loss = 0.38683608
Iteration 2621, loss = 0.38735053
Iteration 2622, loss = 0.38664505
Iteration 2623, loss = 0.38520336
Iteration 2624, loss = 0.38763390
Iteration 2625, loss = 0.38661755
Iteration 2626, loss = 0.38323201
Iteration 2627, loss = 0.38379589
Iteration 2628, loss = 0.38396604
Iteration 2629, loss = 0.38786641
Iteration 2630, loss = 0.38766386
Iteration 2631, loss = 0.39167859
Iteration 2632, loss = 0.38422262
Iteration 2633, loss = 0.38744445
Iteration 2634, loss = 0.38196648
Iteration 2635, loss = 0.38490991
Iteration 2636, loss = 0.38586432
Iteration 2637, loss = 0.38482224
Iteration 2638, loss = 0.38441988
Iteration 2639, loss = 0.38466876
Iteration 2640, loss = 0.38345288
Iteration 2641, loss = 0.38453862
Iteration 2642, loss = 0.38593108
Iteration 2643, loss = 0.38940369
Iteration 2644, loss = 0.38976433
Iteration 2645, loss = 0.38458284
Iteration 2646, loss = 0.38331621
Iteration 2647, loss = 0.38998571
Iteration 2648, loss = 0.38687516
Iteration 2649, loss = 0.38872726
Iteration 2650, loss = 0.39280150
Iteration 2651, loss = 0.38558800
Iteration 2652, loss = 0.38906590
Iteration 2653, loss = 0.38421895
Iteration 2654, loss = 0.38738572
Iteration 2655, loss = 0.38755774
Iteration 2656, loss = 0.38454498
Iteration 2657, loss = 0.38395053
Iteration 2658, loss = 0.38347611
Iteration 2659, loss = 0.38472388
Iteration 2660, loss = 0.38393221
Iteration 2661, loss = 0.38764561
Iteration 2662, loss = 0.38445617
Iteration 2663, loss = 0.38544612
Iteration 2664, loss = 0.38717104
Iteration 2665, loss = 0.38843249
Iteration 2666, loss = 0.38543199
Iteration 2667, loss = 0.38246071
Iteration 2668, loss = 0.38474814
Iteration 2669, loss = 0.38412934
Iteration 2670, loss = 0.38737652
Iteration 2671, loss = 0.38324622
Iteration 2672, loss = 0.38530732
Iteration 2673, loss = 0.38402215
Iteration 2674, loss = 0.38503788
Iteration 2675, loss = 0.38370527
Iteration 2676, loss = 0.38388088
Iteration 2677, loss = 0.38497746
Iteration 2678, loss = 0.38640224
Iteration 2679, loss = 0.38369073
Iteration 2680, loss = 0.38280844
Iteration 2681, loss = 0.38545245
Iteration 2682, loss = 0.38461128
Iteration 2683, loss = 0.38396439
Iteration 2684, loss = 0.38072950
Iteration 2685, loss = 0.38426807
Iteration 2686, loss = 0.38307809
Iteration 2687, loss = 0.38467251
Iteration 2688, loss = 0.38443557
Iteration 2689, loss = 0.38501782
Iteration 2690, loss = 0.38306933
Iteration 2691, loss = 0.38342457
Iteration 2692, loss = 0.38477283
Iteration 2693, loss = 0.38493374
Iteration 2694, loss = 0.38425725
Iteration 2695, loss = 0.38238484
Iteration 2696, loss = 0.38484576
Iteration 2697, loss = 0.38795862
Iteration 2698, loss = 0.38405069
Iteration 2699, loss = 0.38358762
Iteration 2700, loss = 0.38622935
Iteration 2701, loss = 0.38404024
Iteration 2702, loss = 0.38731703
Iteration 2703, loss = 0.38426317
Iteration 2704, loss = 0.38473181
Iteration 2705, loss = 0.38878482
Iteration 2706, loss = 0.38607058
Iteration 2707, loss = 0.38274031
Iteration 2708, loss = 0.38752050
Iteration 2709, loss = 0.38715357
Iteration 2710, loss = 0.38773228
Iteration 2711, loss = 0.38507385
Iteration 2712, loss = 0.38496884
Iteration 2713, loss = 0.38406633
Iteration 2714, loss = 0.38222124
Iteration 2715, loss = 0.38456483
Iteration 2716, loss = 0.38765726
Iteration 2717, loss = 0.38210083
Iteration 2718, loss = 0.38182634
Iteration 2719, loss = 0.38356375
Iteration 2720, loss = 0.38555137
Iteration 2721, loss = 0.38543888
Iteration 2722, loss = 0.39145854
Iteration 2723, loss = 0.38586441
Iteration 2724, loss = 0.38672207
Iteration 2725, loss = 0.38614161
Iteration 2726, loss = 0.38254082
Iteration 2727, loss = 0.38746447
Iteration 2728, loss = 0.38262026
Iteration 2729, loss = 0.38322865
Iteration 2730, loss = 0.38632444
Iteration 2731, loss = 0.38389773
Iteration 2732, loss = 0.38182937
Iteration 2733, loss = 0.38504453
Iteration 2734, loss = 0.38501641
Iteration 2735, loss = 0.38539507
Iteration 2736, loss = 0.38215659
Iteration 2737, loss = 0.38403269
Iteration 2738, loss = 0.38531684
Iteration 2739, loss = 0.38496997
Iteration 2740, loss = 0.38153800
Iteration 2741, loss = 0.38445616
Iteration 2742, loss = 0.38299882
Iteration 2743, loss = 0.38595794
Iteration 2744, loss = 0.38480249
Iteration 2745, loss = 0.38441586
Iteration 2746, loss = 0.38430609
Iteration 2747, loss = 0.38340915
Iteration 2748, loss = 0.38558423
Iteration 2749, loss = 0.38609295
Iteration 2750, loss = 0.38419111
Iteration 2751, loss = 0.38376156
Iteration 2752, loss = 0.38290719
Iteration 2753, loss = 0.38261134
Iteration 2754, loss = 0.38268207
Iteration 2755, loss = 0.38158167
Iteration 2756, loss = 0.38164830
Iteration 2757, loss = 0.38441420
Iteration 2758, loss = 0.38448382
Iteration 2759, loss = 0.38780755
Iteration 2760, loss = 0.38564587
Iteration 2761, loss = 0.38337292
Iteration 2762, loss = 0.38686296
Iteration 2763, loss = 0.38561180
Iteration 2764, loss = 0.38606359
Iteration 2765, loss = 0.38568813
Iteration 2766, loss = 0.38904347
Iteration 2767, loss = 0.38555385
Iteration 2768, loss = 0.38428897
Iteration 2769, loss = 0.38445883
Iteration 2770, loss = 0.38311000
Iteration 2771, loss = 0.38787755
Iteration 2772, loss = 0.38381073
Iteration 2773, loss = 0.38160855
Iteration 2774, loss = 0.38457492
Iteration 2775, loss = 0.38440870
Iteration 2776, loss = 0.38412492
Iteration 2777, loss = 0.38425382
Iteration 2778, loss = 0.38475793
Iteration 2779, loss = 0.38326115
Iteration 2780, loss = 0.38201387
Iteration 2781, loss = 0.38487000
Iteration 2782, loss = 0.38638231
Iteration 2783, loss = 0.38438311
Iteration 2784, loss = 0.38674426
Iteration 2785, loss = 0.38785616
Iteration 2786, loss = 0.38263385
Iteration 2787, loss = 0.38505782
Iteration 2788, loss = 0.38433898
Iteration 2789, loss = 0.38546242
Iteration 2790, loss = 0.38591994
Iteration 2791, loss = 0.38118241
Iteration 2792, loss = 0.38271927
Iteration 2793, loss = 0.38347901
Iteration 2794, loss = 0.38262575
Iteration 2795, loss = 0.38283949
Iteration 2796, loss = 0.38336820
Iteration 2797, loss = 0.38445985
Iteration 2798, loss = 0.38020169
Iteration 2799, loss = 0.38813933
Iteration 2800, loss = 0.38769465
Iteration 2801, loss = 0.38363773
Iteration 2802, loss = 0.38283537
Iteration 2803, loss = 0.38298319
Iteration 2804, loss = 0.38667021
Iteration 2805, loss = 0.38402843
Iteration 2806, loss = 0.38396172
Iteration 2807, loss = 0.38678335
Iteration 2808, loss = 0.38334140
Iteration 2809, loss = 0.38207748
Iteration 2810, loss = 0.38128115
Iteration 2811, loss = 0.38596628
Iteration 2812, loss = 0.38329974
Iteration 2813, loss = 0.38530085
Iteration 2814, loss = 0.38373653
Iteration 2815, loss = 0.38255954
Iteration 2816, loss = 0.38098406
Iteration 2817, loss = 0.38387525
Iteration 2818, loss = 0.38342293
Iteration 2819, loss = 0.38442639
Iteration 2820, loss = 0.38246241
Iteration 2821, loss = 0.38178109
Iteration 2822, loss = 0.38240576
Iteration 2823, loss = 0.38158614
Iteration 2824, loss = 0.38521622
Iteration 2825, loss = 0.38390733
Iteration 2826, loss = 0.38449066
Iteration 2827, loss = 0.38600466
Iteration 2828, loss = 0.38171266
Iteration 2829, loss = 0.38145972
Iteration 2830, loss = 0.38090635
Iteration 2831, loss = 0.38318830
Iteration 2832, loss = 0.38330377
Iteration 2833, loss = 0.38383547
Iteration 2834, loss = 0.38236582
Iteration 2835, loss = 0.38394101
Iteration 2836, loss = 0.38346574
Iteration 2837, loss = 0.38423251
Iteration 2838, loss = 0.38473482
Iteration 2839, loss = 0.38665263
Iteration 2840, loss = 0.38395176
Iteration 2841, loss = 0.38190715
Iteration 2842, loss = 0.38040542
Iteration 2843, loss = 0.38061429
Iteration 2844, loss = 0.38365356
Iteration 2845, loss = 0.38046180
Iteration 2846, loss = 0.38278355
Iteration 2847, loss = 0.38166963
Iteration 2848, loss = 0.38233587
Iteration 2849, loss = 0.38117552
Iteration 2850, loss = 0.37925663
Iteration 2851, loss = 0.38287579
Iteration 2852, loss = 0.38142234
Iteration 2853, loss = 0.38428752
Iteration 2854, loss = 0.38229009
Iteration 2855, loss = 0.38235848
Iteration 2856, loss = 0.38012936
Iteration 2857, loss = 0.38225303
Iteration 2858, loss = 0.38339445
Iteration 2859, loss = 0.37959178
Iteration 2860, loss = 0.38147976
Iteration 2861, loss = 0.38161134
Iteration 2862, loss = 0.38154087
Iteration 2863, loss = 0.38050537
Iteration 2864, loss = 0.38191947
Iteration 2865, loss = 0.38526625
Iteration 2866, loss = 0.38112206
Iteration 2867, loss = 0.37997834
Iteration 2868, loss = 0.38009616
Iteration 2869, loss = 0.38144611
Iteration 2870, loss = 0.38334075
Iteration 2871, loss = 0.38125694
Iteration 2872, loss = 0.38392986
Iteration 2873, loss = 0.38476474
Iteration 2874, loss = 0.38265996
Iteration 2875, loss = 0.38653171
Iteration 2876, loss = 0.38058188
Iteration 2877, loss = 0.38128242
Iteration 2878, loss = 0.38161300
Iteration 2879, loss = 0.38293456
Iteration 2880, loss = 0.38192658
Iteration 2881, loss = 0.38083733
Iteration 2882, loss = 0.38221987
Iteration 2883, loss = 0.38539615
Iteration 2884, loss = 0.38176014
Iteration 2885, loss = 0.38060974
Iteration 2886, loss = 0.38228090
Iteration 2887, loss = 0.38136830
Iteration 2888, loss = 0.38552345
Iteration 2889, loss = 0.38196981
Iteration 2890, loss = 0.38394840
Iteration 2891, loss = 0.38160654
Iteration 2892, loss = 0.38470304
Iteration 2893, loss = 0.38598287
Iteration 2894, loss = 0.38445882
Iteration 2895, loss = 0.38294664
Iteration 2896, loss = 0.38340815
Iteration 2897, loss = 0.38273816
Iteration 2898, loss = 0.38081703
Iteration 2899, loss = 0.38222114
Iteration 2900, loss = 0.38168229
Iteration 2901, loss = 0.38317334
Iteration 2902, loss = 0.38270633
Iteration 2903, loss = 0.38292391
Iteration 2904, loss = 0.38211292
Iteration 2905, loss = 0.38191266
Iteration 2906, loss = 0.38004957
Iteration 2907, loss = 0.38189315
Iteration 2908, loss = 0.38355541
Iteration 2909, loss = 0.38954848
Iteration 2910, loss = 0.38116078
Iteration 2911, loss = 0.37938900
Iteration 2912, loss = 0.38117998
Iteration 2913, loss = 0.38036572
Iteration 2914, loss = 0.38076755
Iteration 2915, loss = 0.38463877
Iteration 2916, loss = 0.38186599
Iteration 2917, loss = 0.38161418
Iteration 2918, loss = 0.38335722
Iteration 2919, loss = 0.37850841
Iteration 2920, loss = 0.38246484
Iteration 2921, loss = 0.38130808
Iteration 2922, loss = 0.37923278
Iteration 2923, loss = 0.38262073
Iteration 2924, loss = 0.37886896
Iteration 2925, loss = 0.38078373
Iteration 2926, loss = 0.38382018
Iteration 2927, loss = 0.38225183
Iteration 2928, loss = 0.37999812
Iteration 2929, loss = 0.38043688
Iteration 2930, loss = 0.38236922
Iteration 2931, loss = 0.38449130
Iteration 2932, loss = 0.38133765
Iteration 2933, loss = 0.37930188
Iteration 2934, loss = 0.38131400
Iteration 2935, loss = 0.38310602
Iteration 2936, loss = 0.38334453
Iteration 2937, loss = 0.38115297
Iteration 2938, loss = 0.38412186
Iteration 2939, loss = 0.38403780
Iteration 2940, loss = 0.38206712
Iteration 2941, loss = 0.38317755
Iteration 2942, loss = 0.38308241
Iteration 2943, loss = 0.37977861
Iteration 2944, loss = 0.38797229
Iteration 2945, loss = 0.38197602
Iteration 2946, loss = 0.37952099
Iteration 2947, loss = 0.38077305
Iteration 2948, loss = 0.38058655
Iteration 2949, loss = 0.37943242
Iteration 2950, loss = 0.38095614
Iteration 2951, loss = 0.37963063
Iteration 2952, loss = 0.38250441
Iteration 2953, loss = 0.38569575
Iteration 2954, loss = 0.37929604
Iteration 2955, loss = 0.37989809
Iteration 2956, loss = 0.38600847
Iteration 2957, loss = 0.38211675
Iteration 2958, loss = 0.38063460
Iteration 2959, loss = 0.37872051
Iteration 2960, loss = 0.37901522
Iteration 2961, loss = 0.38097773
Iteration 2962, loss = 0.38346910
Iteration 2963, loss = 0.37922849
Iteration 2964, loss = 0.38125337
Iteration 2965, loss = 0.38424866
Iteration 2966, loss = 0.38227745
Iteration 2967, loss = 0.38059773
Iteration 2968, loss = 0.38001800
Iteration 2969, loss = 0.38149619
Iteration 2970, loss = 0.38129422
Iteration 2971, loss = 0.38020354
Iteration 2972, loss = 0.38157581
Iteration 2973, loss = 0.38691122
Iteration 2974, loss = 0.38065425
Iteration 2975, loss = 0.38241366
Iteration 2976, loss = 0.38100424
Iteration 2977, loss = 0.38188099
Iteration 2978, loss = 0.38187108
Iteration 2979, loss = 0.38122733
Iteration 2980, loss = 0.37883342
Iteration 2981, loss = 0.38109024
Iteration 2982, loss = 0.38207632
Iteration 2983, loss = 0.38153586
Iteration 2984, loss = 0.37943775
Iteration 2985, loss = 0.38499058
Iteration 2986, loss = 0.38270807
Iteration 2987, loss = 0.38293656
Iteration 2988, loss = 0.38077521
Iteration 2989, loss = 0.38040317
Iteration 2990, loss = 0.38022860
Iteration 2991, loss = 0.38083393
Iteration 2992, loss = 0.38109477
Iteration 2993, loss = 0.38304625
Iteration 2994, loss = 0.37910530
Iteration 2995, loss = 0.37835240
Iteration 2996, loss = 0.37950761
Iteration 2997, loss = 0.37974329
Iteration 2998, loss = 0.37857010
Iteration 2999, loss = 0.37980381
Iteration 3000, loss = 0.37928824
Iteration 3001, loss = 0.37982110
Iteration 3002, loss = 0.38071148
Iteration 3003, loss = 0.37925029
Iteration 3004, loss = 0.38441175
Iteration 3005, loss = 0.38194390
Iteration 3006, loss = 0.38131299
Iteration 3007, loss = 0.38081614
Iteration 3008, loss = 0.37902695
Iteration 3009, loss = 0.38041596
Iteration 3010, loss = 0.38410290
Iteration 3011, loss = 0.38010753
Iteration 3012, loss = 0.37833549
Iteration 3013, loss = 0.37759241
Iteration 3014, loss = 0.38003626
Iteration 3015, loss = 0.37746608
Iteration 3016, loss = 0.37985004
Iteration 3017, loss = 0.37983321
Iteration 3018, loss = 0.38253945
Iteration 3019, loss = 0.38074767
Iteration 3020, loss = 0.38185970
Iteration 3021, loss = 0.38084547
Iteration 3022, loss = 0.38057631
Iteration 3023, loss = 0.38082147
Iteration 3024, loss = 0.37934015
Iteration 3025, loss = 0.38051114
Iteration 3026, loss = 0.37873740
Iteration 3027, loss = 0.38001157
Iteration 3028, loss = 0.38118442
Iteration 3029, loss = 0.38172593
Iteration 3030, loss = 0.37832310
Iteration 3031, loss = 0.38406434
Iteration 3032, loss = 0.38000040
Iteration 3033, loss = 0.38002888
Iteration 3034, loss = 0.37954072
Iteration 3035, loss = 0.37986084
Iteration 3036, loss = 0.37863345
Iteration 3037, loss = 0.37744404
Iteration 3038, loss = 0.37976050
Iteration 3039, loss = 0.37851381
Iteration 3040, loss = 0.38061001
Iteration 3041, loss = 0.37943117
Iteration 3042, loss = 0.37863772
Iteration 3043, loss = 0.37976915
Iteration 3044, loss = 0.38299103
Iteration 3045, loss = 0.37864489
Iteration 3046, loss = 0.38658065
Iteration 3047, loss = 0.38385834
Iteration 3048, loss = 0.38257356
Iteration 3049, loss = 0.38213693
Iteration 3050, loss = 0.38052960
Iteration 3051, loss = 0.37780583
Iteration 3052, loss = 0.38041741
Iteration 3053, loss = 0.37921697
Iteration 3054, loss = 0.37972504
Iteration 3055, loss = 0.38009130
Iteration 3056, loss = 0.37884413
Iteration 3057, loss = 0.37895801
Iteration 3058, loss = 0.38306636
Iteration 3059, loss = 0.37967922
Iteration 3060, loss = 0.37911856
Iteration 3061, loss = 0.37957311
Iteration 3062, loss = 0.38014741
Iteration 3063, loss = 0.38193372
Iteration 3064, loss = 0.37884404
Iteration 3065, loss = 0.38091855
Iteration 3066, loss = 0.38041247
Iteration 3067, loss = 0.37927258
Iteration 3068, loss = 0.37954951
Iteration 3069, loss = 0.38088767
Iteration 3070, loss = 0.38124614
Iteration 3071, loss = 0.37822690
Iteration 3072, loss = 0.38371296
Iteration 3073, loss = 0.38079612
Iteration 3074, loss = 0.38005503
Iteration 3075, loss = 0.37823834
Iteration 3076, loss = 0.37950079
Iteration 3077, loss = 0.38195901
Iteration 3078, loss = 0.38079631
Iteration 3079, loss = 0.37988767
Iteration 3080, loss = 0.37901762
Iteration 3081, loss = 0.38048080
Iteration 3082, loss = 0.37973105
Iteration 3083, loss = 0.38303852
Iteration 3084, loss = 0.37983499
Iteration 3085, loss = 0.37880032
Iteration 3086, loss = 0.37928987
Iteration 3087, loss = 0.38042745
Iteration 3088, loss = 0.38141860
Iteration 3089, loss = 0.37991206
Iteration 3090, loss = 0.38247460
Iteration 3091, loss = 0.38166666
Iteration 3092, loss = 0.38188798
Iteration 3093, loss = 0.38155745
Iteration 3094, loss = 0.38055860
Iteration 3095, loss = 0.38155437
Iteration 3096, loss = 0.38284114
Iteration 3097, loss = 0.38344654
Iteration 3098, loss = 0.37972335
Iteration 3099, loss = 0.38120371
Iteration 3100, loss = 0.38375633
Iteration 3101, loss = 0.37941045
Iteration 3102, loss = 0.37871551
Iteration 3103, loss = 0.37762830
Iteration 3104, loss = 0.37716276
Iteration 3105, loss = 0.37898329
Iteration 3106, loss = 0.38204592
Iteration 3107, loss = 0.38541275
Iteration 3108, loss = 0.37899402
Iteration 3109, loss = 0.37754983
Iteration 3110, loss = 0.37785237
Iteration 3111, loss = 0.37715445
Iteration 3112, loss = 0.37901982
Iteration 3113, loss = 0.37892113
Iteration 3114, loss = 0.38313189
Iteration 3115, loss = 0.38231135
Iteration 3116, loss = 0.38091227
Iteration 3117, loss = 0.37834957
Iteration 3118, loss = 0.38077291
Iteration 3119, loss = 0.38215217
Iteration 3120, loss = 0.37874485
Iteration 3121, loss = 0.38008961
Iteration 3122, loss = 0.37886486
Iteration 3123, loss = 0.37851616
Iteration 3124, loss = 0.37951284
Iteration 3125, loss = 0.38039263
Iteration 3126, loss = 0.38023522
Iteration 3127, loss = 0.37972354
Iteration 3128, loss = 0.38086752
Iteration 3129, loss = 0.37873659
Iteration 3130, loss = 0.38253525
Iteration 3131, loss = 0.38232804
Iteration 3132, loss = 0.38060257
Iteration 3133, loss = 0.38009637
Iteration 3134, loss = 0.38065574
Iteration 3135, loss = 0.38025425
Iteration 3136, loss = 0.37843587
Iteration 3137, loss = 0.37873861
Iteration 3138, loss = 0.38017819
Iteration 3139, loss = 0.37844642
Iteration 3140, loss = 0.37887530
Iteration 3141, loss = 0.37932349
Iteration 3142, loss = 0.37878090
Iteration 3143, loss = 0.37686500
Iteration 3144, loss = 0.38001836
Iteration 3145, loss = 0.38147118
Iteration 3146, loss = 0.37767808
Iteration 3147, loss = 0.38039387
Iteration 3148, loss = 0.37910642
Iteration 3149, loss = 0.37863106
Iteration 3150, loss = 0.37565031
Iteration 3151, loss = 0.37823214
Iteration 3152, loss = 0.38525473
Iteration 3153, loss = 0.37873590
Iteration 3154, loss = 0.38386291
Iteration 3155, loss = 0.38040716
Iteration 3156, loss = 0.37872308
Iteration 3157, loss = 0.37784799
Iteration 3158, loss = 0.37810704
Iteration 3159, loss = 0.37679235
Iteration 3160, loss = 0.37855160
Iteration 3161, loss = 0.38168712
Iteration 3162, loss = 0.37918390
Iteration 3163, loss = 0.37813930
Iteration 3164, loss = 0.37929667
Iteration 3165, loss = 0.38009098
Iteration 3166, loss = 0.37814154
Iteration 3167, loss = 0.37617522
Iteration 3168, loss = 0.37807593
Iteration 3169, loss = 0.37874948
Iteration 3170, loss = 0.37818544
Iteration 3171, loss = 0.37724551
Iteration 3172, loss = 0.37866452
Iteration 3173, loss = 0.37722852
Iteration 3174, loss = 0.38593567
Iteration 3175, loss = 0.38572510
Iteration 3176, loss = 0.38005505
Iteration 3177, loss = 0.38059394
Iteration 3178, loss = 0.37956543
Iteration 3179, loss = 0.37776048
Iteration 3180, loss = 0.37846696
Iteration 3181, loss = 0.37671880
Iteration 3182, loss = 0.37878643
Iteration 3183, loss = 0.37755739
Iteration 3184, loss = 0.37830978
Iteration 3185, loss = 0.37882475
Iteration 3186, loss = 0.37674599
Iteration 3187, loss = 0.37807694
Iteration 3188, loss = 0.38016315
Iteration 3189, loss = 0.37873905
Iteration 3190, loss = 0.37880229
Iteration 3191, loss = 0.37813785
Iteration 3192, loss = 0.37913553
Iteration 3193, loss = 0.38059078
Iteration 3194, loss = 0.37889040
Iteration 3195, loss = 0.38263616
Iteration 3196, loss = 0.37837490
Iteration 3197, loss = 0.38041490
Iteration 3198, loss = 0.37967643
Iteration 3199, loss = 0.38076619
Iteration 3200, loss = 0.38082100
Iteration 3201, loss = 0.38368100
Iteration 3202, loss = 0.37851397
Iteration 3203, loss = 0.37708392
Iteration 3204, loss = 0.37891828
Iteration 3205, loss = 0.38598856
Iteration 3206, loss = 0.37966596
Iteration 3207, loss = 0.37991717
Iteration 3208, loss = 0.37927755
Iteration 3209, loss = 0.37914336
Iteration 3210, loss = 0.37855039
Iteration 3211, loss = 0.37722321
Iteration 3212, loss = 0.37715282
Iteration 3213, loss = 0.38044559
Iteration 3214, loss = 0.37994713
Iteration 3215, loss = 0.37989797
Iteration 3216, loss = 0.37753447
Iteration 3217, loss = 0.38044768
Iteration 3218, loss = 0.38157555
Iteration 3219, loss = 0.37762590
Iteration 3220, loss = 0.37696296
Iteration 3221, loss = 0.38120089
Iteration 3222, loss = 0.37910621
Iteration 3223, loss = 0.37957992
Iteration 3224, loss = 0.37641743
Iteration 3225, loss = 0.37787943
Iteration 3226, loss = 0.38225758
Iteration 3227, loss = 0.37796502
Iteration 3228, loss = 0.37807934
Iteration 3229, loss = 0.37690617
Iteration 3230, loss = 0.37781828
Iteration 3231, loss = 0.37968796
Iteration 3232, loss = 0.37977627
Iteration 3233, loss = 0.37875542
Iteration 3234, loss = 0.37647227
Iteration 3235, loss = 0.37642733
Iteration 3236, loss = 0.37686962
Iteration 3237, loss = 0.37691920
Iteration 3238, loss = 0.38000471
Iteration 3239, loss = 0.38208402
Iteration 3240, loss = 0.38239690
Iteration 3241, loss = 0.37955588
Iteration 3242, loss = 0.37687600
Iteration 3243, loss = 0.37738980
Iteration 3244, loss = 0.37995529
Iteration 3245, loss = 0.37850230
Iteration 3246, loss = 0.38066684
Iteration 3247, loss = 0.38027576
Iteration 3248, loss = 0.37809659
Iteration 3249, loss = 0.38066941
Iteration 3250, loss = 0.37958181
Iteration 3251, loss = 0.38049470
Iteration 3252, loss = 0.38165737
Iteration 3253, loss = 0.38023013
Iteration 3254, loss = 0.37862071
Iteration 3255, loss = 0.37999716
Iteration 3256, loss = 0.38152430
Iteration 3257, loss = 0.37912007
Iteration 3258, loss = 0.37724365
Iteration 3259, loss = 0.37784212
Iteration 3260, loss = 0.37781031
Iteration 3261, loss = 0.37699807
Iteration 3262, loss = 0.37739518
Iteration 3263, loss = 0.37785152
Iteration 3264, loss = 0.37641599
Iteration 3265, loss = 0.37680679
Iteration 3266, loss = 0.37806184
Iteration 3267, loss = 0.37761485
Iteration 3268, loss = 0.37587927
Iteration 3269, loss = 0.37690136
Iteration 3270, loss = 0.38138764
Iteration 3271, loss = 0.37750460
Iteration 3272, loss = 0.38088109
Iteration 3273, loss = 0.37936322
Iteration 3274, loss = 0.37638510
Iteration 3275, loss = 0.37897904
Iteration 3276, loss = 0.37689822
Iteration 3277, loss = 0.38073184
Iteration 3278, loss = 0.37551642
Iteration 3279, loss = 0.37814013
Iteration 3280, loss = 0.38059462
Iteration 3281, loss = 0.38289672
Iteration 3282, loss = 0.37854497
Iteration 3283, loss = 0.37755789
Iteration 3284, loss = 0.37657162
Iteration 3285, loss = 0.37627887
Iteration 3286, loss = 0.37568562
Iteration 3287, loss = 0.37643736
Iteration 3288, loss = 0.38113816
Iteration 3289, loss = 0.38019947
Iteration 3290, loss = 0.37677068
Iteration 3291, loss = 0.37767111
Iteration 3292, loss = 0.37492240
Iteration 3293, loss = 0.37581823
Iteration 3294, loss = 0.37520591
Iteration 3295, loss = 0.37651668
Iteration 3296, loss = 0.37788620
Iteration 3297, loss = 0.37600981
Iteration 3298, loss = 0.37568897
Iteration 3299, loss = 0.37794803
Iteration 3300, loss = 0.37627731
Iteration 3301, loss = 0.37525251
Iteration 3302, loss = 0.37538059
Iteration 3303, loss = 0.38081953
Iteration 3304, loss = 0.37739832
Iteration 3305, loss = 0.37828121
Iteration 3306, loss = 0.37578804
Iteration 3307, loss = 0.37673463
Iteration 3308, loss = 0.37747144
Iteration 3309, loss = 0.37780639
Iteration 3310, loss = 0.37861848
Iteration 3311, loss = 0.38004388
Iteration 3312, loss = 0.38129200
Iteration 3313, loss = 0.37546486
Iteration 3314, loss = 0.37948100
Iteration 3315, loss = 0.37754973
Iteration 3316, loss = 0.37931084
Iteration 3317, loss = 0.37896315
Iteration 3318, loss = 0.37843864
Iteration 3319, loss = 0.38074758
Iteration 3320, loss = 0.38072418
Iteration 3321, loss = 0.37702355
Iteration 3322, loss = 0.37686780
Iteration 3323, loss = 0.37718749
Iteration 3324, loss = 0.38007875
Iteration 3325, loss = 0.38390249
Iteration 3326, loss = 0.37833651
Iteration 3327, loss = 0.37554440
Iteration 3328, loss = 0.37815162
Iteration 3329, loss = 0.37546791
Iteration 3330, loss = 0.37553051
Iteration 3331, loss = 0.37603199
Iteration 3332, loss = 0.37699389
Iteration 3333, loss = 0.38027443
Iteration 3334, loss = 0.38045795
Iteration 3335, loss = 0.38157693
Iteration 3336, loss = 0.37696554
Iteration 3337, loss = 0.37551500
Iteration 3338, loss = 0.37783047
Iteration 3339, loss = 0.37577997
Iteration 3340, loss = 0.37709605
Iteration 3341, loss = 0.37800395
Iteration 3342, loss = 0.37771708
Iteration 3343, loss = 0.37741478
Iteration 3344, loss = 0.37546130
Iteration 3345, loss = 0.37447185
Iteration 3346, loss = 0.37601359
Iteration 3347, loss = 0.37931692
Iteration 3348, loss = 0.38116470
Iteration 3349, loss = 0.37745111
Iteration 3350, loss = 0.37655553
Iteration 3351, loss = 0.37547537
Iteration 3352, loss = 0.38279551
Iteration 3353, loss = 0.38565214
Iteration 3354, loss = 0.38040255
Iteration 3355, loss = 0.37505522
Iteration 3356, loss = 0.37648396
Iteration 3357, loss = 0.37610035
Iteration 3358, loss = 0.37765147
Iteration 3359, loss = 0.37710191
Iteration 3360, loss = 0.37782103
Iteration 3361, loss = 0.38022576
Iteration 3362, loss = 0.37959171
Iteration 3363, loss = 0.37607362
Iteration 3364, loss = 0.37475180
Iteration 3365, loss = 0.37889696
Iteration 3366, loss = 0.37994876
Iteration 3367, loss = 0.37892073
Iteration 3368, loss = 0.37856183
Iteration 3369, loss = 0.37670542
Iteration 3370, loss = 0.37591150
Iteration 3371, loss = 0.37746453
Iteration 3372, loss = 0.37807979
Iteration 3373, loss = 0.37522060
Iteration 3374, loss = 0.37767333
Iteration 3375, loss = 0.37529454
Iteration 3376, loss = 0.37585408
Iteration 3377, loss = 0.37452541
Iteration 3378, loss = 0.37399149
Iteration 3379, loss = 0.37638493
Iteration 3380, loss = 0.37862960
Iteration 3381, loss = 0.37648107
Iteration 3382, loss = 0.37600113
Iteration 3383, loss = 0.37479043
Iteration 3384, loss = 0.37604620
Iteration 3385, loss = 0.37590392
Iteration 3386, loss = 0.37672961
Iteration 3387, loss = 0.37538881
Iteration 3388, loss = 0.38054037
Iteration 3389, loss = 0.37494850
Iteration 3390, loss = 0.37714934
Iteration 3391, loss = 0.37540165
Iteration 3392, loss = 0.37565868
Iteration 3393, loss = 0.37431609
Iteration 3394, loss = 0.37599036
Iteration 3395, loss = 0.37735138
Iteration 3396, loss = 0.37815751
Iteration 3397, loss = 0.37746723
Iteration 3398, loss = 0.37645644
Iteration 3399, loss = 0.37678802
Iteration 3400, loss = 0.37994112
Iteration 3401, loss = 0.37783984
Iteration 3402, loss = 0.37835191
Iteration 3403, loss = 0.37862651
Iteration 3404, loss = 0.37518772
Iteration 3405, loss = 0.37511584
Iteration 3406, loss = 0.37475416
Iteration 3407, loss = 0.37561281
Iteration 3408, loss = 0.37456967
Iteration 3409, loss = 0.37442257
Iteration 3410, loss = 0.37582479
Iteration 3411, loss = 0.37793575
Iteration 3412, loss = 0.37708269
Iteration 3413, loss = 0.37725724
Iteration 3414, loss = 0.37746689
Iteration 3415, loss = 0.37601719
Iteration 3416, loss = 0.37854163
Iteration 3417, loss = 0.37966842
Iteration 3418, loss = 0.37660061
Iteration 3419, loss = 0.37821286
Iteration 3420, loss = 0.37923886
Iteration 3421, loss = 0.37759566
Iteration 3422, loss = 0.37655234
Iteration 3423, loss = 0.37635362
Iteration 3424, loss = 0.37744254
Iteration 3425, loss = 0.37587623
Iteration 3426, loss = 0.37507305
Iteration 3427, loss = 0.37613779
Iteration 3428, loss = 0.37462793
Iteration 3429, loss = 0.37963382
Iteration 3430, loss = 0.37750264
Iteration 3431, loss = 0.37367767
Iteration 3432, loss = 0.37646345
Iteration 3433, loss = 0.37660557
Iteration 3434, loss = 0.37498407
Iteration 3435, loss = 0.37671753
Iteration 3436, loss = 0.37636782
Iteration 3437, loss = 0.37546993
Iteration 3438, loss = 0.37864200
Iteration 3439, loss = 0.38095069
Iteration 3440, loss = 0.37584083
Iteration 3441, loss = 0.37577674
Iteration 3442, loss = 0.38024109
Iteration 3443, loss = 0.37493030
Iteration 3444, loss = 0.37498726
Iteration 3445, loss = 0.37600070
Iteration 3446, loss = 0.37572953
Iteration 3447, loss = 0.37749581
Iteration 3448, loss = 0.37721638
Iteration 3449, loss = 0.37536576
Iteration 3450, loss = 0.37550451
Iteration 3451, loss = 0.37707963
Iteration 3452, loss = 0.37333395
Iteration 3453, loss = 0.37501591
Iteration 3454, loss = 0.37461873
Iteration 3455, loss = 0.37661143
Iteration 3456, loss = 0.37805304
Iteration 3457, loss = 0.37739642
Iteration 3458, loss = 0.37793261
Iteration 3459, loss = 0.37393619
Iteration 3460, loss = 0.37770568
Iteration 3461, loss = 0.37328459
Iteration 3462, loss = 0.37398795
Iteration 3463, loss = 0.37205735
Iteration 3464, loss = 0.37502530
Iteration 3465, loss = 0.37380879
Iteration 3466, loss = 0.37545544
Iteration 3467, loss = 0.37754673
Iteration 3468, loss = 0.37825477
Iteration 3469, loss = 0.37677628
Iteration 3470, loss = 0.37696132
Iteration 3471, loss = 0.37707325
Iteration 3472, loss = 0.37769020
Iteration 3473, loss = 0.37678924
Iteration 3474, loss = 0.37501964
Iteration 3475, loss = 0.37883146
Iteration 3476, loss = 0.37634782
Iteration 3477, loss = 0.37746259
Iteration 3478, loss = 0.37529840
Iteration 3479, loss = 0.37465939
Iteration 3480, loss = 0.37527552
Iteration 3481, loss = 0.37475421
Iteration 3482, loss = 0.37654775
Iteration 3483, loss = 0.37711620
Iteration 3484, loss = 0.37245001
Iteration 3485, loss = 0.37502003
Iteration 3486, loss = 0.37498681
Iteration 3487, loss = 0.37541906
Iteration 3488, loss = 0.37825288
Iteration 3489, loss = 0.37442250
Iteration 3490, loss = 0.37715351
Iteration 3491, loss = 0.37734548
Iteration 3492, loss = 0.37322768
Iteration 3493, loss = 0.37914217
Iteration 3494, loss = 0.37667604
Iteration 3495, loss = 0.37520330
Iteration 3496, loss = 0.37691523
Iteration 3497, loss = 0.37643535
Iteration 3498, loss = 0.37288649
Iteration 3499, loss = 0.37701107
Iteration 3500, loss = 0.37538341
Iteration 3501, loss = 0.37398004
Iteration 3502, loss = 0.37625814
Iteration 3503, loss = 0.37277383
Iteration 3504, loss = 0.37743874
Iteration 3505, loss = 0.37924999
Iteration 3506, loss = 0.37810797
Iteration 3507, loss = 0.37399307
Iteration 3508, loss = 0.37388134
Iteration 3509, loss = 0.37612447
Iteration 3510, loss = 0.37636137
Iteration 3511, loss = 0.37345439
Iteration 3512, loss = 0.37558536
Iteration 3513, loss = 0.37568546
Iteration 3514, loss = 0.37527778
Iteration 3515, loss = 0.37251800
Iteration 3516, loss = 0.37661126
Iteration 3517, loss = 0.37508603
Iteration 3518, loss = 0.37840167
Iteration 3519, loss = 0.37525005
Iteration 3520, loss = 0.37651823
Iteration 3521, loss = 0.37686390
Iteration 3522, loss = 0.37908131
Iteration 3523, loss = 0.37457030
Iteration 3524, loss = 0.37278184
Iteration 3525, loss = 0.37579859
Iteration 3526, loss = 0.37954350
Iteration 3527, loss = 0.37384191
Iteration 3528, loss = 0.37427634
Iteration 3529, loss = 0.37753686
Iteration 3530, loss = 0.37447352
Iteration 3531, loss = 0.37534091
Iteration 3532, loss = 0.37459294
Iteration 3533, loss = 0.37350723
Iteration 3534, loss = 0.37362624
Iteration 3535, loss = 0.37408603
Iteration 3536, loss = 0.37410004
Iteration 3537, loss = 0.37500278
Iteration 3538, loss = 0.37813897
Iteration 3539, loss = 0.37430122
Iteration 3540, loss = 0.37732671
Iteration 3541, loss = 0.37558690
Iteration 3542, loss = 0.37499809
Iteration 3543, loss = 0.37728842
Iteration 3544, loss = 0.38097193
Iteration 3545, loss = 0.37836405
Iteration 3546, loss = 0.37389841
Iteration 3547, loss = 0.37308005
Iteration 3548, loss = 0.37371842
Iteration 3549, loss = 0.37557579
Iteration 3550, loss = 0.37226895
Iteration 3551, loss = 0.37344952
Iteration 3552, loss = 0.37342223
Iteration 3553, loss = 0.37515674
Iteration 3554, loss = 0.37347956
Iteration 3555, loss = 0.37388741
Iteration 3556, loss = 0.37848577
Iteration 3557, loss = 0.37477046
Iteration 3558, loss = 0.37450822
Iteration 3559, loss = 0.37547601
Iteration 3560, loss = 0.37373662
Iteration 3561, loss = 0.37312324
Iteration 3562, loss = 0.37815876
Iteration 3563, loss = 0.37643398
Iteration 3564, loss = 0.37571970
Iteration 3565, loss = 0.37538906
Iteration 3566, loss = 0.37578526
Iteration 3567, loss = 0.37365278
Iteration 3568, loss = 0.37540309
Iteration 3569, loss = 0.37540926
Iteration 3570, loss = 0.37477784
Iteration 3571, loss = 0.37353682
Iteration 3572, loss = 0.37460741
Iteration 3573, loss = 0.37395380
Iteration 3574, loss = 0.37530467
Iteration 3575, loss = 0.37801945
Iteration 3576, loss = 0.37538287
Iteration 3577, loss = 0.37616657
Iteration 3578, loss = 0.37665151
Iteration 3579, loss = 0.37218857
Iteration 3580, loss = 0.37373530
Iteration 3581, loss = 0.37264082
Iteration 3582, loss = 0.37231152
Iteration 3583, loss = 0.37450528
Iteration 3584, loss = 0.37601110
Iteration 3585, loss = 0.37617660
Iteration 3586, loss = 0.37426645
Iteration 3587, loss = 0.37389417
Iteration 3588, loss = 0.37248325
Iteration 3589, loss = 0.37761435
Iteration 3590, loss = 0.37597528
Iteration 3591, loss = 0.37456426
Iteration 3592, loss = 0.37611507
Iteration 3593, loss = 0.37354962
Iteration 3594, loss = 0.37773732
Iteration 3595, loss = 0.37437680
Iteration 3596, loss = 0.37835101
Iteration 3597, loss = 0.37653217
Iteration 3598, loss = 0.37321553
Iteration 3599, loss = 0.37805145
Iteration 3600, loss = 0.37714963
Iteration 3601, loss = 0.37873699
Iteration 3602, loss = 0.37427994
Iteration 3603, loss = 0.37382994
Iteration 3604, loss = 0.37370799
Iteration 3605, loss = 0.37234660
Iteration 3606, loss = 0.37326689
Iteration 3607, loss = 0.37300144
Iteration 3608, loss = 0.37582843
Iteration 3609, loss = 0.37753156
Iteration 3610, loss = 0.37511683
Iteration 3611, loss = 0.37625417
Iteration 3612, loss = 0.37559432
Iteration 3613, loss = 0.37359387
Iteration 3614, loss = 0.37321249
Iteration 3615, loss = 0.37180904
Iteration 3616, loss = 0.37807737
Iteration 3617, loss = 0.37911089
Iteration 3618, loss = 0.37947139
Iteration 3619, loss = 0.37665910
Iteration 3620, loss = 0.37450467
Iteration 3621, loss = 0.38167465
Iteration 3622, loss = 0.37628980
Iteration 3623, loss = 0.37520131
Iteration 3624, loss = 0.37515695
Iteration 3625, loss = 0.37681846
Iteration 3626, loss = 0.37735401
Iteration 3627, loss = 0.37816734
Iteration 3628, loss = 0.37942352
Iteration 3629, loss = 0.37512722
Iteration 3630, loss = 0.37580361
Iteration 3631, loss = 0.37951910
Iteration 3632, loss = 0.37642157
Iteration 3633, loss = 0.37775627
Iteration 3634, loss = 0.37745103
Iteration 3635, loss = 0.37538992
Iteration 3636, loss = 0.37238962
Iteration 3637, loss = 0.37200276
Iteration 3638, loss = 0.37316516
Iteration 3639, loss = 0.37098241
Iteration 3640, loss = 0.37197664
Iteration 3641, loss = 0.37504643
Iteration 3642, loss = 0.37649665
Iteration 3643, loss = 0.37462432
Iteration 3644, loss = 0.37096165
Iteration 3645, loss = 0.37232925
Iteration 3646, loss = 0.37679470
Iteration 3647, loss = 0.37589003
Iteration 3648, loss = 0.37689335
Iteration 3649, loss = 0.37595867
Iteration 3650, loss = 0.37844427
Iteration 3651, loss = 0.38047561
Iteration 3652, loss = 0.37580264
Iteration 3653, loss = 0.37437670
Iteration 3654, loss = 0.37230649
Iteration 3655, loss = 0.37481838
Iteration 3656, loss = 0.37323095
Iteration 3657, loss = 0.37395498
Iteration 3658, loss = 0.37287018
Iteration 3659, loss = 0.37218453
Iteration 3660, loss = 0.37351443
Iteration 3661, loss = 0.37706328
Iteration 3662, loss = 0.37226787
Iteration 3663, loss = 0.37297458
Iteration 3664, loss = 0.37345909
Iteration 3665, loss = 0.37186648
Iteration 3666, loss = 0.37322471
Iteration 3667, loss = 0.37475386
Iteration 3668, loss = 0.37325117
Iteration 3669, loss = 0.37654063
Iteration 3670, loss = 0.37616807
Iteration 3671, loss = 0.37467001
Iteration 3672, loss = 0.37417184
Iteration 3673, loss = 0.37501396
Iteration 3674, loss = 0.37861310
Iteration 3675, loss = 0.37665077
Iteration 3676, loss = 0.37315813
Iteration 3677, loss = 0.37408204
Iteration 3678, loss = 0.37666322
Iteration 3679, loss = 0.37826702
Iteration 3680, loss = 0.38036117
Iteration 3681, loss = 0.37689333
Iteration 3682, loss = 0.37670309
Iteration 3683, loss = 0.37597322
Iteration 3684, loss = 0.37461367
Iteration 3685, loss = 0.37258418
Iteration 3686, loss = 0.37024777
Iteration 3687, loss = 0.37511785
Iteration 3688, loss = 0.37399243
Iteration 3689, loss = 0.37177606
Iteration 3690, loss = 0.37311637
Iteration 3691, loss = 0.37482543
Iteration 3692, loss = 0.37366341
Iteration 3693, loss = 0.37683330
Iteration 3694, loss = 0.37287203
Iteration 3695, loss = 0.37365753
Iteration 3696, loss = 0.37500878
Iteration 3697, loss = 0.37511569
Iteration 3698, loss = 0.37241720
Iteration 3699, loss = 0.37349034
Iteration 3700, loss = 0.37099965
Iteration 3701, loss = 0.37353711
Iteration 3702, loss = 0.37156403
Iteration 3703, loss = 0.37320246
Iteration 3704, loss = 0.37236586
Iteration 3705, loss = 0.37324555
Iteration 3706, loss = 0.37526374
Iteration 3707, loss = 0.37549227
Iteration 3708, loss = 0.37502802
Iteration 3709, loss = 0.37584247
Iteration 3710, loss = 0.37301731
Iteration 3711, loss = 0.37335224
Iteration 3712, loss = 0.37278023
Iteration 3713, loss = 0.37336523
Iteration 3714, loss = 0.37545631
Iteration 3715, loss = 0.37234200
Iteration 3716, loss = 0.37167703
Iteration 3717, loss = 0.37559827
Iteration 3718, loss = 0.37333661
Iteration 3719, loss = 0.37262348
Iteration 3720, loss = 0.37160848
Iteration 3721, loss = 0.37136691
Iteration 3722, loss = 0.37223148
Iteration 3723, loss = 0.37364860
Iteration 3724, loss = 0.37303021
Iteration 3725, loss = 0.37697160
Iteration 3726, loss = 0.37528757
Iteration 3727, loss = 0.37361056
Iteration 3728, loss = 0.37514522
Iteration 3729, loss = 0.37650755
Iteration 3730, loss = 0.37480143
Iteration 3731, loss = 0.37430720
Iteration 3732, loss = 0.37561313
Iteration 3733, loss = 0.37554328
Iteration 3734, loss = 0.37516374
Iteration 3735, loss = 0.37254974
Iteration 3736, loss = 0.37298809
Iteration 3737, loss = 0.37540740
Iteration 3738, loss = 0.37502985
Iteration 3739, loss = 0.37563032
Iteration 3740, loss = 0.37424922
Iteration 3741, loss = 0.37311715
Iteration 3742, loss = 0.37421725
Iteration 3743, loss = 0.37413127
Iteration 3744, loss = 0.37272913
Iteration 3745, loss = 0.37424154
Iteration 3746, loss = 0.37329264
Iteration 3747, loss = 0.37604649
Iteration 3748, loss = 0.37497118
Iteration 3749, loss = 0.37415781
Iteration 3750, loss = 0.37378200
Iteration 3751, loss = 0.37440682
Iteration 3752, loss = 0.37447943
Iteration 3753, loss = 0.37571327
Iteration 3754, loss = 0.37413252
Iteration 3755, loss = 0.37457582
Iteration 3756, loss = 0.37355681
Iteration 3757, loss = 0.37348328
Iteration 3758, loss = 0.37330631
Iteration 3759, loss = 0.37118488
Iteration 3760, loss = 0.37508369
Iteration 3761, loss = 0.37390699
Iteration 3762, loss = 0.37131736
Iteration 3763, loss = 0.37369045
Iteration 3764, loss = 0.37205539
Iteration 3765, loss = 0.37518071
Iteration 3766, loss = 0.37284257
Iteration 3767, loss = 0.37433190
Iteration 3768, loss = 0.37048226
Iteration 3769, loss = 0.37203890
Iteration 3770, loss = 0.37313365
Iteration 3771, loss = 0.37233042
Iteration 3772, loss = 0.37267361
Iteration 3773, loss = 0.37390415
Iteration 3774, loss = 0.37236076
Iteration 3775, loss = 0.37081835
Iteration 3776, loss = 0.37165553
Iteration 3777, loss = 0.37188374
Iteration 3778, loss = 0.37631535
Iteration 3779, loss = 0.37340178
Iteration 3780, loss = 0.37214374
Iteration 3781, loss = 0.37312657
Iteration 3782, loss = 0.37284109
Iteration 3783, loss = 0.37308550
Iteration 3784, loss = 0.37336702
Iteration 3785, loss = 0.37440766
Iteration 3786, loss = 0.37160219
Iteration 3787, loss = 0.37614276
Iteration 3788, loss = 0.37467061
Iteration 3789, loss = 0.37518049
Iteration 3790, loss = 0.37589806
Iteration 3791, loss = 0.37266144
Iteration 3792, loss = 0.37118294
Iteration 3793, loss = 0.37275103
Iteration 3794, loss = 0.37200556
Iteration 3795, loss = 0.37262720
Iteration 3796, loss = 0.37217109
Iteration 3797, loss = 0.37333171
Iteration 3798, loss = 0.37233527
Iteration 3799, loss = 0.37277096
Iteration 3800, loss = 0.37222297
Iteration 3801, loss = 0.37475611
Iteration 3802, loss = 0.37607102
Iteration 3803, loss = 0.37357265
Iteration 3804, loss = 0.37394492
Iteration 3805, loss = 0.36990006
Iteration 3806, loss = 0.37281302
Iteration 3807, loss = 0.37494037
Iteration 3808, loss = 0.37226792
Iteration 3809, loss = 0.37031370
Iteration 3810, loss = 0.37159894
Iteration 3811, loss = 0.37276331
Iteration 3812, loss = 0.37194748
Iteration 3813, loss = 0.37447844
Iteration 3814, loss = 0.37165027
Iteration 3815, loss = 0.37276507
Iteration 3816, loss = 0.37172895
Iteration 3817, loss = 0.37566294
Iteration 3818, loss = 0.37305112
Iteration 3819, loss = 0.37702336
Iteration 3820, loss = 0.37501492
Iteration 3821, loss = 0.37279874
Iteration 3822, loss = 0.37373315
Iteration 3823, loss = 0.37266252
Iteration 3824, loss = 0.37357123
Iteration 3825, loss = 0.37237915
Iteration 3826, loss = 0.37254993
Iteration 3827, loss = 0.37147788
Iteration 3828, loss = 0.37470723
Iteration 3829, loss = 0.37273163
Iteration 3830, loss = 0.37431957
Iteration 3831, loss = 0.37271295
Iteration 3832, loss = 0.37570075
Iteration 3833, loss = 0.37605288
Iteration 3834, loss = 0.37168375
Iteration 3835, loss = 0.37098080
Iteration 3836, loss = 0.37385695
Iteration 3837, loss = 0.37356171
Iteration 3838, loss = 0.37352588
Iteration 3839, loss = 0.37220266
Iteration 3840, loss = 0.37009802
Iteration 3841, loss = 0.37327004
Iteration 3842, loss = 0.37660486
Iteration 3843, loss = 0.37634429
Iteration 3844, loss = 0.37352631
Iteration 3845, loss = 0.37475728
Iteration 3846, loss = 0.37033143
Iteration 3847, loss = 0.37133865
Iteration 3848, loss = 0.37280440
Iteration 3849, loss = 0.37425762
Iteration 3850, loss = 0.37226400
Iteration 3851, loss = 0.37421386
Iteration 3852, loss = 0.37214857
Iteration 3853, loss = 0.37201536
Iteration 3854, loss = 0.37462264
Iteration 3855, loss = 0.37179355
Iteration 3856, loss = 0.37411140
Iteration 3857, loss = 0.37289466
Iteration 3858, loss = 0.37490085
Iteration 3859, loss = 0.37607057
Iteration 3860, loss = 0.37253269
Iteration 3861, loss = 0.37140334
Iteration 3862, loss = 0.37082573
Iteration 3863, loss = 0.37089948
Iteration 3864, loss = 0.37171890
Iteration 3865, loss = 0.37098281
Iteration 3866, loss = 0.37610880
Iteration 3867, loss = 0.37338679
Iteration 3868, loss = 0.37125671
Iteration 3869, loss = 0.37227312
Iteration 3870, loss = 0.37159062
Iteration 3871, loss = 0.36925930
Iteration 3872, loss = 0.37290744
Iteration 3873, loss = 0.37234913
Iteration 3874, loss = 0.37226748
Iteration 3875, loss = 0.37164589
Iteration 3876, loss = 0.37133127
Iteration 3877, loss = 0.37461848
Iteration 3878, loss = 0.37246408
Iteration 3879, loss = 0.37465077
Iteration 3880, loss = 0.37395534
Iteration 3881, loss = 0.37482397
Iteration 3882, loss = 0.37655746
Iteration 3883, loss = 0.37415201
Iteration 3884, loss = 0.37073349
Iteration 3885, loss = 0.37059249
Iteration 3886, loss = 0.37144439
Iteration 3887, loss = 0.37135487
Iteration 3888, loss = 0.37312281
Iteration 3889, loss = 0.37174437
Iteration 3890, loss = 0.37252537
Iteration 3891, loss = 0.37309720
Iteration 3892, loss = 0.37978479
Iteration 3893, loss = 0.37070781
Iteration 3894, loss = 0.37131765
Iteration 3895, loss = 0.37368562
Iteration 3896, loss = 0.37534628
Iteration 3897, loss = 0.37454779
Iteration 3898, loss = 0.37833626
Iteration 3899, loss = 0.37678096
Iteration 3900, loss = 0.37806274
Iteration 3901, loss = 0.37326096
Iteration 3902, loss = 0.37037999
Iteration 3903, loss = 0.37222006
Iteration 3904, loss = 0.37173707
Iteration 3905, loss = 0.36944507
Iteration 3906, loss = 0.37013350
Iteration 3907, loss = 0.37264502
Iteration 3908, loss = 0.37185166
Iteration 3909, loss = 0.37246758
Iteration 3910, loss = 0.37369073
Iteration 3911, loss = 0.37165370
Iteration 3912, loss = 0.37232723
Iteration 3913, loss = 0.37033127
Iteration 3914, loss = 0.37150515
Iteration 3915, loss = 0.37031933
Iteration 3916, loss = 0.37075280
Iteration 3917, loss = 0.37371493
Iteration 3918, loss = 0.37428545
Iteration 3919, loss = 0.37126409
Iteration 3920, loss = 0.37221779
Iteration 3921, loss = 0.37307070
Iteration 3922, loss = 0.36848892
Iteration 3923, loss = 0.37064670
Iteration 3924, loss = 0.37216947
Iteration 3925, loss = 0.37316230
Iteration 3926, loss = 0.37252755
Iteration 3927, loss = 0.37471065
Iteration 3928, loss = 0.37114216
Iteration 3929, loss = 0.37205431
Iteration 3930, loss = 0.37235178
Iteration 3931, loss = 0.36980998
Iteration 3932, loss = 0.37081867
Iteration 3933, loss = 0.37312409
Iteration 3934, loss = 0.37062461
Iteration 3935, loss = 0.37412078
Iteration 3936, loss = 0.37246782
Iteration 3937, loss = 0.37352132
Iteration 3938, loss = 0.37287032
Iteration 3939, loss = 0.37217047
Iteration 3940, loss = 0.36761544
Iteration 3941, loss = 0.37366565
Iteration 3942, loss = 0.37264716
Iteration 3943, loss = 0.37056190
Iteration 3944, loss = 0.37245685
Iteration 3945, loss = 0.37464636
Iteration 3946, loss = 0.37456326
Iteration 3947, loss = 0.37474393
Iteration 3948, loss = 0.37154737
Iteration 3949, loss = 0.37048256
Iteration 3950, loss = 0.36978462
Iteration 3951, loss = 0.37084694
Iteration 3952, loss = 0.37677838
Iteration 3953, loss = 0.37959209
Iteration 3954, loss = 0.37142957
Iteration 3955, loss = 0.37075140
Iteration 3956, loss = 0.37075047
Iteration 3957, loss = 0.37119240
Iteration 3958, loss = 0.37046693
Iteration 3959, loss = 0.37269222
Iteration 3960, loss = 0.37171410
Iteration 3961, loss = 0.37235993
Iteration 3962, loss = 0.37246408
Iteration 3963, loss = 0.37086047
Iteration 3964, loss = 0.36960763
Iteration 3965, loss = 0.37107593
Iteration 3966, loss = 0.37272017
Iteration 3967, loss = 0.37065931
Iteration 3968, loss = 0.36839300
Iteration 3969, loss = 0.37083203
Iteration 3970, loss = 0.37197502
Iteration 3971, loss = 0.37029718
Iteration 3972, loss = 0.36944664
Iteration 3973, loss = 0.36922043
Iteration 3974, loss = 0.37284514
Iteration 3975, loss = 0.37030738
Iteration 3976, loss = 0.37026831
Iteration 3977, loss = 0.37029681
Iteration 3978, loss = 0.37059240
Iteration 3979, loss = 0.37237913
Iteration 3980, loss = 0.37151675
Iteration 3981, loss = 0.37164105
Iteration 3982, loss = 0.37322819
Iteration 3983, loss = 0.37405574
Iteration 3984, loss = 0.37178146
Iteration 3985, loss = 0.37090089
Iteration 3986, loss = 0.37308020
Iteration 3987, loss = 0.37134363
Iteration 3988, loss = 0.37057209
Iteration 3989, loss = 0.36981387
Iteration 3990, loss = 0.37166352
Iteration 3991, loss = 0.37335890
Iteration 3992, loss = 0.37200620
Iteration 3993, loss = 0.37175801
Iteration 3994, loss = 0.37076060
Iteration 3995, loss = 0.37109453
Iteration 3996, loss = 0.37106210
Iteration 3997, loss = 0.37033300
Iteration 3998, loss = 0.37256706
Iteration 3999, loss = 0.37148511
Iteration 4000, loss = 0.37223858
Iteration 4001, loss = 0.37078007
Iteration 4002, loss = 0.37356337
Iteration 4003, loss = 0.37170894
Iteration 4004, loss = 0.37175029
Iteration 4005, loss = 0.37277436
Iteration 4006, loss = 0.36980221
Iteration 4007, loss = 0.36947184
Iteration 4008, loss = 0.36958965
Iteration 4009, loss = 0.37897035
Iteration 4010, loss = 0.37517442
Iteration 4011, loss = 0.37192226
Iteration 4012, loss = 0.37363397
Iteration 4013, loss = 0.37213594
Iteration 4014, loss = 0.37032534
Iteration 4015, loss = 0.37195386
Iteration 4016, loss = 0.37049533
Iteration 4017, loss = 0.36957131
Iteration 4018, loss = 0.37092307
Iteration 4019, loss = 0.37210255
Iteration 4020, loss = 0.36929661
Iteration 4021, loss = 0.37005739
Iteration 4022, loss = 0.37420358
Iteration 4023, loss = 0.37385067
Iteration 4024, loss = 0.37127557
Iteration 4025, loss = 0.37089252
Iteration 4026, loss = 0.37009531
Iteration 4027, loss = 0.37173434
Iteration 4028, loss = 0.37109624
Iteration 4029, loss = 0.37033214
Iteration 4030, loss = 0.36943101
Iteration 4031, loss = 0.37035682
Iteration 4032, loss = 0.37000987
Iteration 4033, loss = 0.36884561
Iteration 4034, loss = 0.37168014
Iteration 4035, loss = 0.37290437
Iteration 4036, loss = 0.36978999
Iteration 4037, loss = 0.37034512
Iteration 4038, loss = 0.37009066
Iteration 4039, loss = 0.37076992
Iteration 4040, loss = 0.37082313
Iteration 4041, loss = 0.37193440
Iteration 4042, loss = 0.36818788
Iteration 4043, loss = 0.36967629
Iteration 4044, loss = 0.37195000
Iteration 4045, loss = 0.37025383
Iteration 4046, loss = 0.37313163
Iteration 4047, loss = 0.36924800
Iteration 4048, loss = 0.37102055
Iteration 4049, loss = 0.37345713
Iteration 4050, loss = 0.37259754
Iteration 4051, loss = 0.37156258
Iteration 4052, loss = 0.37212540
Iteration 4053, loss = 0.37399006
Iteration 4054, loss = 0.37335031
Iteration 4055, loss = 0.37152468
Iteration 4056, loss = 0.36996945
Iteration 4057, loss = 0.37185674
Iteration 4058, loss = 0.37221332
Iteration 4059, loss = 0.36989667
Iteration 4060, loss = 0.37009328
Iteration 4061, loss = 0.37263897
Iteration 4062, loss = 0.37444228
Iteration 4063, loss = 0.37154411
Iteration 4064, loss = 0.37074960
Iteration 4065, loss = 0.37106330
Iteration 4066, loss = 0.37077441
Iteration 4067, loss = 0.37040019
Iteration 4068, loss = 0.37183919
Iteration 4069, loss = 0.37073827
Iteration 4070, loss = 0.37094269
Iteration 4071, loss = 0.37210325
Iteration 4072, loss = 0.36926526
Iteration 4073, loss = 0.37566851
Iteration 4074, loss = 0.37349445
Iteration 4075, loss = 0.37048527
Iteration 4076, loss = 0.37286037
Iteration 4077, loss = 0.37082249
Iteration 4078, loss = 0.37002663
Iteration 4079, loss = 0.37244328
Iteration 4080, loss = 0.37352864
Iteration 4081, loss = 0.37211496
Iteration 4082, loss = 0.37350568
Iteration 4083, loss = 0.37083240
Iteration 4084, loss = 0.36923553
Iteration 4085, loss = 0.36913014
Iteration 4086, loss = 0.37359419
Iteration 4087, loss = 0.37111407
Iteration 4088, loss = 0.36946728
Iteration 4089, loss = 0.37383165
Iteration 4090, loss = 0.37803889
Iteration 4091, loss = 0.37339748
Iteration 4092, loss = 0.36991066
Iteration 4093, loss = 0.37003305
Iteration 4094, loss = 0.37200068
Iteration 4095, loss = 0.37416073
Iteration 4096, loss = 0.36965407
Iteration 4097, loss = 0.37031899
Iteration 4098, loss = 0.37555202
Iteration 4099, loss = 0.37513560
Iteration 4100, loss = 0.37254438
Iteration 4101, loss = 0.36993133
Iteration 4102, loss = 0.37196756
Iteration 4103, loss = 0.36789917
Iteration 4104, loss = 0.37058212
Iteration 4105, loss = 0.37002054
Iteration 4106, loss = 0.37006945
Iteration 4107, loss = 0.37298725
Iteration 4108, loss = 0.37016418
Iteration 4109, loss = 0.36971145
Iteration 4110, loss = 0.37167063
Iteration 4111, loss = 0.36955134
Iteration 4112, loss = 0.37029531
Iteration 4113, loss = 0.37040266
Iteration 4114, loss = 0.37176947
Iteration 4115, loss = 0.37010311
Iteration 4116, loss = 0.37096058
Iteration 4117, loss = 0.37272835
Iteration 4118, loss = 0.37188270
Iteration 4119, loss = 0.37057835
Iteration 4120, loss = 0.37256050
Iteration 4121, loss = 0.37085348
Iteration 4122, loss = 0.37248484
Iteration 4123, loss = 0.36908506
Iteration 4124, loss = 0.37005173
Iteration 4125, loss = 0.37047407
Iteration 4126, loss = 0.36976026
Iteration 4127, loss = 0.37092758
Iteration 4128, loss = 0.37103838
Iteration 4129, loss = 0.37424924
Iteration 4130, loss = 0.37209765
Iteration 4131, loss = 0.37043321
Iteration 4132, loss = 0.36766437
Iteration 4133, loss = 0.36861556
Iteration 4134, loss = 0.37121166
Iteration 4135, loss = 0.37370875
Iteration 4136, loss = 0.37069553
Iteration 4137, loss = 0.37298784
Iteration 4138, loss = 0.37071806
Iteration 4139, loss = 0.36965063
Iteration 4140, loss = 0.36915443
Iteration 4141, loss = 0.36920323
Training loss did not improve more than tol=0.000100 for 200 consecutive epochs. Stopping.
MLP accuracy 0.832858253433532
MLP accuracy 0.7842900302114804
0.832858253433532
TN, FN, TP, FP 637 195 661 162
neg score 0.765625
pos score 0.8031591737545565
accuracy 0.7842900302114804
